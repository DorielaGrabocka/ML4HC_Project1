{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95c0aa73",
   "metadata": {},
   "source": [
    "## This notebook provides transfer learning functionality for the CNN Models\n",
    "\n",
    "Specifically, we need the params.json of the best PTBDB model. We first pretrain that model on MITBIH, then finetune finally on PTBDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17303fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eabeeed",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113f9a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import skorch\n",
    "from skorch.callbacks import LRScheduler, EarlyStopping, Checkpoint, Freezer\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from src.data_loading import load_data_mitbih, load_data_ptbdb\n",
    "from src.data_preprocessing import preprocess_x_pytorch, preprocess_y_pytorch\n",
    "from src.metrics_utils import compute_metrics, skorch_f1_score, sklearn_f1_score\n",
    "from src.cnn_models.cnn import CNN\n",
    "from src.skorch_utils import get_neural_net_classifier, get_class_weights\n",
    "from src.json_utils import serialize_tensors, deserialize_tensors, save_file, read_file\n",
    "from src.constants import DEVICE\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14905b74",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2dcec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_ptbdb, y_ptbdb), (xtest_ptbdb, ytest_ptbdb) = load_data_ptbdb()\n",
    "(x_mitbih, y_mitbih), (_, _) = load_data_mitbih()\n",
    "    \n",
    "print(x_ptbdb.shape)\n",
    "print(np.unique(y_ptbdb))\n",
    "assert np.array_equal(np.unique(y_ptbdb), np.unique(ytest_ptbdb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95a2f73",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45827d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ptbdb, xtest_ptbdb = preprocess_x_pytorch(x_ptbdb), preprocess_x_pytorch(xtest_ptbdb)\n",
    "y_ptbdb, ytest_ptbdb = preprocess_y_pytorch(y_ptbdb), preprocess_y_pytorch(ytest_ptbdb)\n",
    "\n",
    "x_mitbih = preprocess_x_pytorch(x_mitbih)\n",
    "y_mitbih = preprocess_y_pytorch(y_mitbih)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae9ccc",
   "metadata": {},
   "source": [
    "## Pretrain best PTBDB Architecture on MITBIH dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd350f9",
   "metadata": {},
   "source": [
    "### Define callbacks for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1da4917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks necessary for training\n",
    "early_stopping_cb = EarlyStopping(patience=25, monitor=\"skorch_f1_score\", lower_is_better=False)\n",
    "lr_scheduler_cb = LRScheduler(policy=ReduceLROnPlateau, min_lr=0.000001, patience=2, verbose=True)\n",
    "\n",
    "# callback for printing f1 score on validation set during fitting\n",
    "macro_f1_cb = skorch.callbacks.EpochScoring(scoring=skorch_f1_score, lower_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc6a0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = deserialize_tensors(read_file(\"CnnResidual_PTBDB\" + \"/params.json\"))\n",
    "\n",
    "params[\"criterion__weight\"] = torch.Tensor([1., 1., 1., 1., 1.])\n",
    "\n",
    "net = get_neural_net_classifier(module=CNN, n_classes=5, callbacks=[macro_f1_cb, lr_scheduler_cb, early_stopping_cb], params=params)\n",
    "net.fit(x_mitbih, y_mitbih)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f594b1",
   "metadata": {},
   "source": [
    "## Replace classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1f604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired from the skorch docs https://github.com/skorch-dev/skorch/blob/master/notebooks/Transfer_Learning.ipynb\n",
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, n_classes, pretrained_model, fully_connected_features):\n",
    "        super().__init__()\n",
    "        pretrained_model = deepcopy(pretrained_model)\n",
    "        # overwrite with a linear layer that maps to only to classes\n",
    "        pretrained_model.linear2 = nn.Linear(fully_connected_features, n_classes)\n",
    "        self.model = pretrained_model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c87feda",
   "metadata": {},
   "source": [
    "## Fine-tune CNN model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e006ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "finetuning_param_keys = [\"lr\", \"iterator_train__batch_size\", \"module__fully_connected_features\"]\n",
    "finetuning_params = {}\n",
    "for k in finetuning_param_keys:\n",
    "    finetuning_params[k] = params[k]\n",
    "\n",
    "finetuning_params[\"criterion__weight\"] = torch.Tensor([1., 1.])\n",
    "finetuning_params[\"module__pretrained_model\"] = net.module_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83268c54",
   "metadata": {},
   "source": [
    "## Try 1: Retrain everything without freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851cc274",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_net = get_neural_net_classifier(module=PretrainedModel, n_classes=2, callbacks=[macro_f1_cb, lr_scheduler_cb, early_stopping_cb], params=finetuning_params)\n",
    "pretrained_net.fit(x_ptbdb, y_ptbdb)\n",
    "\n",
    "y_proba = pretrained_net.predict_proba(xtest_ptbdb)\n",
    "\n",
    "print(\"-------------------------\\n\\n\")\n",
    "compute_metrics(ytest_ptbdb, y_proba, name=\"Transfer learning CNN - No Freeze\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7312bc1a",
   "metadata": {},
   "source": [
    "## Try 2: Freeze everything but last 2 fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62bf08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "freezer = Freezer(lambda x: not x.startswith('model.linear'))\n",
    "\n",
    "pretrained_net = get_neural_net_classifier(module=PretrainedModel, n_classes=2, callbacks=[macro_f1_cb, lr_scheduler_cb, early_stopping_cb, freezer], params=finetuning_params)\n",
    "pretrained_net.fit(x_ptbdb, y_ptbdb)\n",
    "\n",
    "y_proba = pretrained_net.predict_proba(xtest_ptbdb)\n",
    "\n",
    "print(\"-------------------------\\n\\n\")\n",
    "compute_metrics(ytest_ptbdb, y_proba, name=\"Transfer learning CNN - With Freeze\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74cf40d",
   "metadata": {},
   "source": [
    "## Try 3: First retrain fully connected and keep the rest frozen, then unfreeze everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed2020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set what we've trained previously\n",
    "finetuning_params[\"module__pretrained_model\"] = pretrained_net.module_\n",
    "\n",
    "all_unfrozen = get_neural_net_classifier(module=PretrainedModel, n_classes=2, callbacks=[macro_f1_cb, lr_scheduler_cb, early_stopping_cb], params=finetuning_params)\n",
    "all_unfrozen.fit(x_ptbdb, y_ptbdb)\n",
    "\n",
    "y_proba = all_unfrozen.predict_proba(xtest_ptbdb)\n",
    "\n",
    "print(\"-------------------------\\n\\n\")\n",
    "compute_metrics(ytest_ptbdb, y_proba, name=\"Transfer learning CNN - Freeze top layers then unfreeze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f71fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
