{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "207667d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cc3267",
   "metadata": {},
   "source": [
    "# This notebook offers\n",
    "## Hyperparameter Search, Training & Saving  + Loading & Testing CNN models\n",
    "\n",
    "### Main instructions\n",
    "\n",
    "- Global settings section\n",
    "    - Set hyperparameter search flag (takes a while). If one wants to check how it runs, see the below section on how to set up a smaller search grid\n",
    "    - Set the dataset to one of the two options\n",
    "    - Set the experiment type: deep or shallow refers to the number of layers in the model (and concretely correspond to the \"grid_params\" variable in the Hyperparameter Search section\n",
    "    - Otherwise, just run all notebook cells and check outputs of sections of interest.\n",
    "    \n",
    "### Detailed instructions for each section\n",
    "  \n",
    "- Hyperparameter search section\n",
    "    - This takes long, so one could skip directly to the next step (or set a small number of search iterations)\n",
    "    - The number of configs to be tested (number of search iterations) is set via the \"n_iter\" argument to \"RandomizedSearchCV\"\n",
    "    - Set the hyperparameter search grid via the \"grid_params\" variable\n",
    "    - By default, we use 4 splits for both the outer loop (\"cv\" argument to \"RandomizedSearchCV\") and the inner (\"train_split\" argument in \"get_neural_net_classifier\")\n",
    "    \n",
    "\n",
    "- Train & Save section\n",
    "    - use the best parameters found by the hyperparameter search, or just set custom ones\n",
    "    - this trains with a more patient early stopping, and saves the best model according to validation loss\n",
    "    \n",
    "    \n",
    "- Load back model and evaluate\n",
    "    - will work only if a model was previously trained and saved\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e35adc",
   "metadata": {},
   "source": [
    "# Global Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586be4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DO_HYPERPARAMETER_SEARCH = True\n",
    "\n",
    "# DATASET = \"MITBIH\"\n",
    "DATASET = \"PTBDB\"\n",
    "\n",
    "# EXPERIMENT_TYPE = \"shallow_hyperparam_search\"\n",
    "EXPERIMENT_TYPE = \"deep_hyperparam_search\"\n",
    "MODEL_SAVE_DIR = EXPERIMENT_TYPE + '_' + DATASET\n",
    "\n",
    "if DATASET == \"MITBIH\":\n",
    "    N_CLASSES = 5\n",
    "else:\n",
    "    N_CLASSES = 2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2562750",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8db727b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import skorch\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import LRScheduler, Checkpoint, EarlyStopping\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from src.metrics_utils import compute_metrics, skorch_f1_score, sklearn_f1_score\n",
    "from src.data_loading import load_data_mitbih, load_data_ptbdb\n",
    "from src.data_preprocessing import preprocess_x_pytorch, preprocess_y_pytorch\n",
    "from src.cnn_models.cnn import CNN\n",
    "from src.skorch_utils import get_neural_net_classifier, get_class_weights\n",
    "from src.json_utils import save_file, read_file, serialize_tensors, deserialize_tensors\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f573e",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062294b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11641, 187, 1)\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "if N_CLASSES == 5:\n",
    "    (x, y), (xtest, ytest) = load_data_mitbih()\n",
    "else:\n",
    "    (x, y), (xtest, ytest) = load_data_ptbdb()\n",
    "    \n",
    "print(x.shape)\n",
    "print(np.unique(y))\n",
    "assert np.array_equal(np.unique(y), np.unique(ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89a079d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, xtest = preprocess_x_pytorch(x), preprocess_x_pytorch(xtest)\n",
    "y, ytest = preprocess_y_pytorch(y), preprocess_y_pytorch(ytest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f252e682",
   "metadata": {},
   "source": [
    "# Hyperparameter Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dedcb5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_cb = LRScheduler(policy=ReduceLROnPlateau,\n",
    "                              min_lr=0.000001,\n",
    "                              patience=2,\n",
    "                              verbose=True)\n",
    "\n",
    "early_stopping_cb = EarlyStopping(patience=8, monitor=\"skorch_f1_score\", lower_is_better=False)\n",
    "macro_f1_cb = skorch.callbacks.EpochScoring(scoring=skorch_f1_score, lower_is_better=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c9f8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 25 candidates, totalling 100 fits\n",
      "[CV 1/4; 1/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4199\u001b[0m        \u001b[32m0.3981\u001b[0m       \u001b[35m0.7238\u001b[0m        \u001b[31m0.9365\u001b[0m  0.8272\n",
      "      2             \u001b[36m0.8744\u001b[0m        \u001b[32m0.1851\u001b[0m       \u001b[35m0.8992\u001b[0m        \u001b[31m0.2298\u001b[0m  0.6271\n",
      "      3             \u001b[36m0.9415\u001b[0m        \u001b[32m0.1066\u001b[0m       \u001b[35m0.9510\u001b[0m        \u001b[31m0.1227\u001b[0m  0.6257\n",
      "      4             \u001b[36m0.9579\u001b[0m        \u001b[32m0.0630\u001b[0m       \u001b[35m0.9656\u001b[0m        \u001b[31m0.0795\u001b[0m  0.6224\n",
      "      5             0.8396        \u001b[32m0.0536\u001b[0m       0.8891        0.4704  0.6462\n",
      "      6             \u001b[36m0.9847\u001b[0m        \u001b[32m0.0470\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0426\u001b[0m  0.6291\n",
      "      7             0.9666        \u001b[32m0.0239\u001b[0m       0.9725        0.0856  0.6182\n",
      "      8             0.9780        \u001b[32m0.0228\u001b[0m       0.9821        0.0645  0.6147\n",
      "      9             0.9586        \u001b[32m0.0222\u001b[0m       0.9679        0.1609  0.6168\n",
      "     10             0.9787        \u001b[32m0.0187\u001b[0m       0.9831        0.0440  0.6154\n",
      "     11             0.9844        0.0225       0.9876        \u001b[31m0.0402\u001b[0m  0.6486\n",
      "     12             0.9682        0.0332       0.9748        0.0907  0.6531\n",
      "Epoch 00013: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     13             0.9651        0.0220       0.9716        0.0827  0.6211\n",
      "     14             \u001b[36m0.9891\u001b[0m        \u001b[32m0.0089\u001b[0m       \u001b[35m0.9913\u001b[0m        \u001b[31m0.0308\u001b[0m  0.6166\n",
      "     15             \u001b[36m0.9908\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9927\u001b[0m        \u001b[31m0.0228\u001b[0m  0.6155\n",
      "     16             \u001b[36m0.9914\u001b[0m        \u001b[32m0.0024\u001b[0m       \u001b[35m0.9931\u001b[0m        \u001b[31m0.0212\u001b[0m  0.6166\n",
      "     17             \u001b[36m0.9920\u001b[0m        \u001b[32m0.0018\u001b[0m       \u001b[35m0.9936\u001b[0m        \u001b[31m0.0203\u001b[0m  0.6151\n",
      "     18             0.9920        \u001b[32m0.0016\u001b[0m       0.9936        \u001b[31m0.0198\u001b[0m  0.6167\n",
      "     19             \u001b[36m0.9926\u001b[0m        \u001b[32m0.0013\u001b[0m       \u001b[35m0.9940\u001b[0m        0.0201  0.6143\n",
      "     20             0.9920        \u001b[32m0.0013\u001b[0m       0.9936        \u001b[31m0.0193\u001b[0m  0.6161\n",
      "     21             0.9926        \u001b[32m0.0012\u001b[0m       0.9940        \u001b[31m0.0184\u001b[0m  0.6145\n",
      "     22             0.9926        0.0012       0.9940        0.0189  0.6182\n",
      "     23             0.9926        \u001b[32m0.0009\u001b[0m       0.9940        0.0191  0.6159\n",
      "     24             0.9926        0.0011       0.9940        0.0192  0.6161\n",
      "     25             \u001b[36m0.9931\u001b[0m        \u001b[32m0.0008\u001b[0m       \u001b[35m0.9945\u001b[0m        0.0191  0.6144\n",
      "     26             0.9931        \u001b[32m0.0008\u001b[0m       0.9945        0.0191  0.6161\n",
      "     27             \u001b[36m0.9937\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9950\u001b[0m        0.0194  0.6141\n",
      "     28             0.9931        \u001b[32m0.0006\u001b[0m       0.9945        0.0193  0.6163\n",
      "     29             0.9931        \u001b[32m0.0006\u001b[0m       0.9945        0.0189  0.6146\n",
      "     30             0.9937        \u001b[32m0.0006\u001b[0m       0.9950        0.0190  0.6156\n",
      "     31             0.9931        0.0006       0.9945        0.0192  0.6143\n",
      "     32             0.9931        \u001b[32m0.0005\u001b[0m       0.9945        0.0194  0.6151\n",
      "     33             0.9931        0.0005       0.9945        0.0191  0.6145\n",
      "     34             0.9931        \u001b[32m0.0004\u001b[0m       0.9945        0.0191  0.6148\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 1/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.993) f1_score: (test=0.991) total time=  23.5s\n",
      "[CV 2/4; 1/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4232\u001b[0m        \u001b[32m0.4033\u001b[0m       \u001b[35m0.7288\u001b[0m        \u001b[31m0.5969\u001b[0m  0.6159\n",
      "      2             \u001b[36m0.8572\u001b[0m        \u001b[32m0.1789\u001b[0m       \u001b[35m0.8960\u001b[0m        \u001b[31m0.2463\u001b[0m  0.6195\n",
      "      3             \u001b[36m0.9657\u001b[0m        \u001b[32m0.0824\u001b[0m       \u001b[35m0.9725\u001b[0m        \u001b[31m0.0857\u001b[0m  0.6603\n",
      "      4             0.9080        \u001b[32m0.0584\u001b[0m       0.9331        0.1840  0.6339\n",
      "      5             \u001b[36m0.9807\u001b[0m        \u001b[32m0.0354\u001b[0m       \u001b[35m0.9849\u001b[0m        \u001b[31m0.0502\u001b[0m  0.6169\n",
      "      6             0.9686        \u001b[32m0.0275\u001b[0m       0.9757        0.0928  0.6158\n",
      "      7             0.9359        \u001b[32m0.0251\u001b[0m       0.9524        0.1419  0.6153\n",
      "      8             0.8694        0.0442       0.8855        0.5018  0.6159\n",
      "      9             0.9747        0.0430       0.9803        0.0704  0.6153\n",
      "     10             0.9637        \u001b[32m0.0204\u001b[0m       0.9707        0.0861  0.6167\n",
      "     11             0.9702        \u001b[32m0.0094\u001b[0m       0.9771        0.0993  0.6158\n",
      "     12             \u001b[36m0.9831\u001b[0m        \u001b[32m0.0032\u001b[0m       \u001b[35m0.9867\u001b[0m        \u001b[31m0.0435\u001b[0m  0.6156\n",
      "     13             \u001b[36m0.9833\u001b[0m        0.0032       0.9867        0.0528  0.6159\n",
      "     14             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0026\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0420\u001b[0m  0.6182\n",
      "     15             0.9838        \u001b[32m0.0009\u001b[0m       0.9872        0.0482  0.6160\n",
      "     16             0.9878        \u001b[32m0.0006\u001b[0m       0.9904        0.0462  0.6156\n",
      "     17             \u001b[36m0.9889\u001b[0m        \u001b[32m0.0003\u001b[0m       \u001b[35m0.9913\u001b[0m        \u001b[31m0.0374\u001b[0m  0.6157\n",
      "     18             0.9889        \u001b[32m0.0001\u001b[0m       0.9913        \u001b[31m0.0356\u001b[0m  0.6161\n",
      "     19             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0001\u001b[0m       \u001b[35m0.9918\u001b[0m        0.0359  0.6200\n",
      "     20             0.9895        0.0001       0.9918        \u001b[31m0.0349\u001b[0m  0.6628\n",
      "     21             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0001\u001b[0m       \u001b[35m0.9922\u001b[0m        0.0384  0.6348\n",
      "     22             0.9895        \u001b[32m0.0001\u001b[0m       0.9918        0.0391  0.6160\n",
      "     23             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0000\u001b[0m       0.9922        0.0378  0.6204\n",
      "     24             0.9901        0.0001       0.9922        0.0382  0.6168\n",
      "     25             0.9890        0.0001       0.9913        0.0386  0.6145\n",
      "     26             0.9901        \u001b[32m0.0000\u001b[0m       0.9922        0.0392  0.6127\n",
      "     27             0.9889        0.0000       0.9913        0.0400  0.6187\n",
      "     28             0.9901        0.0000       0.9922        0.0382  0.6157\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 1/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.995) f1_score: (test=0.994) total time=  18.2s\n",
      "[CV 3/4; 1/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4505\u001b[0m        \u001b[32m0.3628\u001b[0m       \u001b[35m0.7279\u001b[0m        \u001b[31m0.5826\u001b[0m  0.6149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2             \u001b[36m0.9038\u001b[0m        \u001b[32m0.1601\u001b[0m       \u001b[35m0.9217\u001b[0m        \u001b[31m0.2031\u001b[0m  0.6176\n",
      "      3             \u001b[36m0.9285\u001b[0m        \u001b[32m0.0907\u001b[0m       \u001b[35m0.9414\u001b[0m        \u001b[31m0.1623\u001b[0m  0.6167\n",
      "      4             \u001b[36m0.9581\u001b[0m        \u001b[32m0.0751\u001b[0m       \u001b[35m0.9670\u001b[0m        \u001b[31m0.0816\u001b[0m  0.6167\n",
      "      5             \u001b[36m0.9753\u001b[0m        \u001b[32m0.0496\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0640\u001b[0m  0.6167\n",
      "      6             \u001b[36m0.9842\u001b[0m        \u001b[32m0.0312\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0440\u001b[0m  0.6162\n",
      "      7             0.9197        0.0329       0.9404        0.2479  0.6170\n",
      "      8             0.9803        \u001b[32m0.0245\u001b[0m       0.9844        0.0461  0.6165\n",
      "      9             0.9632        \u001b[32m0.0214\u001b[0m       0.9702        0.1085  0.6164\n",
      "     10             0.9526        0.0580       0.9620        0.1375  0.6162\n",
      "     11             0.9824        0.0340       0.9863        0.0587  0.6178\n",
      "     12             0.9665        \u001b[32m0.0162\u001b[0m       0.9743        0.1008  0.6158\n",
      "     13             0.9771        \u001b[32m0.0082\u001b[0m       0.9817        0.0654  0.6178\n",
      "     14             \u001b[36m0.9907\u001b[0m        \u001b[32m0.0033\u001b[0m       \u001b[35m0.9927\u001b[0m        \u001b[31m0.0329\u001b[0m  0.6170\n",
      "     15             0.9890        \u001b[32m0.0009\u001b[0m       0.9913        \u001b[31m0.0322\u001b[0m  0.6153\n",
      "     16             0.9901        0.0012       0.9922        0.0386  0.6169\n",
      "     17             0.9906        \u001b[32m0.0005\u001b[0m       0.9927        0.0335  0.6153\n",
      "     18             \u001b[36m0.9918\u001b[0m        \u001b[32m0.0002\u001b[0m       \u001b[35m0.9936\u001b[0m        0.0324  0.6171\n",
      "     19             0.9907        \u001b[32m0.0002\u001b[0m       0.9927        0.0325  0.6206\n",
      "     20             0.9907        \u001b[32m0.0001\u001b[0m       0.9927        0.0325  0.6193\n",
      "     21             0.9918        0.0001       0.9936        \u001b[31m0.0319\u001b[0m  0.6220\n",
      "     22             0.9913        \u001b[32m0.0001\u001b[0m       0.9931        0.0323  0.6189\n",
      "     23             0.9907        0.0001       0.9927        0.0320  0.6185\n",
      "     24             \u001b[36m0.9930\u001b[0m        0.0001       \u001b[35m0.9945\u001b[0m        0.0331  0.6172\n",
      "     25             0.9930        \u001b[32m0.0001\u001b[0m       0.9945        0.0329  0.6159\n",
      "     26             0.9907        \u001b[32m0.0001\u001b[0m       0.9927        0.0322  0.6191\n",
      "     27             0.9930        0.0001       0.9945        0.0337  0.6153\n",
      "     28             0.9907        \u001b[32m0.0000\u001b[0m       0.9927        0.0338  0.6181\n",
      "     29             0.9907        0.0000       0.9927        0.0341  0.6293\n",
      "     30             0.9907        \u001b[32m0.0000\u001b[0m       0.9927        0.0341  0.6188\n",
      "     31             0.9907        0.0000       0.9927        0.0347  0.6150\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 1/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.995) f1_score: (test=0.994) total time=  19.9s\n",
      "[CV 4/4; 1/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4775\u001b[0m        \u001b[32m0.4016\u001b[0m       \u001b[35m0.7119\u001b[0m        \u001b[31m0.5810\u001b[0m  0.6206\n",
      "      2             \u001b[36m0.8420\u001b[0m        \u001b[32m0.2049\u001b[0m       \u001b[35m0.8672\u001b[0m        \u001b[31m0.3302\u001b[0m  0.6206\n",
      "      3             \u001b[36m0.9560\u001b[0m        \u001b[32m0.1286\u001b[0m       \u001b[35m0.9652\u001b[0m        \u001b[31m0.1021\u001b[0m  0.6203\n",
      "      4             0.9527        \u001b[32m0.0670\u001b[0m       0.9615        0.1074  0.6196\n",
      "      5             \u001b[36m0.9561\u001b[0m        \u001b[32m0.0639\u001b[0m       \u001b[35m0.9666\u001b[0m        0.1114  0.6149\n",
      "      6             \u001b[36m0.9739\u001b[0m        \u001b[32m0.0509\u001b[0m       \u001b[35m0.9794\u001b[0m        \u001b[31m0.0705\u001b[0m  0.6168\n",
      "      7             0.9687        \u001b[32m0.0294\u001b[0m       0.9757        0.0894  0.6173\n",
      "      8             0.9689        0.0333       0.9757        0.0792  0.6214\n",
      "      9             \u001b[36m0.9792\u001b[0m        \u001b[32m0.0201\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0612\u001b[0m  0.6208\n",
      "     10             0.9789        \u001b[32m0.0167\u001b[0m       0.9835        0.0781  0.6237\n",
      "     11             0.9594        0.0305       0.9670        0.0968  0.6200\n",
      "     12             \u001b[36m0.9826\u001b[0m        0.0282       \u001b[35m0.9863\u001b[0m        0.0639  0.6186\n",
      "Epoch 00013: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     13             0.9342        0.0259       0.9510        0.1778  0.6181\n",
      "     14             0.9809        \u001b[32m0.0108\u001b[0m       0.9849        \u001b[31m0.0510\u001b[0m  0.6167\n",
      "     15             \u001b[36m0.9866\u001b[0m        \u001b[32m0.0039\u001b[0m       \u001b[35m0.9895\u001b[0m        \u001b[31m0.0442\u001b[0m  0.6167\n",
      "     16             \u001b[36m0.9872\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9899\u001b[0m        \u001b[31m0.0442\u001b[0m  0.6155\n",
      "     17             0.9866        \u001b[32m0.0018\u001b[0m       0.9895        \u001b[31m0.0435\u001b[0m  0.6176\n",
      "     18             0.9866        \u001b[32m0.0015\u001b[0m       0.9895        \u001b[31m0.0412\u001b[0m  0.6158\n",
      "     19             0.9866        \u001b[32m0.0011\u001b[0m       0.9895        0.0431  0.6164\n",
      "     20             0.9866        \u001b[32m0.0011\u001b[0m       0.9895        0.0417  0.6160\n",
      "     21             0.9872        0.0011       0.9899        0.0424  0.6172\n",
      "     22             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9904\u001b[0m        0.0419  0.6161\n",
      "     23             0.9872        0.0009       0.9899        0.0425  0.6175\n",
      "     24             0.9878        \u001b[32m0.0008\u001b[0m       0.9904        0.0430  0.6204\n",
      "     25             0.9878        \u001b[32m0.0008\u001b[0m       0.9904        0.0432  0.6203\n",
      "     26             \u001b[36m0.9883\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9908\u001b[0m        0.0417  0.6197\n",
      "     27             0.9878        \u001b[32m0.0006\u001b[0m       0.9904        0.0423  0.6238\n",
      "     28             0.9878        \u001b[32m0.0005\u001b[0m       0.9904        0.0413  0.6279\n",
      "     29             0.9878        \u001b[32m0.0005\u001b[0m       0.9904        \u001b[31m0.0410\u001b[0m  0.6241\n",
      "     30             0.9878        0.0006       0.9904        0.0427  0.6188\n",
      "     31             0.9866        \u001b[32m0.0005\u001b[0m       0.9895        0.0424  0.6195\n",
      "     32             0.9872        \u001b[32m0.0004\u001b[0m       0.9899        0.0420  0.6199\n",
      "     33             0.9878        \u001b[32m0.0004\u001b[0m       0.9904        0.0428  0.6182\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 1/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.994) f1_score: (test=0.992) total time=  21.2s\n",
      "[CV 1/4; 2/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4199\u001b[0m        \u001b[32m0.4685\u001b[0m       \u001b[35m0.7238\u001b[0m        \u001b[31m0.5535\u001b[0m  0.5749\n",
      "      2             \u001b[36m0.8145\u001b[0m        \u001b[32m0.2565\u001b[0m       \u001b[35m0.8653\u001b[0m        \u001b[31m0.3411\u001b[0m  0.5714\n",
      "      3             \u001b[36m0.9314\u001b[0m        \u001b[32m0.1442\u001b[0m       \u001b[35m0.9432\u001b[0m        \u001b[31m0.1254\u001b[0m  0.5716\n",
      "      4             \u001b[36m0.9451\u001b[0m        \u001b[32m0.0933\u001b[0m       \u001b[35m0.9546\u001b[0m        \u001b[31m0.1080\u001b[0m  0.5695\n",
      "      5             \u001b[36m0.9701\u001b[0m        \u001b[32m0.0675\u001b[0m       \u001b[35m0.9757\u001b[0m        \u001b[31m0.0684\u001b[0m  0.5707\n",
      "      6             \u001b[36m0.9772\u001b[0m        \u001b[32m0.0321\u001b[0m       \u001b[35m0.9817\u001b[0m        \u001b[31m0.0475\u001b[0m  0.5681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7             0.9756        \u001b[32m0.0144\u001b[0m       0.9808        0.0514  0.5700\n",
      "      8             \u001b[36m0.9798\u001b[0m        \u001b[32m0.0094\u001b[0m       \u001b[35m0.9840\u001b[0m        0.0540  0.5677\n",
      "      9             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0075\u001b[0m       \u001b[35m0.9872\u001b[0m        \u001b[31m0.0383\u001b[0m  0.5685\n",
      "     10             0.9690        0.0079       0.9757        0.0837  0.5714\n",
      "     11             0.9762        0.0089       0.9808        0.0640  0.5707\n",
      "Epoch 00012: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     12             0.9685        0.0118       0.9753        0.0884  0.5677\n",
      "     13             \u001b[36m0.9840\u001b[0m        \u001b[32m0.0046\u001b[0m       0.9872        0.0425  0.5702\n",
      "     14             \u001b[36m0.9840\u001b[0m        \u001b[32m0.0022\u001b[0m       0.9872        0.0386  0.5681\n",
      "     15             \u001b[36m0.9851\u001b[0m        \u001b[32m0.0015\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0382\u001b[0m  0.5732\n",
      "     16             0.9851        \u001b[32m0.0012\u001b[0m       0.9881        \u001b[31m0.0376\u001b[0m  0.5684\n",
      "     17             0.9851        \u001b[32m0.0009\u001b[0m       0.9881        \u001b[31m0.0370\u001b[0m  0.5695\n",
      "     18             \u001b[36m0.9857\u001b[0m        \u001b[32m0.0008\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0365\u001b[0m  0.5675\n",
      "     19             0.9856        \u001b[32m0.0007\u001b[0m       0.9885        \u001b[31m0.0358\u001b[0m  0.5677\n",
      "     20             \u001b[36m0.9857\u001b[0m        0.0008       0.9885        0.0358  0.5671\n",
      "     21             \u001b[36m0.9874\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9899\u001b[0m        \u001b[31m0.0337\u001b[0m  0.5669\n",
      "     22             \u001b[36m0.9879\u001b[0m        \u001b[32m0.0006\u001b[0m       \u001b[35m0.9904\u001b[0m        0.0347  0.5673\n",
      "     23             0.9873        \u001b[32m0.0005\u001b[0m       0.9899        0.0343  0.5667\n",
      "     24             \u001b[36m0.9885\u001b[0m        0.0006       \u001b[35m0.9908\u001b[0m        0.0343  0.5670\n",
      "     25             0.9873        \u001b[32m0.0005\u001b[0m       0.9899        0.0338  0.5666\n",
      "     26             \u001b[36m0.9891\u001b[0m        \u001b[32m0.0005\u001b[0m       \u001b[35m0.9913\u001b[0m        0.0343  0.5662\n",
      "     27             0.9879        \u001b[32m0.0004\u001b[0m       0.9904        0.0346  0.5667\n",
      "     28             0.9891        0.0004       0.9913        \u001b[31m0.0336\u001b[0m  0.5661\n",
      "     29             0.9885        \u001b[32m0.0004\u001b[0m       0.9908        \u001b[31m0.0333\u001b[0m  0.5674\n",
      "     30             \u001b[36m0.9891\u001b[0m        0.0004       0.9913        0.0335  0.5685\n",
      "     31             0.9879        \u001b[32m0.0003\u001b[0m       0.9904        0.0339  0.5679\n",
      "     32             0.9868        0.0004       0.9895        0.0344  0.5670\n",
      "     33             0.9874        0.0004       0.9899        0.0340  0.5664\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 2/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.989) f1_score: (test=0.986) total time=  19.5s\n",
      "[CV 2/4; 2/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4508\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.7022\u001b[0m  0.5649\n",
      "      2             \u001b[36m0.8751\u001b[0m        \u001b[32m0.2253\u001b[0m       \u001b[35m0.9056\u001b[0m        \u001b[31m0.2319\u001b[0m  0.5675\n",
      "      3             \u001b[36m0.9675\u001b[0m        \u001b[32m0.1016\u001b[0m       \u001b[35m0.9748\u001b[0m        \u001b[31m0.0754\u001b[0m  0.5674\n",
      "      4             \u001b[36m0.9741\u001b[0m        \u001b[32m0.0600\u001b[0m       \u001b[35m0.9798\u001b[0m        \u001b[31m0.0682\u001b[0m  0.5648\n",
      "      5             0.9651        \u001b[32m0.0315\u001b[0m       0.9721        0.0835  0.5660\n",
      "      6             0.9730        \u001b[32m0.0213\u001b[0m       0.9785        0.0708  0.5647\n",
      "      7             0.9732        \u001b[32m0.0209\u001b[0m       0.9789        \u001b[31m0.0654\u001b[0m  0.5645\n",
      "      8             \u001b[36m0.9790\u001b[0m        \u001b[32m0.0140\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0614\u001b[0m  0.5656\n",
      "      9             0.9754        \u001b[32m0.0067\u001b[0m       0.9808        \u001b[31m0.0583\u001b[0m  0.5650\n",
      "     10             0.9724        0.0082       0.9780        0.0742  0.5646\n",
      "     11             0.9751        \u001b[32m0.0050\u001b[0m       0.9808        0.0768  0.5647\n",
      "     12             0.9776        0.0053       0.9821        0.0614  0.5647\n",
      "     13             0.9773        0.0069       0.9821        0.0683  0.5651\n",
      "Epoch 00014: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     14             0.9767        0.0155       0.9817        0.0800  0.5680\n",
      "     15             \u001b[36m0.9793\u001b[0m        \u001b[32m0.0039\u001b[0m       0.9835        0.0616  0.5646\n",
      "     16             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0012\u001b[0m       \u001b[35m0.9872\u001b[0m        \u001b[31m0.0507\u001b[0m  0.5646\n",
      "     17             \u001b[36m0.9849\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0488\u001b[0m  0.5647\n",
      "     18             0.9849        \u001b[32m0.0006\u001b[0m       0.9881        \u001b[31m0.0478\u001b[0m  0.5647\n",
      "     19             0.9838        0.0007       0.9872        0.0494  0.5647\n",
      "     20             0.9832        \u001b[32m0.0005\u001b[0m       0.9867        \u001b[31m0.0477\u001b[0m  0.5647\n",
      "     21             0.9843        \u001b[32m0.0004\u001b[0m       0.9876        0.0481  0.5670\n",
      "     22             0.9843        0.0004       0.9876        0.0489  0.5697\n",
      "     23             0.9837        \u001b[32m0.0004\u001b[0m       0.9872        0.0489  0.5690\n",
      "     24             0.9849        0.0004       0.9881        0.0492  0.5681\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 2/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.990) f1_score: (test=0.987) total time=  14.3s\n",
      "[CV 3/4; 2/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4212\u001b[0m        \u001b[32m0.4260\u001b[0m       \u001b[35m0.7229\u001b[0m        \u001b[31m0.5158\u001b[0m  0.5680\n",
      "      2             \u001b[36m0.8427\u001b[0m        \u001b[32m0.2001\u001b[0m       \u001b[35m0.8749\u001b[0m        \u001b[31m0.2656\u001b[0m  0.5680\n",
      "      3             \u001b[36m0.9638\u001b[0m        \u001b[32m0.0867\u001b[0m       \u001b[35m0.9716\u001b[0m        \u001b[31m0.0813\u001b[0m  0.5685\n",
      "      4             0.9420        \u001b[32m0.0699\u001b[0m       0.9565        0.1140  0.5694\n",
      "      5             \u001b[36m0.9729\u001b[0m        \u001b[32m0.0292\u001b[0m       \u001b[35m0.9785\u001b[0m        \u001b[31m0.0620\u001b[0m  0.5884\n",
      "      6             \u001b[36m0.9842\u001b[0m        \u001b[32m0.0150\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0534\u001b[0m  0.5718\n",
      "      7             0.9818        \u001b[32m0.0095\u001b[0m       0.9858        0.0565  0.5734\n",
      "      8             0.9734        0.0148       0.9794        0.0780  0.5702\n",
      "      9             0.9747        0.0232       0.9798        0.0701  0.5686\n",
      "Epoch 00010: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     10             0.9786        0.0150       0.9831        0.0598  0.5696\n",
      "     11             0.9832        \u001b[32m0.0058\u001b[0m       0.9867        0.0544  0.5694\n",
      "     12             \u001b[36m0.9854\u001b[0m        \u001b[32m0.0024\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0517\u001b[0m  0.5717\n",
      "     13             0.9843        \u001b[32m0.0015\u001b[0m       0.9876        0.0526  0.5730\n",
      "     14             0.9849        \u001b[32m0.0014\u001b[0m       0.9881        \u001b[31m0.0512\u001b[0m  0.5763\n",
      "     15             0.9849        \u001b[32m0.0012\u001b[0m       0.9881        \u001b[31m0.0508\u001b[0m  0.5689\n",
      "     16             \u001b[36m0.9854\u001b[0m        \u001b[32m0.0012\u001b[0m       0.9885        \u001b[31m0.0502\u001b[0m  0.5698\n",
      "     17             0.9854        \u001b[32m0.0009\u001b[0m       0.9885        0.0508  0.5682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18             0.9854        0.0009       0.9885        \u001b[31m0.0495\u001b[0m  0.5695\n",
      "     19             0.9854        0.0009       0.9885        0.0501  0.5678\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 2/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.987) f1_score: (test=0.984) total time=  11.5s\n",
      "[CV 4/4; 2/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4216\u001b[0m        \u001b[32m0.4769\u001b[0m       \u001b[35m0.7288\u001b[0m        \u001b[31m0.5510\u001b[0m  0.5767\n",
      "      2             \u001b[36m0.8794\u001b[0m        \u001b[32m0.2534\u001b[0m       \u001b[35m0.9024\u001b[0m        \u001b[31m0.2278\u001b[0m  0.5710\n",
      "      3             \u001b[36m0.9568\u001b[0m        \u001b[32m0.1212\u001b[0m       \u001b[35m0.9666\u001b[0m        \u001b[31m0.0917\u001b[0m  0.5708\n",
      "      4             \u001b[36m0.9708\u001b[0m        \u001b[32m0.0741\u001b[0m       \u001b[35m0.9771\u001b[0m        \u001b[31m0.0698\u001b[0m  0.5880\n",
      "      5             0.9554        \u001b[32m0.0519\u001b[0m       0.9638        0.0913  0.6097\n",
      "      6             \u001b[36m0.9771\u001b[0m        \u001b[32m0.0312\u001b[0m       \u001b[35m0.9821\u001b[0m        \u001b[31m0.0587\u001b[0m  0.6061\n",
      "      7             0.9731        \u001b[32m0.0243\u001b[0m       0.9789        0.0674  0.5706\n",
      "      8             0.9771        \u001b[32m0.0190\u001b[0m       0.9821        0.0617  0.5795\n",
      "      9             \u001b[36m0.9827\u001b[0m        \u001b[32m0.0079\u001b[0m       \u001b[35m0.9863\u001b[0m        \u001b[31m0.0439\u001b[0m  0.5748\n",
      "     10             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0041\u001b[0m       \u001b[35m0.9872\u001b[0m        0.0549  0.5747\n",
      "     11             0.9818        \u001b[32m0.0023\u001b[0m       0.9858        0.0581  0.5692\n",
      "     12             0.9813        0.0032       0.9853        0.0507  0.5679\n",
      "     13             \u001b[36m0.9860\u001b[0m        \u001b[32m0.0016\u001b[0m       \u001b[35m0.9890\u001b[0m        0.0568  0.5685\n",
      "     14             0.9827        0.0034       0.9863        0.0640  0.5676\n",
      "     15             0.9786        0.0057       0.9831        0.0708  0.5699\n",
      "Epoch 00016: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     16             0.9642        0.0200       0.9716        0.1139  0.5680\n",
      "     17             0.9831        0.0095       0.9867        0.0547  0.5692\n",
      "     18             0.9848        0.0018       0.9881        0.0495  0.5719\n",
      "     19             0.9848        \u001b[32m0.0012\u001b[0m       0.9881        0.0495  0.5903\n",
      "     20             0.9854        \u001b[32m0.0008\u001b[0m       0.9885        0.0486  0.5772\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 2/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.989) f1_score: (test=0.986) total time=  12.2s\n",
      "[CV 1/4; 3/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.6943\u001b[0m        \u001b[32m0.5393\u001b[0m       \u001b[35m0.7499\u001b[0m        \u001b[31m0.6611\u001b[0m  0.4494\n",
      "      2             0.6921        \u001b[32m0.4265\u001b[0m       \u001b[35m0.7943\u001b[0m        \u001b[31m0.4036\u001b[0m  0.4490\n",
      "      3             \u001b[36m0.8891\u001b[0m        \u001b[32m0.3015\u001b[0m       \u001b[35m0.9098\u001b[0m        \u001b[31m0.2484\u001b[0m  0.4485\n",
      "      4             \u001b[36m0.9157\u001b[0m        \u001b[32m0.2036\u001b[0m       \u001b[35m0.9308\u001b[0m        \u001b[31m0.1721\u001b[0m  0.4497\n",
      "      5             \u001b[36m0.9384\u001b[0m        \u001b[32m0.1418\u001b[0m       \u001b[35m0.9492\u001b[0m        \u001b[31m0.1347\u001b[0m  0.4619\n",
      "      6             \u001b[36m0.9594\u001b[0m        \u001b[32m0.1029\u001b[0m       \u001b[35m0.9670\u001b[0m        \u001b[31m0.0958\u001b[0m  0.4483\n",
      "      7             \u001b[36m0.9677\u001b[0m        \u001b[32m0.0800\u001b[0m       \u001b[35m0.9743\u001b[0m        \u001b[31m0.0707\u001b[0m  0.4488\n",
      "      8             \u001b[36m0.9707\u001b[0m        \u001b[32m0.0581\u001b[0m       \u001b[35m0.9766\u001b[0m        \u001b[31m0.0640\u001b[0m  0.4500\n",
      "      9             \u001b[36m0.9717\u001b[0m        \u001b[32m0.0455\u001b[0m       \u001b[35m0.9771\u001b[0m        \u001b[31m0.0627\u001b[0m  0.4487\n",
      "     10             \u001b[36m0.9766\u001b[0m        \u001b[32m0.0396\u001b[0m       \u001b[35m0.9812\u001b[0m        \u001b[31m0.0521\u001b[0m  0.4481\n",
      "     11             0.9763        \u001b[32m0.0260\u001b[0m       0.9812        0.0558  0.4486\n",
      "     12             0.9654        \u001b[32m0.0230\u001b[0m       0.9716        0.0728  0.4497\n",
      "     13             \u001b[36m0.9810\u001b[0m        \u001b[32m0.0166\u001b[0m       \u001b[35m0.9849\u001b[0m        \u001b[31m0.0459\u001b[0m  0.4617\n",
      "     14             0.9741        \u001b[32m0.0138\u001b[0m       0.9789        0.0600  0.4502\n",
      "     15             0.9773        \u001b[32m0.0136\u001b[0m       0.9817        0.0463  0.4511\n",
      "     16             0.9784        \u001b[32m0.0101\u001b[0m       0.9826        0.0506  0.4531\n",
      "     17             0.9739        \u001b[32m0.0088\u001b[0m       0.9789        0.0588  0.4546\n",
      "     18             \u001b[36m0.9811\u001b[0m        \u001b[32m0.0073\u001b[0m       0.9849        0.0484  0.4562\n",
      "     19             0.9767        0.0103       0.9812        0.0536  0.4513\n",
      "     20             0.9805        0.0150       0.9844        0.0495  0.4494\n",
      "Epoch 00021: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 3/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.978) f1_score: (test=0.973) total time=   9.6s\n",
      "[CV 2/4; 3/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.5321\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5813\u001b[0m  0.4607\n",
      "      2             \u001b[36m0.5156\u001b[0m        \u001b[32m0.4598\u001b[0m       \u001b[35m0.7545\u001b[0m        \u001b[31m0.4574\u001b[0m  0.4588\n",
      "      3             \u001b[36m0.8359\u001b[0m        \u001b[32m0.3789\u001b[0m       \u001b[35m0.8763\u001b[0m        \u001b[31m0.3212\u001b[0m  0.4537\n",
      "      4             \u001b[36m0.8852\u001b[0m        \u001b[32m0.2938\u001b[0m       \u001b[35m0.9070\u001b[0m        \u001b[31m0.2556\u001b[0m  0.4538\n",
      "      5             \u001b[36m0.9118\u001b[0m        \u001b[32m0.2275\u001b[0m       \u001b[35m0.9285\u001b[0m        \u001b[31m0.2005\u001b[0m  0.4537\n",
      "      6             \u001b[36m0.9410\u001b[0m        \u001b[32m0.1724\u001b[0m       \u001b[35m0.9528\u001b[0m        \u001b[31m0.1378\u001b[0m  0.4527\n",
      "      7             \u001b[36m0.9533\u001b[0m        \u001b[32m0.1347\u001b[0m       \u001b[35m0.9624\u001b[0m        \u001b[31m0.1175\u001b[0m  0.4499\n",
      "      8             \u001b[36m0.9599\u001b[0m        \u001b[32m0.1051\u001b[0m       \u001b[35m0.9679\u001b[0m        \u001b[31m0.0965\u001b[0m  0.4503\n",
      "      9             0.9573        \u001b[32m0.0774\u001b[0m       0.9656        \u001b[31m0.0963\u001b[0m  0.4616\n",
      "     10             \u001b[36m0.9687\u001b[0m        \u001b[32m0.0698\u001b[0m       \u001b[35m0.9753\u001b[0m        \u001b[31m0.0792\u001b[0m  0.4556\n",
      "     11             0.9651        \u001b[32m0.0524\u001b[0m       0.9721        0.0846  0.4655\n",
      "     12             0.9680        0.0535       0.9753        0.0873  0.4801\n",
      "     13             0.9687        \u001b[32m0.0427\u001b[0m       \u001b[35m0.9757\u001b[0m        0.0815  0.4892\n",
      "     14             0.9537        \u001b[32m0.0340\u001b[0m       0.9624        0.1178  0.4820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15             \u001b[36m0.9735\u001b[0m        0.0435       \u001b[35m0.9794\u001b[0m        \u001b[31m0.0762\u001b[0m  0.4828\n",
      "     16             0.9640        \u001b[32m0.0304\u001b[0m       0.9711        0.0833  0.4672\n",
      "     17             \u001b[36m0.9736\u001b[0m        \u001b[32m0.0271\u001b[0m       0.9794        \u001b[31m0.0723\u001b[0m  0.4865\n",
      "     18             0.9717        \u001b[32m0.0179\u001b[0m       0.9776        0.0813  0.4692\n",
      "     19             \u001b[36m0.9774\u001b[0m        \u001b[32m0.0127\u001b[0m       \u001b[35m0.9821\u001b[0m        \u001b[31m0.0662\u001b[0m  0.4776\n",
      "     20             0.9771        \u001b[32m0.0099\u001b[0m       0.9821        0.0706  0.4704\n",
      "     21             0.9755        \u001b[32m0.0099\u001b[0m       0.9808        0.0696  0.4794\n",
      "     22             0.9766        \u001b[32m0.0081\u001b[0m       0.9817        0.0718  0.4560\n",
      "     23             0.9724        \u001b[32m0.0064\u001b[0m       0.9780        0.0809  0.4488\n",
      "     24             0.9774        \u001b[32m0.0042\u001b[0m       0.9821        0.0703  0.4481\n",
      "     25             0.9757        \u001b[32m0.0030\u001b[0m       0.9808        0.0749  0.4512\n",
      "     26             0.9740        0.0036       0.9794        0.0821  0.4498\n",
      "     27             \u001b[36m0.9790\u001b[0m        0.0060       \u001b[35m0.9835\u001b[0m        0.0779  0.4502\n",
      "Epoch 00028: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     28             0.9778        0.0035       0.9826        0.0765  0.4639\n",
      "     29             0.9785        \u001b[32m0.0024\u001b[0m       0.9831        0.0775  0.4734\n",
      "     30             0.9779        \u001b[32m0.0019\u001b[0m       0.9826        0.0772  0.4514\n",
      "     31             0.9785        0.0022       0.9831        0.0765  0.4464\n",
      "     32             \u001b[36m0.9791\u001b[0m        \u001b[32m0.0018\u001b[0m       0.9835        0.0764  0.4461\n",
      "     33             0.9768        \u001b[32m0.0017\u001b[0m       0.9817        0.0762  0.4468\n",
      "     34             0.9768        0.0018       0.9817        0.0764  0.4474\n",
      "     35             0.9774        \u001b[32m0.0016\u001b[0m       0.9821        0.0765  0.4473\n",
      "     36             0.9780        0.0019       0.9826        0.0768  0.4535\n",
      "     37             0.9768        0.0021       0.9817        0.0770  0.4514\n",
      "Epoch 00038: reducing learning rate of group 0 to 2.0000e-06.\n",
      "     38             0.9780        0.0017       0.9826        0.0784  0.4511\n",
      "     39             0.9774        0.0019       0.9821        0.0778  0.4454\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 3/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.985) f1_score: (test=0.981) total time=  18.6s\n",
      "[CV 3/4; 3/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.2135\u001b[0m        \u001b[32m0.5241\u001b[0m       \u001b[35m0.2707\u001b[0m        \u001b[31m0.7479\u001b[0m  0.4497\n",
      "      2             \u001b[36m0.7966\u001b[0m        \u001b[32m0.4200\u001b[0m       \u001b[35m0.8273\u001b[0m        \u001b[31m0.4420\u001b[0m  0.4490\n",
      "      3             \u001b[36m0.8847\u001b[0m        \u001b[32m0.2944\u001b[0m       \u001b[35m0.9111\u001b[0m        \u001b[31m0.2324\u001b[0m  0.4591\n",
      "      4             \u001b[36m0.9328\u001b[0m        \u001b[32m0.1936\u001b[0m       \u001b[35m0.9478\u001b[0m        \u001b[31m0.1513\u001b[0m  0.4626\n",
      "      5             \u001b[36m0.9420\u001b[0m        \u001b[32m0.1351\u001b[0m       \u001b[35m0.9546\u001b[0m        \u001b[31m0.1231\u001b[0m  0.4545\n",
      "      6             \u001b[36m0.9576\u001b[0m        \u001b[32m0.0954\u001b[0m       \u001b[35m0.9666\u001b[0m        \u001b[31m0.1012\u001b[0m  0.4524\n",
      "      7             \u001b[36m0.9656\u001b[0m        \u001b[32m0.0733\u001b[0m       \u001b[35m0.9730\u001b[0m        \u001b[31m0.0867\u001b[0m  0.4527\n",
      "      8             0.9640        \u001b[32m0.0570\u001b[0m       0.9716        \u001b[31m0.0809\u001b[0m  0.4551\n",
      "      9             0.9565        \u001b[32m0.0416\u001b[0m       0.9652        0.0907  0.4517\n",
      "     10             \u001b[36m0.9658\u001b[0m        \u001b[32m0.0369\u001b[0m       0.9730        0.0825  0.4497\n",
      "     11             0.9507        \u001b[32m0.0318\u001b[0m       0.9601        0.1051  0.4575\n",
      "     12             \u001b[36m0.9720\u001b[0m        \u001b[32m0.0252\u001b[0m       \u001b[35m0.9780\u001b[0m        \u001b[31m0.0729\u001b[0m  0.4530\n",
      "     13             0.9713        \u001b[32m0.0156\u001b[0m       0.9776        0.0745  0.4533\n",
      "     14             0.9720        \u001b[32m0.0145\u001b[0m       0.9780        0.0739  0.4519\n",
      "     15             \u001b[36m0.9733\u001b[0m        \u001b[32m0.0111\u001b[0m       \u001b[35m0.9789\u001b[0m        0.0805  0.4533\n",
      "     16             \u001b[36m0.9755\u001b[0m        \u001b[32m0.0096\u001b[0m       \u001b[35m0.9808\u001b[0m        0.0759  0.4491\n",
      "     17             0.9711        \u001b[32m0.0075\u001b[0m       0.9771        0.0834  0.4589\n",
      "     18             \u001b[36m0.9761\u001b[0m        0.0077       \u001b[35m0.9812\u001b[0m        0.0844  0.4578\n",
      "     19             0.9754        \u001b[32m0.0048\u001b[0m       0.9808        0.0850  0.4528\n",
      "     20             0.9755        \u001b[32m0.0037\u001b[0m       0.9808        0.0819  0.4504\n",
      "     21             0.9734        0.0053       0.9789        0.0845  0.4708\n",
      "     22             0.9749        0.0051       0.9803        0.0840  0.4510\n",
      "Epoch 00023: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     23             0.9722        0.0042       0.9780        0.0888  0.4500\n",
      "     24             \u001b[36m0.9784\u001b[0m        \u001b[32m0.0027\u001b[0m       \u001b[35m0.9831\u001b[0m        0.0857  0.4487\n",
      "     25             0.9784        \u001b[32m0.0017\u001b[0m       0.9831        0.0854  0.4484\n",
      "     26             0.9772        0.0019       0.9821        0.0820  0.4481\n",
      "     27             0.9778        \u001b[32m0.0015\u001b[0m       0.9826        0.0832  0.4487\n",
      "     28             0.9778        \u001b[32m0.0013\u001b[0m       0.9826        0.0858  0.4495\n",
      "     29             \u001b[36m0.9790\u001b[0m        \u001b[32m0.0012\u001b[0m       \u001b[35m0.9835\u001b[0m        0.0829  0.4501\n",
      "     30             0.9784        \u001b[32m0.0011\u001b[0m       0.9831        0.0832  0.4490\n",
      "     31             0.9783        0.0012       0.9831        0.0834  0.4512\n",
      "     32             0.9778        0.0012       0.9826        0.0855  0.4497\n",
      "Epoch 00033: reducing learning rate of group 0 to 2.0000e-06.\n",
      "     33             0.9778        0.0014       0.9826        0.0836  0.4520\n",
      "     34             0.9784        0.0014       0.9831        0.0856  0.4658\n",
      "     35             0.9778        0.0012       0.9826        0.0857  0.4494\n",
      "Epoch 00036: reducing learning rate of group 0 to 1.0000e-06.\n",
      "     36             0.9778        0.0011       0.9826        0.0847  0.4499\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 3/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.980) f1_score: (test=0.975) total time=  16.9s\n",
      "[CV 4/4; 3/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4210\u001b[0m        \u001b[32m0.5389\u001b[0m       \u001b[35m0.7270\u001b[0m        \u001b[31m0.6283\u001b[0m  0.4517\n",
      "      2             \u001b[36m0.8018\u001b[0m        \u001b[32m0.4239\u001b[0m       \u001b[35m0.8369\u001b[0m        \u001b[31m0.4076\u001b[0m  0.4525\n",
      "      3             \u001b[36m0.8881\u001b[0m        \u001b[32m0.2984\u001b[0m       \u001b[35m0.9125\u001b[0m        \u001b[31m0.2418\u001b[0m  0.4620\n",
      "      4             \u001b[36m0.9223\u001b[0m        \u001b[32m0.2046\u001b[0m       \u001b[35m0.9404\u001b[0m        \u001b[31m0.1755\u001b[0m  0.4590\n",
      "      5             \u001b[36m0.9349\u001b[0m        \u001b[32m0.1433\u001b[0m       \u001b[35m0.9478\u001b[0m        \u001b[31m0.1381\u001b[0m  0.4501\n",
      "      6             \u001b[36m0.9591\u001b[0m        \u001b[32m0.0966\u001b[0m       \u001b[35m0.9684\u001b[0m        \u001b[31m0.1016\u001b[0m  0.4576\n",
      "      7             \u001b[36m0.9609\u001b[0m        \u001b[32m0.0671\u001b[0m       \u001b[35m0.9698\u001b[0m        \u001b[31m0.0846\u001b[0m  0.4591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8             \u001b[36m0.9681\u001b[0m        \u001b[32m0.0452\u001b[0m       \u001b[35m0.9748\u001b[0m        \u001b[31m0.0730\u001b[0m  0.4618\n",
      "      9             \u001b[36m0.9701\u001b[0m        \u001b[32m0.0372\u001b[0m       \u001b[35m0.9766\u001b[0m        \u001b[31m0.0712\u001b[0m  0.4576\n",
      "     10             \u001b[36m0.9725\u001b[0m        \u001b[32m0.0273\u001b[0m       \u001b[35m0.9785\u001b[0m        \u001b[31m0.0632\u001b[0m  0.4553\n",
      "     11             \u001b[36m0.9743\u001b[0m        \u001b[32m0.0237\u001b[0m       \u001b[35m0.9798\u001b[0m        0.0661  0.4700\n",
      "     12             0.9716        \u001b[32m0.0167\u001b[0m       0.9776        0.0659  0.4686\n",
      "     13             \u001b[36m0.9790\u001b[0m        \u001b[32m0.0124\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0617\u001b[0m  0.4483\n",
      "     14             0.9778        \u001b[32m0.0076\u001b[0m       0.9826        0.0626  0.4475\n",
      "     15             0.9756        \u001b[32m0.0061\u001b[0m       0.9808        0.0640  0.4530\n",
      "     16             0.9784        \u001b[32m0.0037\u001b[0m       0.9831        0.0662  0.4482\n",
      "     17             0.9784        \u001b[32m0.0035\u001b[0m       0.9831        0.0640  0.4494\n",
      "     18             0.9777        \u001b[32m0.0023\u001b[0m       0.9826        0.0653  0.4546\n",
      "     19             \u001b[36m0.9796\u001b[0m        \u001b[32m0.0017\u001b[0m       \u001b[35m0.9840\u001b[0m        0.0653  0.4501\n",
      "     20             0.9713        0.0039       0.9776        0.0801  0.4485\n",
      "     21             0.9751        0.0076       0.9803        0.0675  0.4671\n",
      "Epoch 00022: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     22             0.9750        0.0076       0.9803        0.0713  0.4492\n",
      "     23             0.9789        0.0032       0.9835        0.0693  0.4769\n",
      "     24             0.9789        0.0021       0.9835        0.0689  0.4719\n",
      "     25             0.9777        \u001b[32m0.0015\u001b[0m       0.9826        0.0696  0.4777\n",
      "     26             0.9789        0.0016       0.9835        0.0689  0.4625\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 3/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.984) f1_score: (test=0.979) total time=  12.5s\n",
      "[CV 1/4; 4/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4440\u001b[0m        \u001b[32m0.4495\u001b[0m       \u001b[35m0.7041\u001b[0m        \u001b[31m0.6008\u001b[0m  0.7328\n",
      "      2             \u001b[36m0.8426\u001b[0m        \u001b[32m0.1992\u001b[0m       \u001b[35m0.8658\u001b[0m        \u001b[31m0.3097\u001b[0m  0.7364\n",
      "      3             \u001b[36m0.9663\u001b[0m        \u001b[32m0.0969\u001b[0m       \u001b[35m0.9730\u001b[0m        \u001b[31m0.0805\u001b[0m  0.7239\n",
      "      4             0.9655        \u001b[32m0.0533\u001b[0m       0.9730        \u001b[31m0.0752\u001b[0m  0.7307\n",
      "      5             \u001b[36m0.9790\u001b[0m        \u001b[32m0.0258\u001b[0m       \u001b[35m0.9831\u001b[0m        \u001b[31m0.0492\u001b[0m  0.7352\n",
      "      6             0.9637        \u001b[32m0.0244\u001b[0m       0.9702        0.0748  0.7320\n",
      "      7             \u001b[36m0.9845\u001b[0m        \u001b[32m0.0133\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0311\u001b[0m  0.7244\n",
      "      8             \u001b[36m0.9857\u001b[0m        \u001b[32m0.0084\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0298\u001b[0m  0.7257\n",
      "      9             \u001b[36m0.9874\u001b[0m        \u001b[32m0.0067\u001b[0m       \u001b[35m0.9899\u001b[0m        \u001b[31m0.0281\u001b[0m  0.7270\n",
      "     10             0.9869        \u001b[32m0.0035\u001b[0m       0.9895        0.0321  0.7349\n",
      "     11             0.9864        \u001b[32m0.0015\u001b[0m       0.9890        0.0334  0.7441\n",
      "     12             0.9791        0.0021       0.9835        0.0429  0.7320\n",
      "     13             0.9819        0.0026       0.9853        0.0519  0.7432\n",
      "Epoch 00014: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     14             0.9852        0.0101       0.9881        0.0548  0.7367\n",
      "     15             \u001b[36m0.9903\u001b[0m        0.0048       \u001b[35m0.9922\u001b[0m        \u001b[31m0.0271\u001b[0m  0.7296\n",
      "     16             0.9897        0.0017       0.9918        \u001b[31m0.0270\u001b[0m  0.7405\n",
      "     17             0.9886        \u001b[32m0.0012\u001b[0m       0.9908        \u001b[31m0.0265\u001b[0m  0.8202\n",
      "     18             0.9892        \u001b[32m0.0009\u001b[0m       0.9913        \u001b[31m0.0257\u001b[0m  0.7612\n",
      "     19             0.9892        \u001b[32m0.0008\u001b[0m       0.9913        \u001b[31m0.0251\u001b[0m  0.7305\n",
      "     20             0.9897        \u001b[32m0.0007\u001b[0m       0.9918        0.0253  0.7321\n",
      "     21             0.9892        \u001b[32m0.0007\u001b[0m       0.9913        0.0259  0.7516\n",
      "     22             \u001b[36m0.9903\u001b[0m        \u001b[32m0.0006\u001b[0m       0.9922        \u001b[31m0.0241\u001b[0m  0.7488\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 4/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.991) f1_score: (test=0.988) total time=  17.2s\n",
      "[CV 2/4; 4/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4342\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5648\u001b[0m  0.7618\n",
      "      2             \u001b[36m0.9090\u001b[0m        \u001b[32m0.1855\u001b[0m       \u001b[35m0.9272\u001b[0m        \u001b[31m0.1901\u001b[0m  0.7617\n",
      "      3             \u001b[36m0.9630\u001b[0m        \u001b[32m0.0792\u001b[0m       \u001b[35m0.9702\u001b[0m        \u001b[31m0.0874\u001b[0m  0.7490\n",
      "      4             \u001b[36m0.9684\u001b[0m        \u001b[32m0.0549\u001b[0m       \u001b[35m0.9748\u001b[0m        \u001b[31m0.0796\u001b[0m  0.7713\n",
      "      5             \u001b[36m0.9789\u001b[0m        \u001b[32m0.0316\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0513\u001b[0m  0.7617\n",
      "      6             \u001b[36m0.9791\u001b[0m        \u001b[32m0.0161\u001b[0m       0.9835        \u001b[31m0.0502\u001b[0m  0.7444\n",
      "      7             \u001b[36m0.9842\u001b[0m        \u001b[32m0.0101\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0457\u001b[0m  0.7265\n",
      "      8             \u001b[36m0.9849\u001b[0m        \u001b[32m0.0050\u001b[0m       \u001b[35m0.9881\u001b[0m        0.0483  0.7653\n",
      "      9             0.9791        0.0051       0.9835        0.0643  0.7339\n",
      "     10             0.9556        0.0181       0.9638        0.1029  0.7628\n",
      "Epoch 00011: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     11             0.9779        0.0155       0.9826        0.0575  0.7240\n",
      "     12             \u001b[36m0.9849\u001b[0m        0.0056       0.9881        \u001b[31m0.0430\u001b[0m  0.7301\n",
      "     13             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0019\u001b[0m       \u001b[35m0.9885\u001b[0m        0.0449  0.7338\n",
      "     14             0.9849        \u001b[32m0.0016\u001b[0m       0.9881        0.0431  0.7228\n",
      "     15             0.9849        \u001b[32m0.0012\u001b[0m       0.9881        0.0444  0.7230\n",
      "     16             0.9843        \u001b[32m0.0010\u001b[0m       0.9876        0.0446  0.7560\n",
      "     17             0.9855        \u001b[32m0.0010\u001b[0m       0.9885        0.0436  0.7238\n",
      "     18             0.9855        0.0011       0.9885        0.0431  0.7243\n",
      "     19             \u001b[36m0.9860\u001b[0m        \u001b[32m0.0008\u001b[0m       \u001b[35m0.9890\u001b[0m        0.0431  0.7390\n",
      "     20             0.9849        \u001b[32m0.0007\u001b[0m       0.9881        0.0435  0.7363\n",
      "     21             0.9849        \u001b[32m0.0006\u001b[0m       0.9881        0.0440  0.7770\n",
      "     22             0.9849        \u001b[32m0.0006\u001b[0m       0.9881        0.0438  0.7491\n",
      "     23             0.9849        \u001b[32m0.0006\u001b[0m       0.9881        0.0437  0.7237\n",
      "     24             0.9849        0.0006       0.9881        0.0436  0.7319\n",
      "     25             0.9849        \u001b[32m0.0005\u001b[0m       0.9881        0.0442  0.7601\n",
      "     26             0.9855        \u001b[32m0.0005\u001b[0m       0.9885        0.0435  0.7764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 4/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.989) f1_score: (test=0.987) total time=  20.3s\n",
      "[CV 3/4; 4/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4078\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5722\u001b[0m  0.7508\n",
      "      2             \u001b[36m0.8848\u001b[0m        \u001b[32m0.1705\u001b[0m       \u001b[35m0.9107\u001b[0m        \u001b[31m0.2160\u001b[0m  0.7430\n",
      "      3             \u001b[36m0.9571\u001b[0m        \u001b[32m0.0759\u001b[0m       \u001b[35m0.9670\u001b[0m        \u001b[31m0.0918\u001b[0m  0.7282\n",
      "      4             \u001b[36m0.9662\u001b[0m        \u001b[32m0.0430\u001b[0m       \u001b[35m0.9739\u001b[0m        \u001b[31m0.0739\u001b[0m  0.7520\n",
      "      5             \u001b[36m0.9755\u001b[0m        \u001b[32m0.0375\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0576\u001b[0m  0.7362\n",
      "      6             0.9746        \u001b[32m0.0196\u001b[0m       0.9803        0.0584  0.7689\n",
      "      7             \u001b[36m0.9813\u001b[0m        0.0293       \u001b[35m0.9853\u001b[0m        \u001b[31m0.0537\u001b[0m  0.7422\n",
      "      8             0.9639        \u001b[32m0.0150\u001b[0m       0.9721        0.0981  0.7226\n",
      "      9             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0129\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0410\u001b[0m  0.7236\n",
      "     10             0.9831        \u001b[32m0.0047\u001b[0m       0.9867        0.0479  0.7451\n",
      "     11             0.9849        \u001b[32m0.0021\u001b[0m       0.9881        0.0438  0.7259\n",
      "     12             \u001b[36m0.9860\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9890\u001b[0m        0.0426  0.7385\n",
      "     13             \u001b[36m0.9860\u001b[0m        \u001b[32m0.0004\u001b[0m       0.9890        0.0429  0.7704\n",
      "     14             0.9855        \u001b[32m0.0003\u001b[0m       0.9885        0.0432  0.7527\n",
      "     15             \u001b[36m0.9872\u001b[0m        \u001b[32m0.0002\u001b[0m       \u001b[35m0.9899\u001b[0m        0.0437  0.7468\n",
      "     16             0.9855        \u001b[32m0.0002\u001b[0m       0.9885        0.0446  0.7640\n",
      "     17             0.9855        \u001b[32m0.0001\u001b[0m       0.9885        0.0453  0.7701\n",
      "     18             0.9860        0.0002       0.9890        0.0452  0.7816\n",
      "     19             0.9855        \u001b[32m0.0001\u001b[0m       0.9885        0.0448  0.7645\n",
      "     20             0.9866        \u001b[32m0.0001\u001b[0m       0.9895        0.0447  0.7589\n",
      "     21             0.9860        \u001b[32m0.0001\u001b[0m       0.9890        0.0459  0.7572\n",
      "     22             0.9854        0.0001       0.9885        0.0470  0.7810\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 4/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.990) f1_score: (test=0.988) total time=  17.5s\n",
      "[CV 4/4; 4/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4190\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5778\u001b[0m  0.7940\n",
      "      2             \u001b[36m0.7976\u001b[0m        \u001b[32m0.1550\u001b[0m       \u001b[35m0.8676\u001b[0m        \u001b[31m0.3031\u001b[0m  0.7588\n",
      "      3             \u001b[36m0.9611\u001b[0m        \u001b[32m0.0752\u001b[0m       \u001b[35m0.9702\u001b[0m        \u001b[31m0.0917\u001b[0m  0.7240\n",
      "      4             \u001b[36m0.9659\u001b[0m        \u001b[32m0.0412\u001b[0m       \u001b[35m0.9725\u001b[0m        \u001b[31m0.0722\u001b[0m  0.7256\n",
      "      5             \u001b[36m0.9754\u001b[0m        \u001b[32m0.0240\u001b[0m       \u001b[35m0.9803\u001b[0m        \u001b[31m0.0564\u001b[0m  0.7261\n",
      "      6             0.9737        \u001b[32m0.0131\u001b[0m       0.9789        0.0673  0.7260\n",
      "      7             0.9703        \u001b[32m0.0121\u001b[0m       0.9771        0.0730  0.7263\n",
      "      8             \u001b[36m0.9843\u001b[0m        \u001b[32m0.0103\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0453\u001b[0m  0.7260\n",
      "      9             \u001b[36m0.9849\u001b[0m        \u001b[32m0.0058\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0430\u001b[0m  0.7250\n",
      "     10             \u001b[36m0.9877\u001b[0m        \u001b[32m0.0035\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0396\u001b[0m  0.7248\n",
      "     11             0.9782        0.0040       0.9831        0.0626  0.7246\n",
      "     12             0.9832        \u001b[32m0.0013\u001b[0m       0.9867        0.0435  0.7250\n",
      "     13             0.9866        \u001b[32m0.0005\u001b[0m       0.9895        \u001b[31m0.0383\u001b[0m  0.7257\n",
      "     14             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0003\u001b[0m       0.9904        \u001b[31m0.0372\u001b[0m  0.7250\n",
      "     15             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0002\u001b[0m       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0358\u001b[0m  0.7312\n",
      "     16             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0001\u001b[0m       0.9908        0.0365  0.7285\n",
      "     17             0.9884        0.0001       0.9908        0.0358  0.7265\n",
      "     18             \u001b[36m0.9895\u001b[0m        0.0001       \u001b[35m0.9918\u001b[0m        0.0363  0.7244\n",
      "     19             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0001\u001b[0m       0.9918        0.0366  0.7244\n",
      "     20             0.9895        \u001b[32m0.0001\u001b[0m       0.9918        0.0364  0.7251\n",
      "     21             \u001b[36m0.9907\u001b[0m        \u001b[32m0.0001\u001b[0m       \u001b[35m0.9927\u001b[0m        0.0366  0.7247\n",
      "     22             0.9895        \u001b[32m0.0001\u001b[0m       0.9918        0.0365  0.7245\n",
      "     23             0.9901        \u001b[32m0.0001\u001b[0m       0.9922        0.0367  0.7249\n",
      "     24             0.9901        \u001b[32m0.0001\u001b[0m       0.9922        0.0370  0.7259\n",
      "     25             0.9901        0.0001       0.9922        0.0373  0.7247\n",
      "     26             \u001b[36m0.9907\u001b[0m        \u001b[32m0.0000\u001b[0m       0.9927        0.0372  0.7252\n",
      "     27             0.9895        0.0001       0.9918        0.0370  0.7255\n",
      "     28             \u001b[36m0.9913\u001b[0m        0.0001       \u001b[35m0.9931\u001b[0m        0.0367  0.7250\n",
      "Epoch 00029: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     29             0.9913        0.0000       0.9931        0.0368  0.7247\n",
      "     30             0.9913        \u001b[32m0.0000\u001b[0m       0.9931        0.0371  0.7254\n",
      "     31             0.9913        0.0001       0.9931        0.0371  0.7254\n",
      "     32             0.9907        \u001b[32m0.0000\u001b[0m       0.9927        0.0373  0.7258\n",
      "     33             \u001b[36m0.9919\u001b[0m        0.0000       \u001b[35m0.9936\u001b[0m        0.0373  0.7258\n",
      "     34             0.9919        0.0001       0.9936        0.0372  0.7250\n",
      "     35             0.9907        \u001b[32m0.0000\u001b[0m       0.9927        0.0375  0.7256\n",
      "     36             0.9913        0.0000       0.9931        0.0376  0.7249\n",
      "     37             \u001b[36m0.9924\u001b[0m        \u001b[32m0.0000\u001b[0m       \u001b[35m0.9940\u001b[0m        0.0371  0.7251\n",
      "     38             0.9913        \u001b[32m0.0000\u001b[0m       0.9931        0.0371  0.7252\n",
      "     39             0.9913        0.0000       0.9931        0.0373  0.7251\n",
      "     40             0.9913        0.0000       0.9931        0.0373  0.7247\n",
      "Epoch 00041: reducing learning rate of group 0 to 2.0000e-06.\n",
      "     41             0.9913        0.0000       0.9931        0.0375  0.7254\n",
      "     42             0.9919        0.0000       0.9936        0.0373  0.7251\n",
      "     43             0.9919        0.0000       0.9936        0.0374  0.7245\n",
      "Epoch 00044: reducing learning rate of group 0 to 1.0000e-06.\n",
      "     44             0.9907        0.0000       0.9927        0.0377  0.7252\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 4/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.992) f1_score: (test=0.990) total time=  33.0s\n",
      "[CV 1/4; 5/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4185\u001b[0m        \u001b[32m0.4217\u001b[0m       \u001b[35m0.7197\u001b[0m        \u001b[31m0.6959\u001b[0m  0.7169\n",
      "      2             \u001b[36m0.7135\u001b[0m        \u001b[32m0.2029\u001b[0m       \u001b[35m0.8227\u001b[0m        \u001b[31m0.5779\u001b[0m  0.7171\n",
      "      3             \u001b[36m0.9112\u001b[0m        \u001b[32m0.1379\u001b[0m       \u001b[35m0.9317\u001b[0m        \u001b[31m0.2143\u001b[0m  0.7186\n",
      "      4             \u001b[36m0.9147\u001b[0m        \u001b[32m0.0987\u001b[0m       \u001b[35m0.9350\u001b[0m        \u001b[31m0.1776\u001b[0m  0.7179\n",
      "      5             \u001b[36m0.9694\u001b[0m        \u001b[32m0.0677\u001b[0m       \u001b[35m0.9753\u001b[0m        \u001b[31m0.0599\u001b[0m  0.7180\n",
      "      6             \u001b[36m0.9715\u001b[0m        \u001b[32m0.0388\u001b[0m       \u001b[35m0.9771\u001b[0m        0.0716  0.7176\n",
      "      7             0.8827        \u001b[32m0.0339\u001b[0m       0.9153        0.3685  0.7180\n",
      "      8             0.9695        0.0367       0.9762        0.0774  0.7179\n",
      "      9             0.9678        0.0539       0.9739        0.0704  0.7176\n",
      "Epoch 00010: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     10             \u001b[36m0.9733\u001b[0m        0.0482       \u001b[35m0.9785\u001b[0m        \u001b[31m0.0542\u001b[0m  0.7173\n",
      "     11             \u001b[36m0.9891\u001b[0m        \u001b[32m0.0162\u001b[0m       \u001b[35m0.9913\u001b[0m        \u001b[31m0.0220\u001b[0m  0.7173\n",
      "     12             \u001b[36m0.9914\u001b[0m        \u001b[32m0.0096\u001b[0m       \u001b[35m0.9931\u001b[0m        \u001b[31m0.0184\u001b[0m  0.7190\n",
      "     13             0.9908        \u001b[32m0.0073\u001b[0m       0.9927        0.0185  0.7171\n",
      "     14             \u001b[36m0.9920\u001b[0m        \u001b[32m0.0065\u001b[0m       \u001b[35m0.9936\u001b[0m        \u001b[31m0.0167\u001b[0m  0.7170\n",
      "     15             0.9914        \u001b[32m0.0052\u001b[0m       0.9931        0.0175  0.7175\n",
      "     16             \u001b[36m0.9925\u001b[0m        \u001b[32m0.0045\u001b[0m       \u001b[35m0.9940\u001b[0m        0.0173  0.7170\n",
      "     17             0.9925        \u001b[32m0.0040\u001b[0m       0.9940        \u001b[31m0.0164\u001b[0m  0.7167\n",
      "     18             0.9920        \u001b[32m0.0036\u001b[0m       0.9936        0.0174  0.7170\n",
      "     19             0.9925        \u001b[32m0.0034\u001b[0m       0.9940        0.0180  0.7169\n",
      "     20             0.9925        \u001b[32m0.0030\u001b[0m       0.9940        0.0173  0.7169\n",
      "     21             0.9925        \u001b[32m0.0025\u001b[0m       0.9940        \u001b[31m0.0163\u001b[0m  0.7168\n",
      "     22             \u001b[36m0.9931\u001b[0m        0.0027       \u001b[35m0.9945\u001b[0m        \u001b[31m0.0158\u001b[0m  0.7172\n",
      "     23             0.9931        \u001b[32m0.0020\u001b[0m       0.9945        0.0166  0.7168\n",
      "     24             \u001b[36m0.9937\u001b[0m        0.0021       \u001b[35m0.9950\u001b[0m        0.0164  0.7173\n",
      "     25             0.9931        \u001b[32m0.0016\u001b[0m       0.9945        0.0160  0.7178\n",
      "     26             0.9931        \u001b[32m0.0015\u001b[0m       0.9945        0.0163  0.7187\n",
      "     27             0.9925        0.0017       0.9940        0.0167  0.7186\n",
      "     28             0.9937        \u001b[32m0.0014\u001b[0m       0.9950        \u001b[31m0.0154\u001b[0m  0.7180\n",
      "     29             0.9931        0.0015       0.9945        0.0177  0.7173\n",
      "     30             0.9931        \u001b[32m0.0013\u001b[0m       0.9945        0.0158  0.7186\n",
      "     31             0.9931        \u001b[32m0.0011\u001b[0m       0.9945        0.0170  0.7180\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 5/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.992) f1_score: (test=0.990) total time=  23.2s\n",
      "[CV 2/4; 5/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4468\u001b[0m        \u001b[32m0.3890\u001b[0m       \u001b[35m0.6409\u001b[0m        \u001b[31m0.6536\u001b[0m  0.7171\n",
      "      2             \u001b[36m0.8565\u001b[0m        \u001b[32m0.2054\u001b[0m       \u001b[35m0.8882\u001b[0m        \u001b[31m0.2641\u001b[0m  0.7179\n",
      "      3             \u001b[36m0.9334\u001b[0m        \u001b[32m0.1092\u001b[0m       \u001b[35m0.9450\u001b[0m        \u001b[31m0.1436\u001b[0m  0.7178\n",
      "      4             \u001b[36m0.9541\u001b[0m        \u001b[32m0.1025\u001b[0m       \u001b[35m0.9629\u001b[0m        \u001b[31m0.0937\u001b[0m  0.7179\n",
      "      5             0.9467        \u001b[32m0.0689\u001b[0m       0.9565        0.1178  0.7186\n",
      "      6             0.9099        \u001b[32m0.0424\u001b[0m       0.9345        0.2012  0.7480\n",
      "      7             \u001b[36m0.9699\u001b[0m        \u001b[32m0.0296\u001b[0m       \u001b[35m0.9762\u001b[0m        \u001b[31m0.0637\u001b[0m  0.7303\n",
      "      8             0.9428        \u001b[32m0.0197\u001b[0m       0.9569        0.1605  0.7901\n",
      "      9             0.9618        0.0339       0.9707        0.1105  0.8031\n",
      "     10             0.9620        0.0306       0.9693        0.0948  0.7263\n",
      "Epoch 00011: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     11             0.9585        0.0270       0.9666        0.1330  0.7906\n",
      "     12             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0111\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0333\u001b[0m  0.7996\n",
      "     13             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0037\u001b[0m       \u001b[35m0.9922\u001b[0m        \u001b[31m0.0282\u001b[0m  0.7934\n",
      "     14             0.9895        \u001b[32m0.0028\u001b[0m       0.9918        0.0299  0.8025\n",
      "     15             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0022\u001b[0m       0.9922        0.0291  0.8055\n",
      "     16             0.9889        \u001b[32m0.0021\u001b[0m       0.9913        0.0309  0.7436\n",
      "     17             0.9895        \u001b[32m0.0017\u001b[0m       0.9918        0.0306  0.8094\n",
      "     18             0.9895        \u001b[32m0.0016\u001b[0m       0.9918        0.0306  0.7795\n",
      "     19             0.9895        \u001b[32m0.0015\u001b[0m       0.9918        0.0305  0.7240\n",
      "     20             0.9895        \u001b[32m0.0012\u001b[0m       0.9918        0.0306  0.7315\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 5/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.995) f1_score: (test=0.994) total time=  16.1s\n",
      "[CV 3/4; 5/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.3615\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m1.2329\u001b[0m  0.7809\n",
      "      2             \u001b[36m0.8862\u001b[0m        \u001b[32m0.1474\u001b[0m       \u001b[35m0.9056\u001b[0m        \u001b[31m0.2214\u001b[0m  0.8060\n",
      "      3             \u001b[36m0.9410\u001b[0m        0.1536       \u001b[35m0.9519\u001b[0m        \u001b[31m0.1279\u001b[0m  0.7766\n",
      "      4             \u001b[36m0.9709\u001b[0m        \u001b[32m0.0760\u001b[0m       \u001b[35m0.9771\u001b[0m        \u001b[31m0.0687\u001b[0m  0.7462\n",
      "      5             0.9622        \u001b[32m0.0478\u001b[0m       0.9698        0.1040  0.7435\n",
      "      6             0.9161        0.0529       0.9382        0.1722  0.7322\n",
      "      7             \u001b[36m0.9741\u001b[0m        0.0573       \u001b[35m0.9798\u001b[0m        \u001b[31m0.0644\u001b[0m  0.7529\n",
      "      8             \u001b[36m0.9778\u001b[0m        \u001b[32m0.0291\u001b[0m       \u001b[35m0.9826\u001b[0m        \u001b[31m0.0613\u001b[0m  0.7472\n",
      "      9             0.9498        0.0438       0.9588        0.1149  0.7843\n",
      "     10             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0179\u001b[0m       \u001b[35m0.9918\u001b[0m        \u001b[31m0.0399\u001b[0m  0.7902\n",
      "     11             0.9635        \u001b[32m0.0141\u001b[0m       0.9707        0.0941  0.7565\n",
      "     12             0.9830        \u001b[32m0.0104\u001b[0m       0.9867        0.0610  0.7200\n",
      "     13             0.9711        0.0228       0.9776        0.0860  0.7209\n",
      "     14             0.9698        0.0350       0.9766        0.1104  0.7258\n",
      "Epoch 00015: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     15             0.9848        0.0130       0.9881        0.0525  0.7523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0059\u001b[0m       \u001b[35m0.9922\u001b[0m        \u001b[31m0.0327\u001b[0m  0.7241\n",
      "     17             \u001b[36m0.9913\u001b[0m        \u001b[32m0.0022\u001b[0m       \u001b[35m0.9931\u001b[0m        \u001b[31m0.0316\u001b[0m  0.7220\n",
      "     18             0.9913        \u001b[32m0.0017\u001b[0m       0.9931        \u001b[31m0.0310\u001b[0m  0.7232\n",
      "     19             0.9901        \u001b[32m0.0015\u001b[0m       0.9922        \u001b[31m0.0308\u001b[0m  0.7227\n",
      "     20             \u001b[36m0.9918\u001b[0m        \u001b[32m0.0012\u001b[0m       \u001b[35m0.9936\u001b[0m        0.0309  0.7388\n",
      "     21             0.9913        \u001b[32m0.0010\u001b[0m       0.9931        0.0308  0.7385\n",
      "     22             0.9918        \u001b[32m0.0009\u001b[0m       0.9936        0.0310  0.7263\n",
      "     23             0.9918        \u001b[32m0.0009\u001b[0m       0.9936        0.0309  0.7264\n",
      "     24             0.9907        \u001b[32m0.0007\u001b[0m       0.9927        0.0313  0.7246\n",
      "     25             0.9907        0.0008       0.9927        0.0315  0.7259\n",
      "     26             0.9907        \u001b[32m0.0007\u001b[0m       0.9927        0.0317  0.7240\n",
      "     27             0.9907        \u001b[32m0.0006\u001b[0m       0.9927        0.0315  0.7553\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 5/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.995) f1_score: (test=0.993) total time=  21.0s\n",
      "[CV 4/4; 5/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.3711\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.9434\u001b[0m  0.7221\n",
      "      2             \u001b[36m0.7902\u001b[0m        \u001b[32m0.1672\u001b[0m       \u001b[35m0.8204\u001b[0m        \u001b[31m0.4047\u001b[0m  0.7238\n",
      "      3             \u001b[36m0.9461\u001b[0m        \u001b[32m0.1263\u001b[0m       \u001b[35m0.9583\u001b[0m        \u001b[31m0.1161\u001b[0m  0.7428\n",
      "      4             \u001b[36m0.9696\u001b[0m        \u001b[32m0.0827\u001b[0m       \u001b[35m0.9762\u001b[0m        \u001b[31m0.0788\u001b[0m  0.7470\n",
      "      5             \u001b[36m0.9732\u001b[0m        \u001b[32m0.0468\u001b[0m       \u001b[35m0.9785\u001b[0m        \u001b[31m0.0632\u001b[0m  0.7234\n",
      "      6             0.9732        \u001b[32m0.0301\u001b[0m       0.9785        0.0691  0.7473\n",
      "      7             \u001b[36m0.9732\u001b[0m        0.0383       \u001b[35m0.9789\u001b[0m        0.0873  0.7246\n",
      "      8             0.9548        0.0374       0.9647        0.1498  0.7437\n",
      "Epoch 00009: reducing learning rate of group 0 to 8.0000e-05.\n",
      "      9             0.9412        0.0396       0.9556        0.1442  0.7223\n",
      "     10             \u001b[36m0.9883\u001b[0m        \u001b[32m0.0214\u001b[0m       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0346\u001b[0m  0.7220\n",
      "     11             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0072\u001b[0m       \u001b[35m0.9922\u001b[0m        \u001b[31m0.0302\u001b[0m  0.7219\n",
      "     12             0.9901        \u001b[32m0.0052\u001b[0m       0.9922        0.0302  0.7219\n",
      "     13             0.9895        \u001b[32m0.0038\u001b[0m       0.9918        \u001b[31m0.0295\u001b[0m  0.7218\n",
      "     14             \u001b[36m0.9919\u001b[0m        \u001b[32m0.0035\u001b[0m       \u001b[35m0.9936\u001b[0m        \u001b[31m0.0294\u001b[0m  0.7229\n",
      "     15             0.9919        \u001b[32m0.0030\u001b[0m       0.9936        \u001b[31m0.0293\u001b[0m  0.7213\n",
      "     16             \u001b[36m0.9924\u001b[0m        \u001b[32m0.0026\u001b[0m       \u001b[35m0.9940\u001b[0m        0.0296  0.7230\n",
      "     17             0.9907        0.0027       0.9927        0.0298  0.7211\n",
      "     18             0.9918        \u001b[32m0.0021\u001b[0m       0.9936        0.0296  0.7256\n",
      "     19             0.9918        \u001b[32m0.0021\u001b[0m       0.9936        \u001b[31m0.0288\u001b[0m  0.7430\n",
      "     20             0.9918        \u001b[32m0.0020\u001b[0m       0.9936        0.0289  0.7272\n",
      "     21             0.9924        \u001b[32m0.0016\u001b[0m       0.9940        0.0290  0.7237\n",
      "     22             0.9918        \u001b[32m0.0014\u001b[0m       0.9936        0.0292  0.7251\n",
      "     23             0.9924        \u001b[32m0.0014\u001b[0m       0.9940        0.0292  0.7228\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 5/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.993) f1_score: (test=0.992) total time=  17.6s\n",
      "[CV 1/4; 6/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4199\u001b[0m        \u001b[32m0.4508\u001b[0m       \u001b[35m0.7238\u001b[0m        \u001b[31m0.5850\u001b[0m  1.2853\n",
      "      2             \u001b[36m0.8766\u001b[0m        \u001b[32m0.2114\u001b[0m       \u001b[35m0.9043\u001b[0m        \u001b[31m0.2281\u001b[0m  1.2995\n",
      "      3             \u001b[36m0.9605\u001b[0m        \u001b[32m0.1063\u001b[0m       \u001b[35m0.9689\u001b[0m        \u001b[31m0.0853\u001b[0m  1.2998\n",
      "      4             \u001b[36m0.9685\u001b[0m        \u001b[32m0.0665\u001b[0m       \u001b[35m0.9743\u001b[0m        \u001b[31m0.0743\u001b[0m  1.2958\n",
      "      5             \u001b[36m0.9723\u001b[0m        \u001b[32m0.0473\u001b[0m       \u001b[35m0.9776\u001b[0m        \u001b[31m0.0626\u001b[0m  1.2748\n",
      "      6             0.9713        \u001b[32m0.0376\u001b[0m       0.9766        0.0649  1.2890\n",
      "      7             \u001b[36m0.9835\u001b[0m        \u001b[32m0.0240\u001b[0m       \u001b[35m0.9867\u001b[0m        \u001b[31m0.0398\u001b[0m  1.3068\n",
      "      8             \u001b[36m0.9839\u001b[0m        \u001b[32m0.0128\u001b[0m       \u001b[35m0.9872\u001b[0m        0.0454  1.2952\n",
      "      9             \u001b[36m0.9851\u001b[0m        \u001b[32m0.0073\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0394\u001b[0m  1.2880\n",
      "     10             \u001b[36m0.9862\u001b[0m        \u001b[32m0.0061\u001b[0m       \u001b[35m0.9890\u001b[0m        0.0401  1.3032\n",
      "     11             \u001b[36m0.9886\u001b[0m        \u001b[32m0.0040\u001b[0m       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0357\u001b[0m  1.2813\n",
      "     12             0.9862        \u001b[32m0.0031\u001b[0m       0.9890        0.0372  1.3360\n",
      "     13             0.9858        \u001b[32m0.0021\u001b[0m       0.9885        0.0375  1.3697\n",
      "     14             0.9857        0.0024       0.9885        0.0413  1.4004\n",
      "     15             0.9857        \u001b[32m0.0019\u001b[0m       0.9885        0.0361  1.3151\n",
      "     16             0.9874        \u001b[32m0.0011\u001b[0m       0.9899        \u001b[31m0.0350\u001b[0m  1.3620\n",
      "     17             0.9880        \u001b[32m0.0007\u001b[0m       0.9904        \u001b[31m0.0345\u001b[0m  1.2933\n",
      "     18             0.9885        \u001b[32m0.0005\u001b[0m       0.9908        0.0377  1.2900\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 6/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.989) f1_score: (test=0.986) total time=  25.1s\n",
      "[CV 2/4; 6/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4297\u001b[0m        \u001b[32m0.4569\u001b[0m       \u001b[35m0.7206\u001b[0m        \u001b[31m0.5927\u001b[0m  1.3313\n",
      "      2             \u001b[36m0.8303\u001b[0m        \u001b[32m0.2505\u001b[0m       \u001b[35m0.8644\u001b[0m        \u001b[31m0.2922\u001b[0m  1.3221\n",
      "      3             \u001b[36m0.9643\u001b[0m        \u001b[32m0.1271\u001b[0m       \u001b[35m0.9716\u001b[0m        \u001b[31m0.0936\u001b[0m  1.2832\n",
      "      4             \u001b[36m0.9755\u001b[0m        \u001b[32m0.0691\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0619\u001b[0m  1.2892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5             \u001b[36m0.9813\u001b[0m        \u001b[32m0.0513\u001b[0m       \u001b[35m0.9853\u001b[0m        \u001b[31m0.0519\u001b[0m  1.2899\n",
      "      6             \u001b[36m0.9820\u001b[0m        \u001b[32m0.0261\u001b[0m       \u001b[35m0.9858\u001b[0m        \u001b[31m0.0439\u001b[0m  1.2771\n",
      "      7             0.9781        \u001b[32m0.0195\u001b[0m       0.9826        0.0520  1.2769\n",
      "      8             \u001b[36m0.9836\u001b[0m        \u001b[32m0.0181\u001b[0m       \u001b[35m0.9872\u001b[0m        0.0450  1.3287\n",
      "      9             \u001b[36m0.9854\u001b[0m        \u001b[32m0.0123\u001b[0m       \u001b[35m0.9885\u001b[0m        0.0458  1.2859\n",
      "     10             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0066\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0393\u001b[0m  1.2676\n",
      "     11             0.9855        \u001b[32m0.0032\u001b[0m       0.9885        \u001b[31m0.0376\u001b[0m  1.2674\n",
      "     12             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0023\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0337\u001b[0m  1.2678\n",
      "     13             0.9878        \u001b[32m0.0013\u001b[0m       0.9904        0.0342  1.2763\n",
      "     14             \u001b[36m0.9889\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9913\u001b[0m        \u001b[31m0.0323\u001b[0m  1.2830\n",
      "     15             \u001b[36m0.9890\u001b[0m        \u001b[32m0.0007\u001b[0m       0.9913        0.0341  1.2771\n",
      "     16             0.9884        0.0007       0.9908        0.0368  1.2704\n",
      "     17             0.9884        \u001b[32m0.0005\u001b[0m       0.9908        0.0347  1.2770\n",
      "     18             0.9884        \u001b[32m0.0004\u001b[0m       0.9908        0.0335  1.2743\n",
      "     19             0.9884        \u001b[32m0.0003\u001b[0m       0.9908        0.0340  1.2671\n",
      "     20             0.9878        \u001b[32m0.0003\u001b[0m       0.9904        0.0340  1.2796\n",
      "     21             0.9884        \u001b[32m0.0003\u001b[0m       0.9908        0.0356  1.3251\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 6/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.992) f1_score: (test=0.990) total time=  28.4s\n",
      "[CV 3/4; 6/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4715\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.6022\u001b[0m  1.2675\n",
      "      2             \u001b[36m0.8582\u001b[0m        \u001b[32m0.2408\u001b[0m       \u001b[35m0.8786\u001b[0m        \u001b[31m0.2813\u001b[0m  1.2679\n",
      "      3             \u001b[36m0.9601\u001b[0m        \u001b[32m0.1221\u001b[0m       \u001b[35m0.9684\u001b[0m        \u001b[31m0.1001\u001b[0m  1.2770\n",
      "      4             \u001b[36m0.9735\u001b[0m        \u001b[32m0.0667\u001b[0m       \u001b[35m0.9789\u001b[0m        \u001b[31m0.0747\u001b[0m  1.2685\n",
      "      5             \u001b[36m0.9741\u001b[0m        \u001b[32m0.0461\u001b[0m       \u001b[35m0.9794\u001b[0m        \u001b[31m0.0687\u001b[0m  1.2671\n",
      "      6             0.9717        \u001b[32m0.0296\u001b[0m       0.9780        0.0743  1.2683\n",
      "      7             \u001b[36m0.9813\u001b[0m        \u001b[32m0.0273\u001b[0m       \u001b[35m0.9853\u001b[0m        \u001b[31m0.0632\u001b[0m  1.2692\n",
      "      8             0.9777        \u001b[32m0.0172\u001b[0m       0.9826        \u001b[31m0.0608\u001b[0m  1.2692\n",
      "      9             \u001b[36m0.9837\u001b[0m        \u001b[32m0.0148\u001b[0m       \u001b[35m0.9872\u001b[0m        \u001b[31m0.0566\u001b[0m  1.2694\n",
      "     10             0.9819        \u001b[32m0.0099\u001b[0m       0.9858        0.0568  1.2700\n",
      "     11             0.9791        \u001b[32m0.0062\u001b[0m       0.9835        \u001b[31m0.0516\u001b[0m  1.2682\n",
      "     12             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0046\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0468\u001b[0m  1.2687\n",
      "     13             \u001b[36m0.9866\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9895\u001b[0m        \u001b[31m0.0431\u001b[0m  1.2697\n",
      "     14             0.9837        0.0049       0.9872        0.0523  1.2686\n",
      "     15             0.9848        0.0045       0.9881        0.0495  1.3295\n",
      "     16             0.9849        \u001b[32m0.0023\u001b[0m       0.9881        0.0459  1.4088\n",
      "     17             0.9836        \u001b[32m0.0012\u001b[0m       0.9872        0.0583  1.4031\n",
      "     18             0.9855        \u001b[32m0.0006\u001b[0m       0.9885        0.0484  1.4037\n",
      "     19             0.9860        \u001b[32m0.0005\u001b[0m       0.9890        0.0512  1.3412\n",
      "     20             0.9849        \u001b[32m0.0004\u001b[0m       0.9881        0.0511  1.3479\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 6/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  27.6s\n",
      "[CV 4/4; 6/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4808\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5824\u001b[0m  1.4069\n",
      "      2             \u001b[36m0.6379\u001b[0m        \u001b[32m0.2686\u001b[0m       \u001b[35m0.7957\u001b[0m        \u001b[31m0.4035\u001b[0m  1.3606\n",
      "      3             \u001b[36m0.9497\u001b[0m        \u001b[32m0.1425\u001b[0m       \u001b[35m0.9615\u001b[0m        \u001b[31m0.1096\u001b[0m  1.3491\n",
      "      4             \u001b[36m0.9666\u001b[0m        \u001b[32m0.0863\u001b[0m       \u001b[35m0.9739\u001b[0m        \u001b[31m0.0801\u001b[0m  1.3449\n",
      "      5             \u001b[36m0.9830\u001b[0m        \u001b[32m0.0548\u001b[0m       \u001b[35m0.9867\u001b[0m        \u001b[31m0.0534\u001b[0m  1.3421\n",
      "      6             0.9803        \u001b[32m0.0339\u001b[0m       0.9844        \u001b[31m0.0520\u001b[0m  1.4047\n",
      "      7             0.9776        \u001b[32m0.0230\u001b[0m       0.9826        0.0565  1.3932\n",
      "      8             \u001b[36m0.9860\u001b[0m        \u001b[32m0.0223\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0493\u001b[0m  1.3627\n",
      "      9             0.9763        \u001b[32m0.0144\u001b[0m       0.9817        0.0579  1.3954\n",
      "     10             \u001b[36m0.9860\u001b[0m        \u001b[32m0.0070\u001b[0m       0.9890        \u001b[31m0.0436\u001b[0m  1.3422\n",
      "     11             \u001b[36m0.9913\u001b[0m        \u001b[32m0.0049\u001b[0m       \u001b[35m0.9931\u001b[0m        \u001b[31m0.0387\u001b[0m  1.3413\n",
      "     12             0.9901        \u001b[32m0.0035\u001b[0m       0.9922        0.0397  1.3583\n",
      "     13             0.9901        \u001b[32m0.0024\u001b[0m       0.9922        0.0389  1.4157\n",
      "     14             0.9895        \u001b[32m0.0014\u001b[0m       0.9918        0.0402  1.4402\n",
      "     15             0.9907        \u001b[32m0.0009\u001b[0m       0.9927        0.0401  1.4389\n",
      "     16             0.9889        \u001b[32m0.0008\u001b[0m       0.9913        0.0434  1.4425\n",
      "     17             0.9895        \u001b[32m0.0006\u001b[0m       0.9918        0.0425  1.4369\n",
      "     18             0.9907        \u001b[32m0.0005\u001b[0m       0.9927        0.0428  1.4402\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 6/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.990) f1_score: (test=0.988) total time=  26.6s\n",
      "[CV 1/4; 7/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4199\u001b[0m        \u001b[32m0.4742\u001b[0m       \u001b[35m0.7238\u001b[0m        \u001b[31m0.5552\u001b[0m  0.4805\n",
      "      2             \u001b[36m0.8450\u001b[0m        \u001b[32m0.2357\u001b[0m       \u001b[35m0.8621\u001b[0m        \u001b[31m0.3092\u001b[0m  0.4810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3             \u001b[36m0.9661\u001b[0m        \u001b[32m0.1238\u001b[0m       \u001b[35m0.9725\u001b[0m        \u001b[31m0.0926\u001b[0m  0.4852\n",
      "      4             \u001b[36m0.9718\u001b[0m        \u001b[32m0.0764\u001b[0m       \u001b[35m0.9771\u001b[0m        \u001b[31m0.0672\u001b[0m  0.4704\n",
      "      5             \u001b[36m0.9735\u001b[0m        \u001b[32m0.0523\u001b[0m       \u001b[35m0.9785\u001b[0m        \u001b[31m0.0566\u001b[0m  0.4880\n",
      "      6             0.9505        \u001b[32m0.0373\u001b[0m       0.9620        0.0957  0.4746\n",
      "      7             \u001b[36m0.9856\u001b[0m        \u001b[32m0.0203\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0336\u001b[0m  0.4788\n",
      "      8             0.9852        \u001b[32m0.0132\u001b[0m       0.9881        \u001b[31m0.0294\u001b[0m  0.4772\n",
      "      9             0.9790        \u001b[32m0.0061\u001b[0m       0.9831        0.0427  0.4701\n",
      "     10             \u001b[36m0.9880\u001b[0m        \u001b[32m0.0037\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0227\u001b[0m  0.4732\n",
      "     11             \u001b[36m0.9881\u001b[0m        \u001b[32m0.0017\u001b[0m       0.9904        0.0292  0.4821\n",
      "     12             \u001b[36m0.9897\u001b[0m        \u001b[32m0.0014\u001b[0m       \u001b[35m0.9918\u001b[0m        0.0235  0.4810\n",
      "     13             \u001b[36m0.9909\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9927\u001b[0m        \u001b[31m0.0191\u001b[0m  0.4790\n",
      "     14             0.9903        0.0010       0.9922        0.0210  0.4813\n",
      "     15             0.9898        \u001b[32m0.0006\u001b[0m       0.9918        0.0203  0.4766\n",
      "     16             \u001b[36m0.9920\u001b[0m        \u001b[32m0.0004\u001b[0m       \u001b[35m0.9936\u001b[0m        \u001b[31m0.0180\u001b[0m  0.4705\n",
      "     17             0.9897        0.0004       0.9918        0.0189  0.4726\n",
      "     18             0.9909        \u001b[32m0.0004\u001b[0m       0.9927        0.0236  0.4671\n",
      "     19             0.9903        \u001b[32m0.0003\u001b[0m       0.9922        0.0201  0.4703\n",
      "     20             0.9903        0.0004       0.9922        0.0246  0.4636\n",
      "     21             0.9909        0.0004       0.9927        0.0208  0.4737\n",
      "     22             \u001b[36m0.9931\u001b[0m        \u001b[32m0.0002\u001b[0m       \u001b[35m0.9945\u001b[0m        0.0213  0.4731\n",
      "     23             0.9926        0.0002       0.9940        0.0223  0.4692\n",
      "     24             0.9909        0.0003       0.9927        0.0277  0.4685\n",
      "Epoch 00025: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     25             0.8984        0.0405       0.9253        0.2562  0.4662\n",
      "     26             0.9763        0.0348       0.9808        0.0544  0.4649\n",
      "     27             0.9833        0.0083       0.9867        0.0301  0.4719\n",
      "Epoch 00028: reducing learning rate of group 0 to 2.0000e-06.\n",
      "     28             0.9852        0.0039       0.9881        0.0289  0.4704\n",
      "     29             0.9852        0.0035       0.9881        0.0296  0.4690\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 7/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.983) f1_score: (test=0.979) total time=  14.4s\n",
      "[CV 2/4; 7/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4827\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5880\u001b[0m  0.4716\n",
      "      2             \u001b[36m0.8018\u001b[0m        \u001b[32m0.2506\u001b[0m       \u001b[35m0.8676\u001b[0m        \u001b[31m0.3171\u001b[0m  0.4654\n",
      "      3             \u001b[36m0.9452\u001b[0m        \u001b[32m0.0951\u001b[0m       \u001b[35m0.9588\u001b[0m        \u001b[31m0.1133\u001b[0m  0.4715\n",
      "      4             \u001b[36m0.9690\u001b[0m        \u001b[32m0.0514\u001b[0m       \u001b[35m0.9757\u001b[0m        \u001b[31m0.0628\u001b[0m  0.4720\n",
      "      5             \u001b[36m0.9758\u001b[0m        \u001b[32m0.0250\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0527\u001b[0m  0.4718\n",
      "      6             \u001b[36m0.9779\u001b[0m        \u001b[32m0.0137\u001b[0m       \u001b[35m0.9826\u001b[0m        \u001b[31m0.0493\u001b[0m  0.4718\n",
      "      7             0.9678        0.0192       0.9753        0.1091  0.4720\n",
      "      8             0.9750        0.0335       0.9803        0.0621  0.4732\n",
      "      9             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0108\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0393\u001b[0m  0.4702\n",
      "     10             0.9854        \u001b[32m0.0028\u001b[0m       0.9885        0.0438  0.4685\n",
      "     11             0.9843        \u001b[32m0.0019\u001b[0m       0.9876        0.0421  0.4685\n",
      "     12             0.9843        \u001b[32m0.0016\u001b[0m       0.9876        0.0466  0.4721\n",
      "     13             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0007\u001b[0m       0.9904        0.0406  0.4666\n",
      "     14             0.9872        \u001b[32m0.0005\u001b[0m       0.9899        0.0439  0.4685\n",
      "     15             0.9866        \u001b[32m0.0004\u001b[0m       0.9895        0.0433  0.4707\n",
      "     16             0.9878        \u001b[32m0.0003\u001b[0m       0.9904        0.0440  0.4707\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 7/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.992) f1_score: (test=0.990) total time=   8.1s\n",
      "[CV 3/4; 7/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4202\u001b[0m        \u001b[32m0.4343\u001b[0m       \u001b[35m0.7247\u001b[0m        \u001b[31m0.6495\u001b[0m  0.4657\n",
      "      2             \u001b[36m0.8875\u001b[0m        \u001b[32m0.2070\u001b[0m       \u001b[35m0.9120\u001b[0m        \u001b[31m0.2151\u001b[0m  0.4709\n",
      "      3             \u001b[36m0.9549\u001b[0m        \u001b[32m0.1028\u001b[0m       \u001b[35m0.9638\u001b[0m        \u001b[31m0.1154\u001b[0m  0.4699\n",
      "      4             \u001b[36m0.9656\u001b[0m        \u001b[32m0.0620\u001b[0m       \u001b[35m0.9725\u001b[0m        \u001b[31m0.0801\u001b[0m  0.4660\n",
      "      5             \u001b[36m0.9716\u001b[0m        \u001b[32m0.0351\u001b[0m       \u001b[35m0.9776\u001b[0m        \u001b[31m0.0638\u001b[0m  0.4754\n",
      "      6             0.9690        \u001b[32m0.0159\u001b[0m       0.9762        0.0873  0.4661\n",
      "      7             \u001b[36m0.9753\u001b[0m        \u001b[32m0.0097\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0574\u001b[0m  0.4656\n",
      "      8             \u001b[36m0.9783\u001b[0m        \u001b[32m0.0079\u001b[0m       \u001b[35m0.9831\u001b[0m        0.0600  0.4644\n",
      "      9             \u001b[36m0.9788\u001b[0m        \u001b[32m0.0047\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0570\u001b[0m  0.4708\n",
      "     10             \u001b[36m0.9796\u001b[0m        0.0048       \u001b[35m0.9840\u001b[0m        \u001b[31m0.0551\u001b[0m  0.4684\n",
      "     11             0.9780        \u001b[32m0.0032\u001b[0m       0.9826        0.0620  0.4659\n",
      "     12             0.9791        0.0032       0.9835        0.0611  0.4732\n",
      "     13             \u001b[36m0.9842\u001b[0m        \u001b[32m0.0010\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0528\u001b[0m  0.4686\n",
      "     14             \u001b[36m0.9842\u001b[0m        \u001b[32m0.0005\u001b[0m       0.9876        \u001b[31m0.0503\u001b[0m  0.4679\n",
      "     15             \u001b[36m0.9860\u001b[0m        \u001b[32m0.0003\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0496\u001b[0m  0.4642\n",
      "     16             0.9860        \u001b[32m0.0002\u001b[0m       0.9890        0.0512  0.4709\n",
      "     17             0.9836        0.0003       0.9872        0.0539  0.4706\n",
      "     18             0.9854        0.0002       0.9885        0.0506  0.4660\n",
      "     19             \u001b[36m0.9866\u001b[0m        \u001b[32m0.0002\u001b[0m       \u001b[35m0.9895\u001b[0m        0.0515  0.4709\n",
      "     20             \u001b[36m0.9866\u001b[0m        0.0002       0.9895        0.0505  0.4705\n",
      "     21             0.9806        0.0005       0.9849        0.0620  0.4657\n",
      "Epoch 00022: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     22             0.9842        0.0002       0.9876        0.0542  0.4733\n",
      "     23             0.9842        0.0002       0.9876        0.0539  0.4729\n",
      "     24             0.9854        \u001b[32m0.0001\u001b[0m       0.9885        0.0537  0.4689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     25             0.9848        \u001b[32m0.0001\u001b[0m       0.9881        0.0535  0.4703\n",
      "     26             0.9860        \u001b[32m0.0001\u001b[0m       0.9890        0.0526  0.4657\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 7/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  12.8s\n",
      "[CV 4/4; 7/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4714\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5740\u001b[0m  0.4716\n",
      "      2             \u001b[36m0.8262\u001b[0m        \u001b[32m0.2548\u001b[0m       \u001b[35m0.8690\u001b[0m        \u001b[31m0.2813\u001b[0m  0.4655\n",
      "      3             \u001b[36m0.9521\u001b[0m        \u001b[32m0.1033\u001b[0m       \u001b[35m0.9615\u001b[0m        \u001b[31m0.1060\u001b[0m  0.4710\n",
      "      4             \u001b[36m0.9664\u001b[0m        \u001b[32m0.0582\u001b[0m       \u001b[35m0.9734\u001b[0m        \u001b[31m0.0712\u001b[0m  0.4706\n",
      "      5             \u001b[36m0.9750\u001b[0m        \u001b[32m0.0355\u001b[0m       \u001b[35m0.9803\u001b[0m        \u001b[31m0.0583\u001b[0m  0.4734\n",
      "      6             0.9647        \u001b[32m0.0182\u001b[0m       0.9725        0.0918  0.4706\n",
      "      7             0.9679        0.0215       0.9748        0.0790  0.4696\n",
      "      8             \u001b[36m0.9797\u001b[0m        \u001b[32m0.0172\u001b[0m       \u001b[35m0.9840\u001b[0m        \u001b[31m0.0486\u001b[0m  0.4677\n",
      "      9             0.9773        \u001b[32m0.0056\u001b[0m       0.9821        0.0580  0.4754\n",
      "     10             \u001b[36m0.9819\u001b[0m        \u001b[32m0.0031\u001b[0m       \u001b[35m0.9858\u001b[0m        \u001b[31m0.0447\u001b[0m  0.4684\n",
      "     11             0.9807        \u001b[32m0.0021\u001b[0m       0.9849        0.0452  0.4713\n",
      "     12             \u001b[36m0.9832\u001b[0m        0.0022       \u001b[35m0.9867\u001b[0m        0.0529  0.4704\n",
      "     13             0.9770        0.0022       0.9817        0.0563  0.4784\n",
      "     14             0.9819        \u001b[32m0.0012\u001b[0m       0.9858        0.0496  0.4684\n",
      "     15             0.9825        \u001b[32m0.0009\u001b[0m       0.9863        0.0473  0.4760\n",
      "     16             \u001b[36m0.9843\u001b[0m        \u001b[32m0.0004\u001b[0m       \u001b[35m0.9876\u001b[0m        0.0479  0.4699\n",
      "     17             0.9842        0.0004       0.9876        0.0510  0.4731\n",
      "     18             \u001b[36m0.9854\u001b[0m        \u001b[32m0.0003\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0441\u001b[0m  0.4703\n",
      "     19             \u001b[36m0.9872\u001b[0m        0.0003       \u001b[35m0.9899\u001b[0m        \u001b[31m0.0439\u001b[0m  0.4754\n",
      "     20             0.9860        \u001b[32m0.0002\u001b[0m       0.9890        0.0444  0.4733\n",
      "     21             0.9860        \u001b[32m0.0002\u001b[0m       0.9890        0.0447  0.4687\n",
      "     22             0.9843        0.0002       0.9876        0.0454  0.4683\n",
      "     23             0.9866        \u001b[32m0.0001\u001b[0m       0.9895        0.0455  0.4731\n",
      "     24             0.9854        \u001b[32m0.0001\u001b[0m       0.9885        0.0449  0.4706\n",
      "     25             0.9860        \u001b[32m0.0001\u001b[0m       0.9890        0.0456  0.4709\n",
      "     26             0.9872        \u001b[32m0.0001\u001b[0m       0.9899        0.0464  0.4658\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 7/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.992) f1_score: (test=0.990) total time=  12.9s\n",
      "[CV 1/4; 8/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4199\u001b[0m        \u001b[32m0.5022\u001b[0m       \u001b[35m0.7238\u001b[0m        \u001b[31m0.5768\u001b[0m  0.4228\n",
      "      2             \u001b[36m0.7669\u001b[0m        \u001b[32m0.3379\u001b[0m       \u001b[35m0.8232\u001b[0m        \u001b[31m0.3639\u001b[0m  0.4131\n",
      "      3             \u001b[36m0.9211\u001b[0m        \u001b[32m0.2036\u001b[0m       \u001b[35m0.9395\u001b[0m        \u001b[31m0.1483\u001b[0m  0.4138\n",
      "      4             \u001b[36m0.9508\u001b[0m        \u001b[32m0.1323\u001b[0m       \u001b[35m0.9601\u001b[0m        \u001b[31m0.1035\u001b[0m  0.4176\n",
      "      5             \u001b[36m0.9676\u001b[0m        \u001b[32m0.0883\u001b[0m       \u001b[35m0.9739\u001b[0m        \u001b[31m0.0767\u001b[0m  0.4295\n",
      "      6             0.9664        \u001b[32m0.0546\u001b[0m       0.9730        \u001b[31m0.0685\u001b[0m  0.4235\n",
      "      7             \u001b[36m0.9807\u001b[0m        \u001b[32m0.0379\u001b[0m       \u001b[35m0.9844\u001b[0m        \u001b[31m0.0511\u001b[0m  0.4225\n",
      "      8             0.9764        \u001b[32m0.0328\u001b[0m       0.9812        0.0541  0.4234\n",
      "      9             \u001b[36m0.9834\u001b[0m        \u001b[32m0.0195\u001b[0m       \u001b[35m0.9867\u001b[0m        \u001b[31m0.0428\u001b[0m  0.4255\n",
      "     10             0.9816        \u001b[32m0.0144\u001b[0m       0.9853        0.0501  0.4177\n",
      "     11             0.9834        \u001b[32m0.0106\u001b[0m       0.9867        0.0457  0.4263\n",
      "     12             0.9834        \u001b[32m0.0100\u001b[0m       0.9867        0.0447  0.4244\n",
      "     13             0.9828        \u001b[32m0.0050\u001b[0m       0.9863        0.0436  0.4219\n",
      "     14             0.9778        \u001b[32m0.0029\u001b[0m       0.9821        0.0528  0.4256\n",
      "     15             0.9704        0.0162       0.9766        0.0771  0.4242\n",
      "     16             0.9738        0.0206       0.9789        0.0670  0.4251\n",
      "Epoch 00017: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 8/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.981) f1_score: (test=0.977) total time=   7.3s\n",
      "[CV 2/4; 8/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.7278\u001b[0m        \u001b[32m0.5145\u001b[0m       \u001b[35m0.7778\u001b[0m        \u001b[31m0.6075\u001b[0m  0.4173\n",
      "      2             \u001b[36m0.8004\u001b[0m        \u001b[32m0.3483\u001b[0m       \u001b[35m0.8401\u001b[0m        \u001b[31m0.3401\u001b[0m  0.4306\n",
      "      3             \u001b[36m0.9159\u001b[0m        \u001b[32m0.1989\u001b[0m       \u001b[35m0.9308\u001b[0m        \u001b[31m0.1642\u001b[0m  0.4278\n",
      "      4             \u001b[36m0.9475\u001b[0m        \u001b[32m0.1167\u001b[0m       \u001b[35m0.9579\u001b[0m        \u001b[31m0.1060\u001b[0m  0.4257\n",
      "      5             \u001b[36m0.9505\u001b[0m        \u001b[32m0.0686\u001b[0m       \u001b[35m0.9597\u001b[0m        \u001b[31m0.1025\u001b[0m  0.4264\n",
      "      6             \u001b[36m0.9655\u001b[0m        \u001b[32m0.0452\u001b[0m       \u001b[35m0.9730\u001b[0m        \u001b[31m0.0685\u001b[0m  0.4284\n",
      "      7             \u001b[36m0.9702\u001b[0m        \u001b[32m0.0327\u001b[0m       \u001b[35m0.9766\u001b[0m        \u001b[31m0.0659\u001b[0m  0.4177\n",
      "      8             \u001b[36m0.9721\u001b[0m        \u001b[32m0.0195\u001b[0m       \u001b[35m0.9780\u001b[0m        \u001b[31m0.0610\u001b[0m  0.4225\n",
      "      9             \u001b[36m0.9741\u001b[0m        \u001b[32m0.0125\u001b[0m       \u001b[35m0.9794\u001b[0m        0.0697  0.4292\n",
      "     10             0.9721        0.0141       0.9780        0.0658  0.4280\n",
      "     11             0.9724        \u001b[32m0.0082\u001b[0m       0.9780        0.0702  0.4240\n",
      "     12             0.9713        \u001b[32m0.0057\u001b[0m       0.9771        0.0816  0.4289\n",
      "     13             \u001b[36m0.9753\u001b[0m        \u001b[32m0.0040\u001b[0m       \u001b[35m0.9808\u001b[0m        0.0739  0.4254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     14             \u001b[36m0.9773\u001b[0m        \u001b[32m0.0025\u001b[0m       \u001b[35m0.9821\u001b[0m        0.0664  0.4242\n",
      "     15             \u001b[36m0.9780\u001b[0m        \u001b[32m0.0023\u001b[0m       \u001b[35m0.9826\u001b[0m        0.0696  0.4231\n",
      "     16             0.9745        0.0090       0.9798        0.0720  0.4301\n",
      "     17             0.9699        0.0071       0.9762        0.0806  0.4234\n",
      "Epoch 00018: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     18             0.9687        0.0113       0.9757        0.1006  0.4282\n",
      "     19             0.9722        0.0037       0.9780        0.0748  0.4237\n",
      "     20             0.9722        \u001b[32m0.0014\u001b[0m       0.9780        0.0723  0.4226\n",
      "     21             0.9739        \u001b[32m0.0010\u001b[0m       0.9794        0.0715  0.4260\n",
      "     22             0.9750        \u001b[32m0.0010\u001b[0m       0.9803        0.0699  0.4225\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 8/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.985) f1_score: (test=0.981) total time=   9.9s\n",
      "[CV 3/4; 8/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.5235\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5867\u001b[0m  0.4247\n",
      "      2             \u001b[36m0.7314\u001b[0m        \u001b[32m0.3765\u001b[0m       \u001b[35m0.8062\u001b[0m        \u001b[31m0.3756\u001b[0m  0.4260\n",
      "      3             \u001b[36m0.8830\u001b[0m        \u001b[32m0.2471\u001b[0m       \u001b[35m0.9020\u001b[0m        \u001b[31m0.2195\u001b[0m  0.4225\n",
      "      4             \u001b[36m0.9463\u001b[0m        \u001b[32m0.1560\u001b[0m       \u001b[35m0.9583\u001b[0m        \u001b[31m0.1205\u001b[0m  0.4209\n",
      "      5             \u001b[36m0.9628\u001b[0m        \u001b[32m0.0939\u001b[0m       \u001b[35m0.9707\u001b[0m        \u001b[31m0.0936\u001b[0m  0.4264\n",
      "      6             \u001b[36m0.9679\u001b[0m        \u001b[32m0.0645\u001b[0m       \u001b[35m0.9743\u001b[0m        \u001b[31m0.0849\u001b[0m  0.4191\n",
      "      7             0.9646        \u001b[32m0.0510\u001b[0m       0.9725        \u001b[31m0.0824\u001b[0m  0.4159\n",
      "      8             \u001b[36m0.9751\u001b[0m        \u001b[32m0.0351\u001b[0m       \u001b[35m0.9803\u001b[0m        \u001b[31m0.0685\u001b[0m  0.4239\n",
      "      9             0.9733        \u001b[32m0.0232\u001b[0m       0.9789        \u001b[31m0.0663\u001b[0m  0.4202\n",
      "     10             0.9747        \u001b[32m0.0159\u001b[0m       0.9798        0.0699  0.4197\n",
      "     11             \u001b[36m0.9761\u001b[0m        \u001b[32m0.0106\u001b[0m       \u001b[35m0.9812\u001b[0m        \u001b[31m0.0608\u001b[0m  0.4142\n",
      "     12             \u001b[36m0.9768\u001b[0m        \u001b[32m0.0077\u001b[0m       \u001b[35m0.9817\u001b[0m        \u001b[31m0.0581\u001b[0m  0.4219\n",
      "     13             \u001b[36m0.9809\u001b[0m        \u001b[32m0.0068\u001b[0m       \u001b[35m0.9849\u001b[0m        0.0641  0.4240\n",
      "     14             0.9696        0.0070       0.9757        0.0812  0.4236\n",
      "     15             0.9731        \u001b[32m0.0043\u001b[0m       0.9789        0.0723  0.4255\n",
      "     16             0.9791        \u001b[32m0.0023\u001b[0m       0.9835        \u001b[31m0.0573\u001b[0m  0.4233\n",
      "     17             0.9796        \u001b[32m0.0021\u001b[0m       0.9840        0.0619  0.4248\n",
      "     18             0.9743        \u001b[32m0.0013\u001b[0m       0.9798        0.0689  0.4233\n",
      "     19             0.9795        0.0028       0.9840        0.0631  0.4195\n",
      "     20             0.9785        \u001b[32m0.0008\u001b[0m       0.9831        0.0643  0.4162\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 8/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.982) f1_score: (test=0.978) total time=   9.0s\n",
      "[CV 4/4; 8/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.5132\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.6134\u001b[0m  0.4308\n",
      "      2             \u001b[36m0.7448\u001b[0m        \u001b[32m0.3721\u001b[0m       \u001b[35m0.8333\u001b[0m        \u001b[31m0.3776\u001b[0m  0.4271\n",
      "      3             \u001b[36m0.8941\u001b[0m        \u001b[32m0.2291\u001b[0m       \u001b[35m0.9116\u001b[0m        \u001b[31m0.1915\u001b[0m  0.4188\n",
      "      4             \u001b[36m0.9458\u001b[0m        \u001b[32m0.1379\u001b[0m       \u001b[35m0.9574\u001b[0m        \u001b[31m0.1148\u001b[0m  0.4171\n",
      "      5             0.9377        \u001b[32m0.0956\u001b[0m       0.9492        0.1234  0.4121\n",
      "      6             \u001b[36m0.9649\u001b[0m        \u001b[32m0.0655\u001b[0m       \u001b[35m0.9721\u001b[0m        \u001b[31m0.0844\u001b[0m  0.4156\n",
      "      7             0.9605        \u001b[32m0.0392\u001b[0m       0.9684        0.0928  0.4132\n",
      "      8             0.9539        \u001b[32m0.0273\u001b[0m       0.9647        0.1009  0.4267\n",
      "      9             \u001b[36m0.9716\u001b[0m        \u001b[32m0.0187\u001b[0m       \u001b[35m0.9776\u001b[0m        \u001b[31m0.0699\u001b[0m  0.4282\n",
      "     10             0.9656        \u001b[32m0.0114\u001b[0m       0.9734        0.0957  0.4256\n",
      "     11             0.9684        \u001b[32m0.0081\u001b[0m       0.9748        0.0817  0.4228\n",
      "     12             0.9649        \u001b[32m0.0051\u001b[0m       0.9721        0.0917  0.4252\n",
      "     13             \u001b[36m0.9730\u001b[0m        \u001b[32m0.0033\u001b[0m       \u001b[35m0.9789\u001b[0m        0.0900  0.4150\n",
      "     14             0.9669        0.0035       0.9743        0.1095  0.4177\n",
      "     15             0.9590        0.0156       0.9679        0.1010  0.4202\n",
      "Epoch 00016: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     16             0.9629        0.0131       0.9707        0.0977  0.4201\n",
      "     17             0.9711        0.0035       0.9771        0.0829  0.4204\n",
      "     18             \u001b[36m0.9739\u001b[0m        \u001b[32m0.0020\u001b[0m       \u001b[35m0.9794\u001b[0m        0.0781  0.4214\n",
      "     19             \u001b[36m0.9739\u001b[0m        \u001b[32m0.0015\u001b[0m       0.9794        0.0773  0.4204\n",
      "     20             \u001b[36m0.9751\u001b[0m        \u001b[32m0.0015\u001b[0m       \u001b[35m0.9803\u001b[0m        0.0784  0.4186\n",
      "     21             0.9739        \u001b[32m0.0015\u001b[0m       0.9794        0.0770  0.4096\n",
      "     22             0.9750        \u001b[32m0.0012\u001b[0m       0.9803        0.0771  0.4113\n",
      "     23             0.9727        0.0012       0.9785        0.0775  0.4181\n",
      "     24             0.9733        \u001b[32m0.0011\u001b[0m       0.9789        0.0774  0.4128\n",
      "     25             0.9739        \u001b[32m0.0009\u001b[0m       0.9794        0.0772  0.4107\n",
      "     26             0.9750        0.0009       0.9803        0.0772  0.4133\n",
      "     27             0.9745        \u001b[32m0.0009\u001b[0m       0.9798        0.0782  0.4114\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 8/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.978) f1_score: (test=0.972) total time=  11.9s\n",
      "[CV 1/4; 9/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5227\u001b[0m        \u001b[32m0.4261\u001b[0m       \u001b[35m0.7339\u001b[0m        \u001b[31m0.7577\u001b[0m  1.0948\n",
      "      2             \u001b[36m0.8605\u001b[0m        \u001b[32m0.1821\u001b[0m       \u001b[35m0.8978\u001b[0m        \u001b[31m0.3981\u001b[0m  1.0935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3             \u001b[36m0.9499\u001b[0m        \u001b[32m0.1405\u001b[0m       \u001b[35m0.9601\u001b[0m        \u001b[31m0.1292\u001b[0m  1.0931\n",
      "      4             \u001b[36m0.9622\u001b[0m        \u001b[32m0.0685\u001b[0m       \u001b[35m0.9689\u001b[0m        \u001b[31m0.0625\u001b[0m  1.0909\n",
      "      5             0.9048        \u001b[32m0.0384\u001b[0m       0.9175        0.1477  1.0948\n",
      "      6             \u001b[36m0.9670\u001b[0m        \u001b[32m0.0365\u001b[0m       \u001b[35m0.9730\u001b[0m        \u001b[31m0.0621\u001b[0m  1.1023\n",
      "      7             0.9550        \u001b[32m0.0364\u001b[0m       0.9652        0.1593  1.0997\n",
      "      8             \u001b[36m0.9757\u001b[0m        \u001b[32m0.0234\u001b[0m       \u001b[35m0.9808\u001b[0m        0.0845  1.1055\n",
      "      9             \u001b[36m0.9851\u001b[0m        \u001b[32m0.0160\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0499\u001b[0m  1.1015\n",
      "     10             0.9798        \u001b[32m0.0078\u001b[0m       0.9840        0.0640  1.1018\n",
      "     11             0.9378        0.0715       0.9478        0.1187  1.1005\n",
      "     12             0.9706        0.0379       0.9766        0.0942  1.1012\n",
      "Epoch 00013: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     13             0.9655        0.0234       0.9716        0.0588  1.1085\n",
      "     14             \u001b[36m0.9920\u001b[0m        0.0161       \u001b[35m0.9936\u001b[0m        \u001b[31m0.0195\u001b[0m  1.1033\n",
      "     15             \u001b[36m0.9920\u001b[0m        \u001b[32m0.0035\u001b[0m       0.9936        \u001b[31m0.0168\u001b[0m  1.1021\n",
      "     16             0.9920        \u001b[32m0.0027\u001b[0m       0.9936        \u001b[31m0.0163\u001b[0m  1.0926\n",
      "     17             0.9915        \u001b[32m0.0020\u001b[0m       0.9931        0.0167  1.0950\n",
      "     18             0.9915        \u001b[32m0.0019\u001b[0m       0.9931        0.0166  1.1010\n",
      "     19             0.9915        \u001b[32m0.0014\u001b[0m       0.9931        0.0167  1.0943\n",
      "     20             0.9920        0.0015       0.9936        0.0170  1.1019\n",
      "     21             0.9915        \u001b[32m0.0013\u001b[0m       0.9931        0.0170  1.1035\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 9/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  24.4s\n",
      "[CV 2/4; 9/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4578\u001b[0m        \u001b[32m0.4141\u001b[0m       \u001b[35m0.7224\u001b[0m        \u001b[31m0.8719\u001b[0m  1.1072\n",
      "      2             \u001b[36m0.8664\u001b[0m        \u001b[32m0.1734\u001b[0m       \u001b[35m0.8910\u001b[0m        \u001b[31m0.2864\u001b[0m  1.1044\n",
      "      3             \u001b[36m0.8803\u001b[0m        \u001b[32m0.1047\u001b[0m       \u001b[35m0.8960\u001b[0m        \u001b[31m0.2037\u001b[0m  1.1021\n",
      "      4             \u001b[36m0.9739\u001b[0m        \u001b[32m0.0668\u001b[0m       \u001b[35m0.9794\u001b[0m        \u001b[31m0.0723\u001b[0m  1.0995\n",
      "      5             0.9486        \u001b[32m0.0602\u001b[0m       0.9579        0.1006  1.1017\n",
      "      6             0.9711        \u001b[32m0.0490\u001b[0m       0.9776        0.1197  1.1095\n",
      "      7             0.9652        \u001b[32m0.0386\u001b[0m       0.9730        0.1253  1.1041\n",
      "      8             0.9439        \u001b[32m0.0231\u001b[0m       0.9537        0.1215  1.1084\n",
      "      9             \u001b[36m0.9764\u001b[0m        0.0336       \u001b[35m0.9812\u001b[0m        \u001b[31m0.0713\u001b[0m  1.1071\n",
      "     10             \u001b[36m0.9808\u001b[0m        \u001b[32m0.0152\u001b[0m       \u001b[35m0.9849\u001b[0m        \u001b[31m0.0617\u001b[0m  1.0998\n",
      "     11             0.9766        \u001b[32m0.0076\u001b[0m       0.9812        0.0658  1.1029\n",
      "     12             0.9741        \u001b[32m0.0070\u001b[0m       0.9794        0.0633  1.1051\n",
      "     13             0.9754        0.0113       0.9803        0.0681  1.1025\n",
      "     14             0.9632        0.0196       0.9702        0.0993  1.1048\n",
      "Epoch 00015: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     15             0.9730        0.0135       0.9785        0.0989  1.1064\n",
      "     16             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0047\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0609\u001b[0m  1.1120\n",
      "     17             0.9850        \u001b[32m0.0019\u001b[0m       0.9881        \u001b[31m0.0573\u001b[0m  1.1061\n",
      "     18             0.9861        \u001b[32m0.0012\u001b[0m       0.9890        \u001b[31m0.0557\u001b[0m  1.1043\n",
      "     19             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0011\u001b[0m       0.9890        0.0558  1.1059\n",
      "     20             0.9855        \u001b[32m0.0009\u001b[0m       0.9885        0.0578  1.1141\n",
      "     21             0.9855        \u001b[32m0.0008\u001b[0m       0.9885        0.0566  1.1075\n",
      "     22             0.9855        \u001b[32m0.0008\u001b[0m       0.9885        0.0557  1.1028\n",
      "     23             0.9850        \u001b[32m0.0007\u001b[0m       0.9881        0.0565  1.0934\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 9/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.991) f1_score: (test=0.989) total time=  26.7s\n",
      "[CV 3/4; 9/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4351\u001b[0m        \u001b[32m0.3962\u001b[0m       \u001b[35m0.7306\u001b[0m        \u001b[31m1.2495\u001b[0m  1.0983\n",
      "      2             \u001b[36m0.8900\u001b[0m        \u001b[32m0.1605\u001b[0m       \u001b[35m0.9107\u001b[0m        \u001b[31m0.2267\u001b[0m  1.1010\n",
      "      3             \u001b[36m0.9667\u001b[0m        \u001b[32m0.0789\u001b[0m       \u001b[35m0.9734\u001b[0m        \u001b[31m0.0904\u001b[0m  1.0859\n",
      "      4             0.9187        0.0809       0.9317        0.1413  1.0912\n",
      "      5             \u001b[36m0.9709\u001b[0m        \u001b[32m0.0646\u001b[0m       \u001b[35m0.9771\u001b[0m        0.1023  1.0948\n",
      "      6             0.9686        \u001b[32m0.0405\u001b[0m       0.9748        \u001b[31m0.0701\u001b[0m  1.0908\n",
      "      7             \u001b[36m0.9778\u001b[0m        \u001b[32m0.0195\u001b[0m       \u001b[35m0.9826\u001b[0m        0.0763  1.1001\n",
      "      8             0.9764        \u001b[32m0.0135\u001b[0m       0.9812        0.0725  1.1021\n",
      "      9             \u001b[36m0.9850\u001b[0m        \u001b[32m0.0108\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0535\u001b[0m  1.0991\n",
      "     10             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0063\u001b[0m       \u001b[35m0.9918\u001b[0m        \u001b[31m0.0485\u001b[0m  1.0973\n",
      "     11             0.9850        \u001b[32m0.0037\u001b[0m       0.9881        \u001b[31m0.0467\u001b[0m  1.1013\n",
      "     12             0.9519        0.0236       0.9615        0.1736  1.0985\n",
      "     13             0.9782        0.0413       0.9831        0.1221  1.1036\n",
      "Epoch 00014: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     14             0.9843        0.0103       0.9876        0.0576  1.1021\n",
      "     15             0.9860        \u001b[32m0.0029\u001b[0m       0.9890        0.0592  1.0994\n",
      "     16             0.9849        \u001b[32m0.0017\u001b[0m       0.9881        0.0560  1.0937\n",
      "     17             0.9854        \u001b[32m0.0013\u001b[0m       0.9885        0.0564  1.0859\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 9/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  19.9s\n",
      "[CV 4/4; 9/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4210\u001b[0m        \u001b[32m0.4165\u001b[0m       \u001b[35m0.7224\u001b[0m        \u001b[31m1.1609\u001b[0m  1.0847\n",
      "      2             \u001b[36m0.8954\u001b[0m        \u001b[32m0.1778\u001b[0m       \u001b[35m0.9143\u001b[0m        \u001b[31m0.1864\u001b[0m  1.0869\n",
      "      3             0.8766        \u001b[32m0.1176\u001b[0m       0.8923        0.2063  1.0868\n",
      "      4             \u001b[36m0.9628\u001b[0m        \u001b[32m0.0689\u001b[0m       \u001b[35m0.9711\u001b[0m        \u001b[31m0.1127\u001b[0m  1.0920\n",
      "      5             \u001b[36m0.9720\u001b[0m        \u001b[32m0.0441\u001b[0m       \u001b[35m0.9776\u001b[0m        \u001b[31m0.0778\u001b[0m  1.0915\n",
      "      6             0.9329        0.0497       0.9441        0.1439  1.0904\n",
      "      7             0.9697        \u001b[32m0.0373\u001b[0m       0.9757        \u001b[31m0.0733\u001b[0m  1.0910\n",
      "      8             0.9428        \u001b[32m0.0165\u001b[0m       0.9528        0.1259  1.0862\n",
      "      9             0.9607        0.0401       0.9684        0.1080  1.0910\n",
      "     10             0.9598        0.0222       0.9675        0.1005  1.0861\n",
      "Epoch 00011: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     11             \u001b[36m0.9752\u001b[0m        0.0281       \u001b[35m0.9803\u001b[0m        0.0797  1.0913\n",
      "     12             \u001b[36m0.9809\u001b[0m        \u001b[32m0.0110\u001b[0m       \u001b[35m0.9849\u001b[0m        \u001b[31m0.0653\u001b[0m  1.0862\n",
      "     13             0.9809        \u001b[32m0.0038\u001b[0m       0.9849        \u001b[31m0.0605\u001b[0m  1.0918\n",
      "     14             \u001b[36m0.9820\u001b[0m        \u001b[32m0.0023\u001b[0m       \u001b[35m0.9858\u001b[0m        \u001b[31m0.0596\u001b[0m  1.0930\n",
      "     15             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0022\u001b[0m       \u001b[35m0.9872\u001b[0m        \u001b[31m0.0574\u001b[0m  1.0908\n",
      "     16             \u001b[36m0.9849\u001b[0m        \u001b[32m0.0019\u001b[0m       \u001b[35m0.9881\u001b[0m        0.0590  1.0901\n",
      "     17             0.9837        \u001b[32m0.0015\u001b[0m       0.9872        0.0580  1.0903\n",
      "     18             0.9843        \u001b[32m0.0015\u001b[0m       0.9876        \u001b[31m0.0565\u001b[0m  1.0974\n",
      "     19             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0012\u001b[0m       \u001b[35m0.9885\u001b[0m        0.0568  1.0973\n",
      "     20             0.9849        0.0014       0.9881        0.0592  1.0954\n",
      "     21             0.9855        \u001b[32m0.0011\u001b[0m       0.9885        0.0585  1.0889\n",
      "     22             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0010\u001b[0m       \u001b[35m0.9890\u001b[0m        0.0574  1.0895\n",
      "     23             \u001b[36m0.9866\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9895\u001b[0m        0.0583  1.0863\n",
      "     24             \u001b[36m0.9866\u001b[0m        \u001b[32m0.0008\u001b[0m       0.9895        \u001b[31m0.0562\u001b[0m  1.0861\n",
      "     25             \u001b[36m0.9872\u001b[0m        0.0009       \u001b[35m0.9899\u001b[0m        \u001b[31m0.0560\u001b[0m  1.0910\n",
      "     26             0.9866        \u001b[32m0.0008\u001b[0m       0.9895        0.0568  1.0901\n",
      "     27             0.9866        \u001b[32m0.0007\u001b[0m       0.9895        0.0575  1.1019\n",
      "     28             0.9872        \u001b[32m0.0006\u001b[0m       0.9899        0.0574  1.1086\n",
      "     29             0.9872        \u001b[32m0.0006\u001b[0m       0.9899        0.0576  1.0990\n",
      "     30             0.9867        0.0006       0.9895        0.0564  1.1006\n",
      "     31             0.9872        0.0006       0.9899        0.0587  1.0956\n",
      "     32             0.9872        \u001b[32m0.0005\u001b[0m       0.9899        0.0573  1.0914\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 9/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.990) f1_score: (test=0.988) total time=  36.3s\n",
      "[CV 1/4; 10/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.6414\u001b[0m        \u001b[32m0.5288\u001b[0m       \u001b[35m0.6601\u001b[0m        \u001b[31m0.6542\u001b[0m  0.6352\n",
      "      2             \u001b[36m0.6773\u001b[0m        \u001b[32m0.2939\u001b[0m       \u001b[35m0.6830\u001b[0m        \u001b[31m0.5667\u001b[0m  0.6370\n",
      "      3             \u001b[36m0.9082\u001b[0m        \u001b[32m0.1698\u001b[0m       \u001b[35m0.9212\u001b[0m        \u001b[31m0.1409\u001b[0m  0.6366\n",
      "      4             \u001b[36m0.9572\u001b[0m        \u001b[32m0.1044\u001b[0m       \u001b[35m0.9652\u001b[0m        \u001b[31m0.0873\u001b[0m  0.6363\n",
      "      5             \u001b[36m0.9758\u001b[0m        \u001b[32m0.0652\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0822\u001b[0m  0.6372\n",
      "      6             0.9702        \u001b[32m0.0430\u001b[0m       0.9766        0.1037  0.6332\n",
      "      7             0.9707        0.0454       0.9762        \u001b[31m0.0706\u001b[0m  0.6348\n",
      "      8             0.9739        \u001b[32m0.0370\u001b[0m       0.9794        0.0829  0.6349\n",
      "      9             \u001b[36m0.9835\u001b[0m        \u001b[32m0.0179\u001b[0m       \u001b[35m0.9867\u001b[0m        \u001b[31m0.0509\u001b[0m  0.6348\n",
      "     10             0.9821        \u001b[32m0.0104\u001b[0m       0.9858        0.0677  0.6277\n",
      "     11             \u001b[36m0.9851\u001b[0m        \u001b[32m0.0062\u001b[0m       \u001b[35m0.9881\u001b[0m        0.0565  0.6266\n",
      "     12             0.9851        \u001b[32m0.0031\u001b[0m       0.9881        \u001b[31m0.0466\u001b[0m  0.6270\n",
      "     13             0.9840        0.0033       0.9872        0.0479  0.6295\n",
      "     14             0.9812        \u001b[32m0.0022\u001b[0m       0.9849        0.0555  0.6356\n",
      "     15             0.9845        \u001b[32m0.0020\u001b[0m       0.9876        0.0651  0.6405\n",
      "     16             0.9763        0.0044       0.9812        0.0979  0.6302\n",
      "     17             0.9795        0.0060       0.9835        0.0694  0.6300\n",
      "Epoch 00018: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     18             0.9824        0.0063       0.9858        0.0562  0.6331\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 10/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.987) f1_score: (test=0.984) total time=  12.2s\n",
      "[CV 2/4; 10/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.3425\u001b[0m        \u001b[32m0.5462\u001b[0m       \u001b[35m0.3605\u001b[0m        \u001b[31m0.6800\u001b[0m  0.6337\n",
      "      2             \u001b[36m0.7809\u001b[0m        \u001b[32m0.3307\u001b[0m       \u001b[35m0.7994\u001b[0m        \u001b[31m0.3468\u001b[0m  0.6339\n",
      "      3             \u001b[36m0.8853\u001b[0m        \u001b[32m0.1778\u001b[0m       \u001b[35m0.9006\u001b[0m        \u001b[31m0.1786\u001b[0m  0.6311\n",
      "      4             \u001b[36m0.9094\u001b[0m        \u001b[32m0.1116\u001b[0m       \u001b[35m0.9235\u001b[0m        \u001b[31m0.1514\u001b[0m  0.6346\n",
      "      5             \u001b[36m0.9247\u001b[0m        \u001b[32m0.0806\u001b[0m       \u001b[35m0.9372\u001b[0m        \u001b[31m0.1218\u001b[0m  0.6355\n",
      "      6             \u001b[36m0.9588\u001b[0m        \u001b[32m0.0413\u001b[0m       \u001b[35m0.9670\u001b[0m        \u001b[31m0.0971\u001b[0m  0.6331\n",
      "      7             0.9312        \u001b[32m0.0374\u001b[0m       0.9427        0.1150  0.6327\n",
      "      8             \u001b[36m0.9691\u001b[0m        \u001b[32m0.0328\u001b[0m       \u001b[35m0.9753\u001b[0m        \u001b[31m0.0725\u001b[0m  0.6325\n",
      "      9             \u001b[36m0.9713\u001b[0m        \u001b[32m0.0140\u001b[0m       \u001b[35m0.9771\u001b[0m        0.0731  0.6346\n",
      "     10             0.9701        0.0259       0.9762        0.0825  0.6371\n",
      "     11             \u001b[36m0.9809\u001b[0m        \u001b[32m0.0114\u001b[0m       \u001b[35m0.9849\u001b[0m        \u001b[31m0.0679\u001b[0m  0.6337\n",
      "     12             0.9791        \u001b[32m0.0045\u001b[0m       0.9835        0.0825  0.6302\n",
      "     13             \u001b[36m0.9820\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9858\u001b[0m        0.0799  0.6312\n",
      "     14             \u001b[36m0.9831\u001b[0m        \u001b[32m0.0018\u001b[0m       \u001b[35m0.9867\u001b[0m        0.0876  0.6372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     15             0.9792        \u001b[32m0.0012\u001b[0m       0.9835        0.0802  0.6349\n",
      "     16             0.9820        \u001b[32m0.0009\u001b[0m       0.9858        0.0793  0.6333\n",
      "     17             0.9803        \u001b[32m0.0007\u001b[0m       0.9844        0.0806  0.6304\n",
      "     18             0.9803        \u001b[32m0.0005\u001b[0m       0.9844        0.0845  0.6327\n",
      "     19             0.9814        0.0006       0.9853        0.0828  0.6294\n",
      "     20             0.9802        \u001b[32m0.0005\u001b[0m       0.9844        0.0909  0.6327\n",
      "     21             0.9808        \u001b[32m0.0004\u001b[0m       0.9849        0.0857  0.6318\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 10/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  14.1s\n",
      "[CV 3/4; 10/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5479\u001b[0m        \u001b[32m0.5060\u001b[0m       \u001b[35m0.7229\u001b[0m        \u001b[31m0.6638\u001b[0m  0.6331\n",
      "      2             \u001b[36m0.8603\u001b[0m        \u001b[32m0.2958\u001b[0m       \u001b[35m0.8832\u001b[0m        \u001b[31m0.3101\u001b[0m  0.6272\n",
      "      3             \u001b[36m0.9470\u001b[0m        \u001b[32m0.1578\u001b[0m       \u001b[35m0.9574\u001b[0m        \u001b[31m0.1348\u001b[0m  0.6237\n",
      "      4             \u001b[36m0.9658\u001b[0m        \u001b[32m0.0993\u001b[0m       \u001b[35m0.9730\u001b[0m        \u001b[31m0.1006\u001b[0m  0.6290\n",
      "      5             0.9651        \u001b[32m0.0681\u001b[0m       0.9721        \u001b[31m0.0812\u001b[0m  0.6327\n",
      "      6             0.9590        \u001b[32m0.0458\u001b[0m       0.9670        0.0952  0.6218\n",
      "      7             \u001b[36m0.9677\u001b[0m        \u001b[32m0.0349\u001b[0m       \u001b[35m0.9748\u001b[0m        0.1250  0.6218\n",
      "      8             0.9612        \u001b[32m0.0294\u001b[0m       0.9689        0.0834  0.6228\n",
      "      9             \u001b[36m0.9756\u001b[0m        \u001b[32m0.0144\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0762\u001b[0m  0.6211\n",
      "     10             \u001b[36m0.9803\u001b[0m        \u001b[32m0.0065\u001b[0m       \u001b[35m0.9844\u001b[0m        0.0782  0.6179\n",
      "     11             0.9778        \u001b[32m0.0040\u001b[0m       0.9826        0.0962  0.6216\n",
      "     12             0.9761        0.0041       0.9812        0.0996  0.6208\n",
      "     13             0.9774        \u001b[32m0.0029\u001b[0m       0.9821        0.0886  0.6243\n",
      "     14             0.9763        \u001b[32m0.0019\u001b[0m       0.9812        0.0918  0.6242\n",
      "     15             \u001b[36m0.9808\u001b[0m        \u001b[32m0.0014\u001b[0m       \u001b[35m0.9849\u001b[0m        0.0943  0.6326\n",
      "     16             0.9791        \u001b[32m0.0008\u001b[0m       0.9835        0.0930  0.6304\n",
      "     17             0.9796        \u001b[32m0.0005\u001b[0m       0.9840        0.0966  0.6267\n",
      "     18             0.9779        \u001b[32m0.0004\u001b[0m       0.9826        0.1033  0.6257\n",
      "     19             0.9796        0.0005       0.9840        0.1038  0.6255\n",
      "     20             0.9779        \u001b[32m0.0004\u001b[0m       0.9826        0.1006  0.6274\n",
      "     21             0.9784        \u001b[32m0.0003\u001b[0m       0.9831        0.1018  0.6336\n",
      "     22             0.9773        \u001b[32m0.0003\u001b[0m       0.9821        0.0999  0.6331\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 10/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  14.5s\n",
      "[CV 4/4; 10/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5671\u001b[0m        \u001b[32m0.5062\u001b[0m       \u001b[35m0.6977\u001b[0m        \u001b[31m0.6508\u001b[0m  0.6274\n",
      "      2             \u001b[36m0.8690\u001b[0m        \u001b[32m0.2609\u001b[0m       \u001b[35m0.8983\u001b[0m        \u001b[31m0.3077\u001b[0m  0.6305\n",
      "      3             \u001b[36m0.9115\u001b[0m        \u001b[32m0.1476\u001b[0m       \u001b[35m0.9253\u001b[0m        \u001b[31m0.1437\u001b[0m  0.6273\n",
      "      4             \u001b[36m0.9459\u001b[0m        \u001b[32m0.0884\u001b[0m       \u001b[35m0.9556\u001b[0m        \u001b[31m0.1019\u001b[0m  0.6305\n",
      "      5             \u001b[36m0.9656\u001b[0m        \u001b[32m0.0660\u001b[0m       \u001b[35m0.9725\u001b[0m        \u001b[31m0.0796\u001b[0m  0.6349\n",
      "      6             \u001b[36m0.9722\u001b[0m        \u001b[32m0.0375\u001b[0m       \u001b[35m0.9780\u001b[0m        0.0802  0.6301\n",
      "      7             \u001b[36m0.9749\u001b[0m        \u001b[32m0.0260\u001b[0m       \u001b[35m0.9803\u001b[0m        \u001b[31m0.0754\u001b[0m  0.6281\n",
      "      8             0.9717        \u001b[32m0.0208\u001b[0m       0.9776        \u001b[31m0.0708\u001b[0m  0.6282\n",
      "      9             0.9743        \u001b[32m0.0181\u001b[0m       0.9798        0.0773  0.6273\n",
      "     10             0.9639        0.0238       0.9711        0.0789  0.6249\n",
      "     11             0.9736        \u001b[32m0.0131\u001b[0m       0.9794        0.0976  0.6240\n",
      "     12             0.9723        \u001b[32m0.0108\u001b[0m       0.9780        0.0837  0.6251\n",
      "     13             \u001b[36m0.9803\u001b[0m        \u001b[32m0.0071\u001b[0m       \u001b[35m0.9844\u001b[0m        \u001b[31m0.0603\u001b[0m  0.6264\n",
      "     14             0.9777        \u001b[32m0.0037\u001b[0m       0.9826        0.0932  0.6221\n",
      "     15             \u001b[36m0.9820\u001b[0m        \u001b[32m0.0023\u001b[0m       \u001b[35m0.9858\u001b[0m        0.0668  0.6203\n",
      "     16             \u001b[36m0.9820\u001b[0m        \u001b[32m0.0012\u001b[0m       0.9858        0.0649  0.6238\n",
      "     17             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9872\u001b[0m        0.0645  0.6225\n",
      "     18             0.9837        \u001b[32m0.0004\u001b[0m       0.9872        0.0677  0.6227\n",
      "     19             0.9820        \u001b[32m0.0003\u001b[0m       0.9858        0.0661  0.6260\n",
      "     20             0.9832        \u001b[32m0.0003\u001b[0m       0.9867        0.0664  0.6251\n",
      "     21             0.9831        \u001b[32m0.0003\u001b[0m       0.9867        0.0695  0.6283\n",
      "     22             0.9797        \u001b[32m0.0002\u001b[0m       0.9840        0.0657  0.6313\n",
      "     23             0.9814        \u001b[32m0.0002\u001b[0m       0.9853        0.0659  0.6293\n",
      "     24             0.9814        \u001b[32m0.0002\u001b[0m       0.9853        0.0696  0.6304\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 10/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.987) f1_score: (test=0.984) total time=  15.8s\n",
      "[CV 1/4; 11/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4974\u001b[0m        \u001b[32m0.4331\u001b[0m       \u001b[35m0.7247\u001b[0m        \u001b[31m2.0256\u001b[0m  0.6155\n",
      "      2             \u001b[36m0.8105\u001b[0m        \u001b[32m0.2310\u001b[0m       \u001b[35m0.8369\u001b[0m        \u001b[31m0.3675\u001b[0m  0.6154\n",
      "      3             \u001b[36m0.9633\u001b[0m        \u001b[32m0.1279\u001b[0m       \u001b[35m0.9702\u001b[0m        \u001b[31m0.0854\u001b[0m  0.6200\n",
      "      4             0.8705        \u001b[32m0.1157\u001b[0m       0.8850        0.2238  0.6198\n",
      "      5             \u001b[36m0.9704\u001b[0m        \u001b[32m0.1074\u001b[0m       \u001b[35m0.9762\u001b[0m        \u001b[31m0.0681\u001b[0m  0.6236\n",
      "      6             \u001b[36m0.9775\u001b[0m        \u001b[32m0.0491\u001b[0m       \u001b[35m0.9821\u001b[0m        0.0998  0.6198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7             0.9714        \u001b[32m0.0424\u001b[0m       0.9766        \u001b[31m0.0434\u001b[0m  0.6184\n",
      "      8             0.9682        \u001b[32m0.0408\u001b[0m       0.9739        0.0453  0.6236\n",
      "      9             \u001b[36m0.9852\u001b[0m        \u001b[32m0.0221\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0339\u001b[0m  0.6249\n",
      "     10             \u001b[36m0.9880\u001b[0m        \u001b[32m0.0092\u001b[0m       \u001b[35m0.9904\u001b[0m        0.0373  0.6195\n",
      "     11             0.9167        0.0179       0.9285        0.2164  0.6189\n",
      "     12             0.9709        0.0612       0.9762        0.0521  0.6217\n",
      "Epoch 00013: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     13             0.9780        0.0383       0.9821        0.0425  0.6191\n",
      "     14             0.9852        0.0133       0.9881        \u001b[31m0.0300\u001b[0m  0.6217\n",
      "     15             \u001b[36m0.9880\u001b[0m        \u001b[32m0.0054\u001b[0m       0.9904        \u001b[31m0.0266\u001b[0m  0.6206\n",
      "     16             0.9869        \u001b[32m0.0045\u001b[0m       0.9895        0.0284  0.6209\n",
      "     17             0.9880        \u001b[32m0.0036\u001b[0m       0.9904        0.0279  0.6215\n",
      "     18             \u001b[36m0.9886\u001b[0m        \u001b[32m0.0030\u001b[0m       \u001b[35m0.9908\u001b[0m        0.0285  0.6194\n",
      "     19             0.9886        \u001b[32m0.0024\u001b[0m       0.9908        0.0284  0.6213\n",
      "     20             0.9886        \u001b[32m0.0020\u001b[0m       0.9908        0.0290  0.6173\n",
      "     21             \u001b[36m0.9891\u001b[0m        \u001b[32m0.0018\u001b[0m       \u001b[35m0.9913\u001b[0m        0.0283  0.6194\n",
      "     22             0.9891        \u001b[32m0.0016\u001b[0m       0.9913        0.0278  0.6209\n",
      "     23             \u001b[36m0.9903\u001b[0m        \u001b[32m0.0014\u001b[0m       \u001b[35m0.9922\u001b[0m        0.0282  0.6182\n",
      "     24             \u001b[36m0.9914\u001b[0m        \u001b[32m0.0013\u001b[0m       \u001b[35m0.9931\u001b[0m        0.0276  0.6180\n",
      "     25             0.9903        \u001b[32m0.0012\u001b[0m       0.9922        0.0291  0.6204\n",
      "     26             0.9908        \u001b[32m0.0011\u001b[0m       0.9927        0.0301  0.6177\n",
      "     27             0.9908        \u001b[32m0.0010\u001b[0m       0.9927        0.0301  0.6185\n",
      "     28             0.9914        \u001b[32m0.0008\u001b[0m       0.9931        0.0286  0.6209\n",
      "     29             0.9908        \u001b[32m0.0008\u001b[0m       0.9927        0.0287  0.6190\n",
      "     30             0.9914        \u001b[32m0.0006\u001b[0m       0.9931        0.0304  0.6205\n",
      "     31             \u001b[36m0.9920\u001b[0m        0.0007       \u001b[35m0.9936\u001b[0m        0.0290  0.6217\n",
      "     32             0.9920        \u001b[32m0.0006\u001b[0m       0.9936        0.0293  0.6202\n",
      "     33             0.9920        \u001b[32m0.0005\u001b[0m       0.9936        0.0297  0.6225\n",
      "     34             0.9920        0.0006       0.9936        0.0304  0.6231\n",
      "     35             0.9920        0.0006       0.9936        0.0294  0.6217\n",
      "     36             0.9920        \u001b[32m0.0004\u001b[0m       0.9936        0.0294  0.6246\n",
      "     37             0.9920        0.0005       0.9936        0.0306  0.6252\n",
      "     38             0.9914        \u001b[32m0.0004\u001b[0m       0.9931        0.0313  0.6214\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 11/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.989) f1_score: (test=0.986) total time=  24.4s\n",
      "[CV 2/4; 11/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4441\u001b[0m        \u001b[32m0.4592\u001b[0m       \u001b[35m0.7265\u001b[0m        \u001b[31m1.2414\u001b[0m  0.6186\n",
      "      2             \u001b[36m0.8089\u001b[0m        \u001b[32m0.2267\u001b[0m       \u001b[35m0.8681\u001b[0m        \u001b[31m0.4378\u001b[0m  0.6186\n",
      "      3             \u001b[36m0.9406\u001b[0m        \u001b[32m0.1381\u001b[0m       \u001b[35m0.9542\u001b[0m        \u001b[31m0.1715\u001b[0m  0.6183\n",
      "      4             0.8764        \u001b[32m0.1148\u001b[0m       0.9111        0.3317  0.6249\n",
      "      5             \u001b[36m0.9459\u001b[0m        \u001b[32m0.0899\u001b[0m       \u001b[35m0.9560\u001b[0m        \u001b[31m0.1164\u001b[0m  0.6280\n",
      "      6             0.9424        \u001b[32m0.0576\u001b[0m       0.9528        0.1205  0.6187\n",
      "      7             \u001b[36m0.9648\u001b[0m        0.0583       \u001b[35m0.9716\u001b[0m        \u001b[31m0.0659\u001b[0m  0.6253\n",
      "      8             0.9626        \u001b[32m0.0367\u001b[0m       0.9698        0.0765  0.6175\n",
      "      9             \u001b[36m0.9757\u001b[0m        \u001b[32m0.0277\u001b[0m       \u001b[35m0.9808\u001b[0m        0.0756  0.6190\n",
      "     10             0.9672        0.0553       0.9739        0.0811  0.6224\n",
      "     11             0.9676        0.0440       0.9739        0.0834  0.6249\n",
      "     12             \u001b[36m0.9782\u001b[0m        \u001b[32m0.0190\u001b[0m       \u001b[35m0.9831\u001b[0m        0.0968  0.6284\n",
      "     13             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0092\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0628\u001b[0m  0.6222\n",
      "     14             0.9769        0.0148       0.9817        0.0850  0.6175\n",
      "     15             0.9693        0.0270       0.9762        0.1046  0.6167\n",
      "Epoch 00016: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     16             0.9709        0.0210       0.9766        0.0901  0.6206\n",
      "     17             0.9827        \u001b[32m0.0070\u001b[0m       0.9863        \u001b[31m0.0540\u001b[0m  0.6343\n",
      "     18             \u001b[36m0.9862\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0483\u001b[0m  0.6192\n",
      "     19             0.9861        \u001b[32m0.0017\u001b[0m       0.9890        0.0485  0.6221\n",
      "     20             0.9861        \u001b[32m0.0015\u001b[0m       0.9890        \u001b[31m0.0477\u001b[0m  0.6301\n",
      "     21             0.9861        \u001b[32m0.0014\u001b[0m       0.9890        0.0478  0.6164\n",
      "     22             \u001b[36m0.9867\u001b[0m        \u001b[32m0.0012\u001b[0m       \u001b[35m0.9895\u001b[0m        0.0479  0.6144\n",
      "     23             \u001b[36m0.9879\u001b[0m        \u001b[32m0.0008\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0474\u001b[0m  0.6214\n",
      "     24             \u001b[36m0.9896\u001b[0m        \u001b[32m0.0008\u001b[0m       \u001b[35m0.9918\u001b[0m        0.0479  0.6217\n",
      "     25             0.9867        0.0008       0.9895        0.0474  0.6222\n",
      "     26             0.9873        0.0008       0.9899        0.0476  0.6282\n",
      "     27             0.9873        \u001b[32m0.0006\u001b[0m       0.9899        0.0482  0.6308\n",
      "     28             0.9879        \u001b[32m0.0006\u001b[0m       0.9904        0.0491  0.6358\n",
      "     29             0.9879        \u001b[32m0.0005\u001b[0m       0.9904        0.0497  0.6239\n",
      "     30             0.9879        \u001b[32m0.0005\u001b[0m       0.9904        0.0488  0.6246\n",
      "     31             0.9884        0.0006       0.9908        0.0489  0.6253\n",
      "     32             \u001b[36m0.9907\u001b[0m        0.0005       \u001b[35m0.9927\u001b[0m        0.0493  0.6261\n",
      "     33             0.9884        \u001b[32m0.0004\u001b[0m       0.9908        0.0496  0.6365\n",
      "     34             0.9884        \u001b[32m0.0004\u001b[0m       0.9908        0.0499  0.6258\n",
      "     35             0.9884        0.0004       0.9908        0.0509  0.6299\n",
      "     36             0.9884        \u001b[32m0.0003\u001b[0m       0.9908        0.0512  0.6306\n",
      "     37             0.9890        \u001b[32m0.0003\u001b[0m       0.9913        0.0505  0.6284\n",
      "     38             0.9896        0.0003       0.9918        0.0511  0.6298\n",
      "     39             0.9896        0.0003       0.9918        0.0517  0.6229\n",
      "Epoch 00040: reducing learning rate of group 0 to 8.0000e-06.\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 11/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.994) f1_score: (test=0.993) total time=  25.2s\n",
      "[CV 3/4; 11/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4220\u001b[0m        \u001b[32m0.4366\u001b[0m       \u001b[35m0.7251\u001b[0m        \u001b[31m1.1621\u001b[0m  0.6190\n",
      "      2             \u001b[36m0.7987\u001b[0m        \u001b[32m0.2083\u001b[0m       \u001b[35m0.8383\u001b[0m        \u001b[31m0.5136\u001b[0m  0.6171\n",
      "      3             \u001b[36m0.9328\u001b[0m        \u001b[32m0.1513\u001b[0m       \u001b[35m0.9446\u001b[0m        \u001b[31m0.1216\u001b[0m  0.6226\n",
      "      4             \u001b[36m0.9452\u001b[0m        \u001b[32m0.0932\u001b[0m       \u001b[35m0.9569\u001b[0m        0.1558  0.6223\n",
      "      5             \u001b[36m0.9620\u001b[0m        \u001b[32m0.0695\u001b[0m       \u001b[35m0.9693\u001b[0m        \u001b[31m0.0813\u001b[0m  0.6230\n",
      "      6             0.9307        \u001b[32m0.0559\u001b[0m       0.9423        0.1343  0.6215\n",
      "      7             0.9586        0.0743       0.9684        0.1775  0.6213\n",
      "      8             \u001b[36m0.9708\u001b[0m        \u001b[32m0.0520\u001b[0m       \u001b[35m0.9766\u001b[0m        \u001b[31m0.0700\u001b[0m  0.6181\n",
      "      9             0.9658        \u001b[32m0.0515\u001b[0m       0.9725        0.0891  0.6187\n",
      "     10             \u001b[36m0.9745\u001b[0m        \u001b[32m0.0290\u001b[0m       \u001b[35m0.9798\u001b[0m        0.0790  0.6175\n",
      "     11             \u001b[36m0.9786\u001b[0m        \u001b[32m0.0222\u001b[0m       \u001b[35m0.9831\u001b[0m        \u001b[31m0.0684\u001b[0m  0.6227\n",
      "     12             \u001b[36m0.9793\u001b[0m        \u001b[32m0.0102\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0668\u001b[0m  0.6223\n",
      "     13             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0072\u001b[0m       \u001b[35m0.9885\u001b[0m        0.0817  0.6236\n",
      "     14             0.9393        0.0248       0.9501        0.2035  0.6234\n",
      "     15             0.9763        0.0699       0.9817        0.1087  0.6222\n",
      "Epoch 00016: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     16             0.9638        0.0266       0.9707        0.0879  0.6235\n",
      "     17             \u001b[36m0.9883\u001b[0m        0.0126       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0568\u001b[0m  0.6196\n",
      "     18             0.9878        \u001b[32m0.0039\u001b[0m       0.9904        \u001b[31m0.0534\u001b[0m  0.6232\n",
      "     19             \u001b[36m0.9889\u001b[0m        \u001b[32m0.0031\u001b[0m       \u001b[35m0.9913\u001b[0m        0.0536  0.6198\n",
      "     20             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0028\u001b[0m       \u001b[35m0.9918\u001b[0m        \u001b[31m0.0531\u001b[0m  0.6184\n",
      "     21             0.9889        \u001b[32m0.0024\u001b[0m       0.9913        0.0546  0.6168\n",
      "     22             0.9890        \u001b[32m0.0020\u001b[0m       0.9913        0.0542  0.6174\n",
      "     23             0.9895        \u001b[32m0.0018\u001b[0m       0.9918        0.0545  0.6185\n",
      "     24             0.9889        0.0018       0.9913        0.0544  0.6238\n",
      "     25             0.9884        \u001b[32m0.0014\u001b[0m       0.9908        0.0537  0.6211\n",
      "     26             0.9884        \u001b[32m0.0012\u001b[0m       0.9908        0.0550  0.6253\n",
      "     27             0.9884        0.0013       0.9908        0.0555  0.6218\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 11/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  17.5s\n",
      "[CV 4/4; 11/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4242\u001b[0m        \u001b[32m0.4364\u001b[0m       \u001b[35m0.7224\u001b[0m        \u001b[31m1.4690\u001b[0m  0.6198\n",
      "      2             \u001b[36m0.8600\u001b[0m        \u001b[32m0.2113\u001b[0m       \u001b[35m0.8777\u001b[0m        \u001b[31m0.2497\u001b[0m  0.6174\n",
      "      3             \u001b[36m0.9447\u001b[0m        \u001b[32m0.1488\u001b[0m       \u001b[35m0.9569\u001b[0m        \u001b[31m0.1798\u001b[0m  0.6227\n",
      "      4             \u001b[36m0.9474\u001b[0m        \u001b[32m0.1078\u001b[0m       0.9569        \u001b[31m0.1056\u001b[0m  0.6242\n",
      "      5             \u001b[36m0.9630\u001b[0m        \u001b[32m0.0658\u001b[0m       \u001b[35m0.9707\u001b[0m        \u001b[31m0.0970\u001b[0m  0.6159\n",
      "      6             0.9344        \u001b[32m0.0584\u001b[0m       0.9455        0.1294  0.6207\n",
      "      7             0.9423        \u001b[32m0.0482\u001b[0m       0.9524        0.1135  0.6199\n",
      "      8             0.9618        \u001b[32m0.0467\u001b[0m       0.9693        0.1062  0.6194\n",
      "      9             \u001b[36m0.9795\u001b[0m        \u001b[32m0.0287\u001b[0m       \u001b[35m0.9840\u001b[0m        \u001b[31m0.0951\u001b[0m  0.6224\n",
      "     10             0.9765        \u001b[32m0.0253\u001b[0m       0.9817        0.0985  0.6155\n",
      "     11             0.9536        0.0378       0.9629        0.1182  0.6198\n",
      "     12             0.9681        0.0435       0.9748        0.1257  0.6194\n",
      "Epoch 00013: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     13             0.9524        0.0273       0.9611        0.1070  0.6191\n",
      "     14             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0102\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0524\u001b[0m  0.6224\n",
      "     15             0.9855        \u001b[32m0.0040\u001b[0m       0.9885        \u001b[31m0.0498\u001b[0m  0.6218\n",
      "     16             \u001b[36m0.9890\u001b[0m        \u001b[32m0.0033\u001b[0m       \u001b[35m0.9913\u001b[0m        0.0505  0.6192\n",
      "     17             0.9890        \u001b[32m0.0027\u001b[0m       0.9913        0.0505  0.6202\n",
      "     18             0.9890        \u001b[32m0.0023\u001b[0m       0.9913        0.0503  0.6189\n",
      "     19             0.9884        \u001b[32m0.0016\u001b[0m       0.9908        0.0502  0.6252\n",
      "     20             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0014\u001b[0m       \u001b[35m0.9918\u001b[0m        0.0507  0.6195\n",
      "     21             0.9895        \u001b[32m0.0013\u001b[0m       0.9918        0.0505  0.6257\n",
      "     22             0.9895        0.0013       0.9918        0.0511  0.6241\n",
      "     23             \u001b[36m0.9901\u001b[0m        0.0014       \u001b[35m0.9922\u001b[0m        0.0524  0.6220\n",
      "     24             0.9884        \u001b[32m0.0011\u001b[0m       0.9908        0.0505  0.6182\n",
      "     25             \u001b[36m0.9907\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9927\u001b[0m        0.0522  0.6206\n",
      "     26             0.9907        \u001b[32m0.0007\u001b[0m       0.9927        0.0522  0.6185\n",
      "     27             0.9901        \u001b[32m0.0007\u001b[0m       0.9922        0.0517  0.6229\n",
      "     28             0.9895        0.0008       0.9918        0.0520  0.6191\n",
      "     29             \u001b[36m0.9913\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9931\u001b[0m        0.0529  0.6179\n",
      "     30             0.9907        0.0007       0.9927        0.0533  0.6206\n",
      "     31             0.9907        \u001b[32m0.0006\u001b[0m       0.9927        0.0532  0.6193\n",
      "     32             0.9901        \u001b[32m0.0005\u001b[0m       0.9922        0.0533  0.6184\n",
      "     33             0.9907        \u001b[32m0.0005\u001b[0m       0.9927        0.0545  0.6182\n",
      "     34             0.9907        \u001b[32m0.0004\u001b[0m       0.9927        0.0542  0.6213\n",
      "     35             0.9907        0.0005       0.9927        0.0534  0.6222\n",
      "     36             0.9913        \u001b[32m0.0004\u001b[0m       0.9931        0.0539  0.6191\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 11/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.992) f1_score: (test=0.991) total time=  23.1s\n",
      "[CV 1/4; 12/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4194\u001b[0m        \u001b[32m0.4363\u001b[0m       \u001b[35m0.7224\u001b[0m        \u001b[31m0.8676\u001b[0m  0.8267\n",
      "      2             \u001b[36m0.8451\u001b[0m        \u001b[32m0.1453\u001b[0m       \u001b[35m0.8864\u001b[0m        \u001b[31m0.4527\u001b[0m  0.8239\n",
      "      3             \u001b[36m0.9444\u001b[0m        \u001b[32m0.0625\u001b[0m       \u001b[35m0.9537\u001b[0m        \u001b[31m0.0836\u001b[0m  0.8237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      4             0.9360        \u001b[32m0.0352\u001b[0m       0.9459        0.1147  0.8228\n",
      "      5             \u001b[36m0.9863\u001b[0m        \u001b[32m0.0341\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0394\u001b[0m  0.8213\n",
      "      6             0.9846        \u001b[32m0.0121\u001b[0m       0.9876        \u001b[31m0.0337\u001b[0m  0.8260\n",
      "      7             \u001b[36m0.9925\u001b[0m        \u001b[32m0.0064\u001b[0m       \u001b[35m0.9940\u001b[0m        \u001b[31m0.0212\u001b[0m  0.8219\n",
      "      8             0.9873        0.0066       0.9899        0.0417  0.8222\n",
      "      9             0.9448        0.0238       0.9537        0.1075  0.8221\n",
      "Epoch 00010: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     10             0.9763        0.0574       0.9808        0.0495  0.8211\n",
      "     11             0.9897        0.0127       0.9918        0.0272  0.8230\n",
      "     12             0.9875        \u001b[32m0.0057\u001b[0m       0.9899        0.0235  0.8225\n",
      "     13             0.9898        \u001b[32m0.0032\u001b[0m       0.9918        0.0214  0.8220\n",
      "     14             0.9909        \u001b[32m0.0028\u001b[0m       0.9927        0.0216  0.8271\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 12/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.991) f1_score: (test=0.988) total time=  12.5s\n",
      "[CV 2/4; 12/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.3978\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m1.3085\u001b[0m  0.8245\n",
      "      2             \u001b[36m0.8818\u001b[0m        \u001b[32m0.1586\u001b[0m       \u001b[35m0.8992\u001b[0m        \u001b[31m0.1825\u001b[0m  0.8212\n",
      "      3             \u001b[36m0.9728\u001b[0m        \u001b[32m0.0803\u001b[0m       \u001b[35m0.9785\u001b[0m        \u001b[31m0.0661\u001b[0m  0.8272\n",
      "      4             0.9727        \u001b[32m0.0693\u001b[0m       0.9785        0.0956  0.8278\n",
      "      5             \u001b[36m0.9769\u001b[0m        \u001b[32m0.0352\u001b[0m       \u001b[35m0.9817\u001b[0m        \u001b[31m0.0554\u001b[0m  0.8224\n",
      "      6             0.9753        \u001b[32m0.0319\u001b[0m       0.9808        0.0797  0.8230\n",
      "      7             0.9671        \u001b[32m0.0247\u001b[0m       0.9743        0.1393  0.8210\n",
      "      8             0.9601        0.0372       0.9679        0.1208  0.8195\n",
      "      9             \u001b[36m0.9789\u001b[0m        \u001b[32m0.0176\u001b[0m       \u001b[35m0.9835\u001b[0m        0.0847  0.8226\n",
      "     10             0.9747        0.0203       0.9798        0.0674  0.8269\n",
      "     11             0.9703        \u001b[32m0.0141\u001b[0m       0.9762        0.0799  0.8199\n",
      "     12             \u001b[36m0.9832\u001b[0m        \u001b[32m0.0119\u001b[0m       \u001b[35m0.9867\u001b[0m        0.0593  0.8221\n",
      "     13             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0085\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0546\u001b[0m  0.8229\n",
      "     14             0.9804        0.0142       0.9844        0.0624  0.8244\n",
      "     15             0.9816        \u001b[32m0.0047\u001b[0m       0.9853        0.0609  0.8272\n",
      "     16             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0038\u001b[0m       \u001b[35m0.9922\u001b[0m        \u001b[31m0.0381\u001b[0m  0.8218\n",
      "     17             0.9816        0.0084       0.9853        0.0512  0.8268\n",
      "     18             0.9810        0.0074       0.9849        0.0501  0.8286\n",
      "     19             0.9878        \u001b[32m0.0014\u001b[0m       0.9904        0.0516  0.8282\n",
      "     20             0.9855        \u001b[32m0.0004\u001b[0m       0.9885        0.0571  0.8260\n",
      "     21             0.9855        0.0005       0.9885        0.0527  0.8231\n",
      "     22             0.9884        \u001b[32m0.0002\u001b[0m       0.9908        0.0509  0.8213\n",
      "     23             0.9873        \u001b[32m0.0001\u001b[0m       0.9899        0.0510  0.8194\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 12/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.990) f1_score: (test=0.988) total time=  20.0s\n",
      "[CV 3/4; 12/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4260\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m1.2058\u001b[0m  0.8257\n",
      "      2             \u001b[36m0.8466\u001b[0m        \u001b[32m0.1802\u001b[0m       \u001b[35m0.8905\u001b[0m        \u001b[31m0.3838\u001b[0m  0.8282\n",
      "      3             \u001b[36m0.9602\u001b[0m        \u001b[32m0.1196\u001b[0m       \u001b[35m0.9689\u001b[0m        \u001b[31m0.1226\u001b[0m  0.8269\n",
      "      4             0.9516        \u001b[32m0.0674\u001b[0m       0.9606        \u001b[31m0.0900\u001b[0m  0.8271\n",
      "      5             0.9561        \u001b[32m0.0428\u001b[0m       0.9643        0.0912  0.8295\n",
      "      6             \u001b[36m0.9794\u001b[0m        \u001b[32m0.0243\u001b[0m       \u001b[35m0.9840\u001b[0m        \u001b[31m0.0841\u001b[0m  0.8266\n",
      "      7             \u001b[36m0.9815\u001b[0m        \u001b[32m0.0111\u001b[0m       \u001b[35m0.9853\u001b[0m        \u001b[31m0.0574\u001b[0m  0.8230\n",
      "      8             0.9718        0.0160       0.9776        0.0849  0.8237\n",
      "      9             0.9476        0.0313       0.9569        0.1260  0.8272\n",
      "Epoch 00010: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     10             0.9616        0.0378       0.9689        0.0889  0.8219\n",
      "     11             \u001b[36m0.9844\u001b[0m        \u001b[32m0.0107\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0514\u001b[0m  0.8269\n",
      "     12             \u001b[36m0.9850\u001b[0m        \u001b[32m0.0053\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0472\u001b[0m  0.8275\n",
      "     13             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0031\u001b[0m       \u001b[35m0.9885\u001b[0m        0.0483  0.8288\n",
      "     14             0.9855        \u001b[32m0.0027\u001b[0m       0.9885        0.0481  0.8252\n",
      "     15             \u001b[36m0.9867\u001b[0m        \u001b[32m0.0024\u001b[0m       \u001b[35m0.9895\u001b[0m        0.0494  0.8256\n",
      "     16             0.9861        \u001b[32m0.0017\u001b[0m       0.9890        0.0488  0.8294\n",
      "     17             0.9855        \u001b[32m0.0015\u001b[0m       0.9885        0.0496  0.8224\n",
      "     18             0.9855        \u001b[32m0.0015\u001b[0m       0.9885        0.0499  0.8226\n",
      "     19             0.9855        \u001b[32m0.0014\u001b[0m       0.9885        0.0504  0.8267\n",
      "     20             0.9849        \u001b[32m0.0011\u001b[0m       0.9881        0.0510  0.8265\n",
      "     21             0.9855        \u001b[32m0.0010\u001b[0m       0.9885        0.0494  0.8256\n",
      "     22             0.9849        \u001b[32m0.0010\u001b[0m       0.9881        0.0518  0.8287\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 12/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  19.2s\n",
      "[CV 4/4; 12/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4224\u001b[0m        \u001b[32m0.4191\u001b[0m       \u001b[35m0.7265\u001b[0m        \u001b[31m0.9630\u001b[0m  0.8287\n",
      "      2             \u001b[36m0.7795\u001b[0m        \u001b[32m0.1716\u001b[0m       \u001b[35m0.8511\u001b[0m        \u001b[31m0.5898\u001b[0m  0.8267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3             \u001b[36m0.9598\u001b[0m        \u001b[32m0.0730\u001b[0m       \u001b[35m0.9684\u001b[0m        \u001b[31m0.1234\u001b[0m  0.8303\n",
      "      4             \u001b[36m0.9735\u001b[0m        \u001b[32m0.0435\u001b[0m       \u001b[35m0.9789\u001b[0m        \u001b[31m0.0597\u001b[0m  0.8253\n",
      "      5             0.9631        \u001b[32m0.0248\u001b[0m       0.9702        0.0788  0.8269\n",
      "      6             0.9626        0.0326       0.9702        0.1156  0.8280\n",
      "      7             \u001b[36m0.9740\u001b[0m        0.0431       \u001b[35m0.9794\u001b[0m        0.0726  0.8272\n",
      "Epoch 00008: reducing learning rate of group 0 to 2.0000e-05.\n",
      "      8             \u001b[36m0.9743\u001b[0m        0.0318       \u001b[35m0.9798\u001b[0m        0.0872  0.8268\n",
      "      9             \u001b[36m0.9843\u001b[0m        \u001b[32m0.0107\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0520\u001b[0m  0.8251\n",
      "     10             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0054\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0420\u001b[0m  0.8249\n",
      "     11             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0033\u001b[0m       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0414\u001b[0m  0.8276\n",
      "     12             0.9884        \u001b[32m0.0022\u001b[0m       0.9908        0.0425  0.8293\n",
      "     13             0.9884        \u001b[32m0.0021\u001b[0m       0.9908        0.0417  0.8292\n",
      "     14             \u001b[36m0.9890\u001b[0m        \u001b[32m0.0018\u001b[0m       \u001b[35m0.9913\u001b[0m        0.0420  0.8324\n",
      "     15             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0017\u001b[0m       \u001b[35m0.9922\u001b[0m        0.0423  0.8313\n",
      "     16             0.9901        \u001b[32m0.0015\u001b[0m       0.9922        \u001b[31m0.0414\u001b[0m  0.8254\n",
      "     17             0.9901        \u001b[32m0.0013\u001b[0m       0.9922        0.0421  0.8294\n",
      "     18             0.9901        \u001b[32m0.0012\u001b[0m       0.9922        0.0432  0.8253\n",
      "     19             0.9901        \u001b[32m0.0011\u001b[0m       0.9922        0.0416  0.8284\n",
      "     20             0.9895        \u001b[32m0.0009\u001b[0m       0.9918        0.0415  0.8254\n",
      "     21             0.9884        \u001b[32m0.0009\u001b[0m       0.9908        0.0419  0.8266\n",
      "     22             0.9895        \u001b[32m0.0009\u001b[0m       0.9918        0.0416  0.8244\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 12/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.991) f1_score: (test=0.989) total time=  19.2s\n",
      "[CV 1/4; 13/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4127\u001b[0m        \u001b[32m0.4759\u001b[0m       \u001b[35m0.7027\u001b[0m        \u001b[31m0.7736\u001b[0m  0.4701\n",
      "      2             \u001b[36m0.8660\u001b[0m        \u001b[32m0.2102\u001b[0m       \u001b[35m0.8887\u001b[0m        \u001b[31m0.3332\u001b[0m  0.4776\n",
      "      3             \u001b[36m0.9490\u001b[0m        \u001b[32m0.1061\u001b[0m       \u001b[35m0.9579\u001b[0m        \u001b[31m0.0901\u001b[0m  0.4659\n",
      "      4             \u001b[36m0.9578\u001b[0m        \u001b[32m0.0746\u001b[0m       \u001b[35m0.9652\u001b[0m        \u001b[31m0.0782\u001b[0m  0.4776\n",
      "      5             \u001b[36m0.9805\u001b[0m        \u001b[32m0.0467\u001b[0m       \u001b[35m0.9844\u001b[0m        \u001b[31m0.0550\u001b[0m  0.4705\n",
      "      6             \u001b[36m0.9863\u001b[0m        \u001b[32m0.0165\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0414\u001b[0m  0.4764\n",
      "      7             0.9852        \u001b[32m0.0086\u001b[0m       0.9881        \u001b[31m0.0374\u001b[0m  0.4790\n",
      "      8             \u001b[36m0.9880\u001b[0m        \u001b[32m0.0061\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0296\u001b[0m  0.4776\n",
      "      9             \u001b[36m0.9903\u001b[0m        \u001b[32m0.0044\u001b[0m       \u001b[35m0.9922\u001b[0m        0.0375  0.4658\n",
      "     10             0.9863        \u001b[32m0.0030\u001b[0m       0.9890        0.0359  0.4651\n",
      "     11             0.9875        0.0035       0.9899        0.0333  0.4807\n",
      "     12             0.9881        \u001b[32m0.0015\u001b[0m       0.9904        0.0329  0.4761\n",
      "     13             0.9897        \u001b[32m0.0013\u001b[0m       0.9918        0.0345  0.4659\n",
      "     14             0.9698        0.0020       0.9753        0.0755  0.4777\n",
      "     15             \u001b[36m0.9908\u001b[0m        0.0106       \u001b[35m0.9927\u001b[0m        0.0375  0.4684\n",
      "Epoch 00016: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     16             0.9125        0.0223       0.9249        0.1896  0.4778\n",
      "     17             0.9840        0.0223       0.9872        0.0459  0.4798\n",
      "     18             0.9830        0.0056       0.9863        0.0409  0.4781\n",
      "Epoch 00019: reducing learning rate of group 0 to 2.0000e-06.\n",
      "     19             0.9869        0.0026       0.9895        0.0384  0.4696\n",
      "     20             0.9869        0.0023       0.9895        0.0377  0.4797\n",
      "     21             0.9875        0.0018       0.9899        0.0369  0.4797\n",
      "Epoch 00022: reducing learning rate of group 0 to 1.0000e-06.\n",
      "     22             0.9869        0.0019       0.9895        0.0373  0.4757\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 13/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.984) f1_score: (test=0.980) total time=  11.0s\n",
      "[CV 2/4; 13/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4227\u001b[0m        \u001b[32m0.4916\u001b[0m       \u001b[35m0.7274\u001b[0m        \u001b[31m0.6930\u001b[0m  0.4762\n",
      "      2             \u001b[36m0.8384\u001b[0m        \u001b[32m0.2152\u001b[0m       \u001b[35m0.8571\u001b[0m        \u001b[31m0.2699\u001b[0m  0.4657\n",
      "      3             \u001b[36m0.9673\u001b[0m        \u001b[32m0.1004\u001b[0m       \u001b[35m0.9743\u001b[0m        \u001b[31m0.0998\u001b[0m  0.4653\n",
      "      4             0.9673        \u001b[32m0.0544\u001b[0m       0.9739        \u001b[31m0.0706\u001b[0m  0.4748\n",
      "      5             \u001b[36m0.9676\u001b[0m        \u001b[32m0.0356\u001b[0m       0.9739        0.0729  0.4672\n",
      "      6             0.9598        \u001b[32m0.0294\u001b[0m       0.9675        0.0925  0.4635\n",
      "      7             \u001b[36m0.9790\u001b[0m        0.0313       \u001b[35m0.9835\u001b[0m        0.0730  0.4638\n",
      "      8             0.9730        \u001b[32m0.0185\u001b[0m       0.9785        0.0867  0.4636\n",
      "      9             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0152\u001b[0m       \u001b[35m0.9872\u001b[0m        \u001b[31m0.0653\u001b[0m  0.4638\n",
      "     10             0.9726        \u001b[32m0.0077\u001b[0m       0.9780        0.0710  0.4657\n",
      "     11             0.9831        \u001b[32m0.0035\u001b[0m       0.9867        0.0872  0.4726\n",
      "     12             0.9832        \u001b[32m0.0021\u001b[0m       0.9867        0.0713  0.4694\n",
      "     13             0.9833        \u001b[32m0.0016\u001b[0m       0.9867        \u001b[31m0.0635\u001b[0m  0.4635\n",
      "     14             \u001b[36m0.9867\u001b[0m        \u001b[32m0.0015\u001b[0m       \u001b[35m0.9895\u001b[0m        0.0704  0.4755\n",
      "     15             0.9759        \u001b[32m0.0011\u001b[0m       0.9808        0.0764  0.4682\n",
      "     16             0.9842        0.0020       0.9876        0.0932  0.4686\n",
      "     17             0.9827        \u001b[32m0.0008\u001b[0m       0.9863        0.0677  0.4729\n",
      "     18             \u001b[36m0.9872\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9899\u001b[0m        0.0683  0.4663\n",
      "     19             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0003\u001b[0m       \u001b[35m0.9904\u001b[0m        0.0710  0.4691\n",
      "     20             0.9855        \u001b[32m0.0002\u001b[0m       0.9885        0.0703  0.4724\n",
      "     21             0.9867        \u001b[32m0.0002\u001b[0m       0.9895        0.0681  0.4729\n",
      "     22             0.9867        \u001b[32m0.0001\u001b[0m       0.9895        0.0696  0.4713\n",
      "     23             0.9866        0.0001       0.9895        0.0734  0.4734\n",
      "     24             0.9866        0.0001       0.9895        0.0733  0.4731\n",
      "     25             0.9838        \u001b[32m0.0001\u001b[0m       0.9872        0.0733  0.4638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     26             0.9838        \u001b[32m0.0001\u001b[0m       0.9872        0.0737  0.4688\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 13/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.990) f1_score: (test=0.987) total time=  12.8s\n",
      "[CV 3/4; 13/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4980\u001b[0m        \u001b[32m0.4672\u001b[0m       \u001b[35m0.7201\u001b[0m        \u001b[31m0.6717\u001b[0m  0.4741\n",
      "      2             \u001b[36m0.8507\u001b[0m        \u001b[32m0.2033\u001b[0m       \u001b[35m0.8791\u001b[0m        \u001b[31m0.3158\u001b[0m  0.4714\n",
      "      3             \u001b[36m0.9283\u001b[0m        \u001b[32m0.0926\u001b[0m       \u001b[35m0.9404\u001b[0m        \u001b[31m0.1230\u001b[0m  0.4773\n",
      "      4             \u001b[36m0.9562\u001b[0m        \u001b[32m0.0791\u001b[0m       \u001b[35m0.9647\u001b[0m        \u001b[31m0.0919\u001b[0m  0.4753\n",
      "      5             \u001b[36m0.9737\u001b[0m        \u001b[32m0.0440\u001b[0m       \u001b[35m0.9794\u001b[0m        \u001b[31m0.0800\u001b[0m  0.4711\n",
      "      6             0.9694        \u001b[32m0.0309\u001b[0m       0.9757        0.0878  0.4727\n",
      "      7             \u001b[36m0.9802\u001b[0m        \u001b[32m0.0264\u001b[0m       \u001b[35m0.9844\u001b[0m        \u001b[31m0.0680\u001b[0m  0.4735\n",
      "      8             \u001b[36m0.9803\u001b[0m        \u001b[32m0.0120\u001b[0m       0.9844        \u001b[31m0.0657\u001b[0m  0.4729\n",
      "      9             \u001b[36m0.9815\u001b[0m        \u001b[32m0.0045\u001b[0m       \u001b[35m0.9853\u001b[0m        \u001b[31m0.0638\u001b[0m  0.4685\n",
      "     10             \u001b[36m0.9820\u001b[0m        \u001b[32m0.0034\u001b[0m       \u001b[35m0.9858\u001b[0m        \u001b[31m0.0586\u001b[0m  0.4727\n",
      "     11             0.9809        \u001b[32m0.0019\u001b[0m       0.9849        0.0618  0.4714\n",
      "     12             0.9807        0.0021       0.9849        0.0953  0.4729\n",
      "     13             \u001b[36m0.9832\u001b[0m        \u001b[32m0.0015\u001b[0m       \u001b[35m0.9867\u001b[0m        0.0734  0.4693\n",
      "     14             0.9820        \u001b[32m0.0005\u001b[0m       0.9858        0.0688  0.4746\n",
      "     15             \u001b[36m0.9837\u001b[0m        \u001b[32m0.0004\u001b[0m       \u001b[35m0.9872\u001b[0m        0.0706  0.4662\n",
      "     16             0.9826        \u001b[32m0.0003\u001b[0m       0.9863        0.0677  0.4686\n",
      "     17             \u001b[36m0.9843\u001b[0m        0.0004       \u001b[35m0.9876\u001b[0m        0.0726  0.4728\n",
      "     18             0.9798        0.0005       0.9840        0.0684  0.4710\n",
      "     19             0.9837        \u001b[32m0.0002\u001b[0m       0.9872        0.0703  0.4753\n",
      "     20             0.9831        \u001b[32m0.0002\u001b[0m       0.9867        0.0708  0.4687\n",
      "     21             0.9843        \u001b[32m0.0002\u001b[0m       0.9876        0.0732  0.4732\n",
      "     22             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0001\u001b[0m       \u001b[35m0.9885\u001b[0m        0.0734  0.4705\n",
      "     23             0.9838        0.0002       0.9872        0.0713  0.4728\n",
      "     24             0.9837        0.0001       0.9872        0.0730  0.4713\n",
      "Epoch 00025: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     25             0.9843        0.0001       0.9876        0.0741  0.4729\n",
      "     26             0.9837        \u001b[32m0.0001\u001b[0m       0.9872        0.0744  0.4713\n",
      "     27             0.9826        0.0001       0.9863        0.0727  0.4754\n",
      "     28             0.9820        0.0001       0.9858        0.0730  0.4686\n",
      "     29             0.9820        \u001b[32m0.0001\u001b[0m       0.9858        0.0730  0.4730\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 13/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.987) f1_score: (test=0.984) total time=  14.3s\n",
      "[CV 4/4; 13/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5195\u001b[0m        \u001b[32m0.4685\u001b[0m       \u001b[35m0.5799\u001b[0m        \u001b[31m0.6777\u001b[0m  0.4743\n",
      "      2             \u001b[36m0.8433\u001b[0m        \u001b[32m0.2016\u001b[0m       \u001b[35m0.8649\u001b[0m        \u001b[31m0.2856\u001b[0m  0.4634\n",
      "      3             \u001b[36m0.9425\u001b[0m        \u001b[32m0.1101\u001b[0m       \u001b[35m0.9528\u001b[0m        \u001b[31m0.1066\u001b[0m  0.4707\n",
      "      4             \u001b[36m0.9550\u001b[0m        \u001b[32m0.0486\u001b[0m       \u001b[35m0.9634\u001b[0m        \u001b[31m0.0768\u001b[0m  0.4712\n",
      "      5             \u001b[36m0.9568\u001b[0m        \u001b[32m0.0301\u001b[0m       \u001b[35m0.9670\u001b[0m        0.1854  0.4704\n",
      "      6             \u001b[36m0.9744\u001b[0m        \u001b[32m0.0255\u001b[0m       \u001b[35m0.9798\u001b[0m        \u001b[31m0.0740\u001b[0m  0.4722\n",
      "      7             0.9742        \u001b[32m0.0207\u001b[0m       0.9794        0.0751  0.4713\n",
      "      8             \u001b[36m0.9774\u001b[0m        \u001b[32m0.0168\u001b[0m       \u001b[35m0.9821\u001b[0m        \u001b[31m0.0715\u001b[0m  0.4752\n",
      "      9             0.9757        \u001b[32m0.0132\u001b[0m       0.9808        0.0791  0.4706\n",
      "     10             \u001b[36m0.9798\u001b[0m        \u001b[32m0.0072\u001b[0m       \u001b[35m0.9840\u001b[0m        \u001b[31m0.0632\u001b[0m  0.4734\n",
      "     11             0.9668        0.0133       0.9734        0.0899  0.4783\n",
      "     12             0.9791        0.0083       0.9835        0.0772  0.4665\n",
      "     13             \u001b[36m0.9825\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9863\u001b[0m        0.0794  0.4771\n",
      "     14             \u001b[36m0.9837\u001b[0m        \u001b[32m0.0013\u001b[0m       \u001b[35m0.9872\u001b[0m        0.0819  0.4663\n",
      "     15             0.9837        \u001b[32m0.0004\u001b[0m       0.9872        0.0772  0.4776\n",
      "     16             \u001b[36m0.9860\u001b[0m        \u001b[32m0.0003\u001b[0m       \u001b[35m0.9890\u001b[0m        0.0779  0.4692\n",
      "     17             0.9849        \u001b[32m0.0003\u001b[0m       0.9881        0.0797  0.4744\n",
      "     18             0.9854        \u001b[32m0.0002\u001b[0m       0.9885        0.0784  0.4663\n",
      "     19             0.9849        \u001b[32m0.0002\u001b[0m       0.9881        0.0766  0.4776\n",
      "     20             0.9832        0.0002       0.9867        0.0750  0.4659\n",
      "     21             0.9843        \u001b[32m0.0001\u001b[0m       0.9876        0.0794  0.4803\n",
      "     22             0.9837        \u001b[32m0.0001\u001b[0m       0.9872        0.0789  0.4787\n",
      "     23             0.9860        \u001b[32m0.0001\u001b[0m       0.9890        0.0803  0.4654\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 13/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  11.5s\n",
      "[CV 1/4; 14/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4182\u001b[0m        \u001b[32m0.4088\u001b[0m       \u001b[35m0.7187\u001b[0m        \u001b[31m1.1458\u001b[0m  1.8156\n",
      "      2             \u001b[36m0.8214\u001b[0m        \u001b[32m0.2226\u001b[0m       \u001b[35m0.8475\u001b[0m        \u001b[31m0.3187\u001b[0m  1.8093\n",
      "      3             \u001b[36m0.8853\u001b[0m        \u001b[32m0.1305\u001b[0m       \u001b[35m0.8997\u001b[0m        \u001b[31m0.1775\u001b[0m  1.8106\n",
      "      4             \u001b[36m0.8952\u001b[0m        \u001b[32m0.1271\u001b[0m       \u001b[35m0.9088\u001b[0m        0.1791  1.8077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      5             \u001b[36m0.9816\u001b[0m        \u001b[32m0.0739\u001b[0m       \u001b[35m0.9853\u001b[0m        \u001b[31m0.0632\u001b[0m  1.8153\n",
      "      6             0.9654        \u001b[32m0.0632\u001b[0m       0.9721        0.0728  1.8175\n",
      "      7             0.9812        \u001b[32m0.0349\u001b[0m       0.9849        \u001b[31m0.0396\u001b[0m  1.8200\n",
      "      8             0.9638        \u001b[32m0.0276\u001b[0m       0.9702        0.0689  1.8122\n",
      "      9             0.9443        0.0449       0.9542        0.1899  1.8143\n",
      "     10             0.9736        0.0395       0.9785        0.0524  1.8152\n",
      "Epoch 00011: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     11             0.9764        0.0353       0.9812        0.0825  1.8125\n",
      "     12             \u001b[36m0.9909\u001b[0m        \u001b[32m0.0160\u001b[0m       \u001b[35m0.9927\u001b[0m        \u001b[31m0.0201\u001b[0m  1.8112\n",
      "     13             \u001b[36m0.9920\u001b[0m        \u001b[32m0.0084\u001b[0m       \u001b[35m0.9936\u001b[0m        \u001b[31m0.0166\u001b[0m  1.8171\n",
      "     14             0.9920        \u001b[32m0.0054\u001b[0m       0.9936        \u001b[31m0.0163\u001b[0m  1.8135\n",
      "     15             0.9920        \u001b[32m0.0042\u001b[0m       0.9936        \u001b[31m0.0158\u001b[0m  1.8107\n",
      "     16             \u001b[36m0.9932\u001b[0m        \u001b[32m0.0037\u001b[0m       \u001b[35m0.9945\u001b[0m        \u001b[31m0.0147\u001b[0m  1.8055\n",
      "     17             \u001b[36m0.9937\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9950\u001b[0m        0.0148  1.8042\n",
      "     18             \u001b[36m0.9943\u001b[0m        \u001b[32m0.0028\u001b[0m       \u001b[35m0.9954\u001b[0m        \u001b[31m0.0141\u001b[0m  1.8103\n",
      "     19             0.9943        \u001b[32m0.0026\u001b[0m       0.9954        0.0147  1.7957\n",
      "     20             0.9937        \u001b[32m0.0019\u001b[0m       0.9950        0.0146  1.8034\n",
      "     21             0.9943        \u001b[32m0.0017\u001b[0m       0.9954        \u001b[31m0.0140\u001b[0m  1.8142\n",
      "     22             0.9943        0.0018       0.9954        \u001b[31m0.0136\u001b[0m  1.8103\n",
      "     23             0.9943        \u001b[32m0.0016\u001b[0m       0.9954        0.0138  1.8154\n",
      "     24             0.9943        \u001b[32m0.0016\u001b[0m       0.9954        0.0141  1.8150\n",
      "     25             0.9943        \u001b[32m0.0014\u001b[0m       0.9954        0.0145  1.8063\n",
      "     26             \u001b[36m0.9949\u001b[0m        \u001b[32m0.0013\u001b[0m       \u001b[35m0.9959\u001b[0m        0.0150  1.8150\n",
      "     27             0.9943        \u001b[32m0.0013\u001b[0m       0.9954        0.0153  1.8134\n",
      "     28             \u001b[36m0.9949\u001b[0m        \u001b[32m0.0011\u001b[0m       0.9959        0.0141  1.8162\n",
      "     29             \u001b[36m0.9960\u001b[0m        \u001b[32m0.0010\u001b[0m       \u001b[35m0.9968\u001b[0m        0.0139  1.8186\n",
      "     30             0.9948        \u001b[32m0.0009\u001b[0m       0.9959        0.0149  1.8085\n",
      "     31             0.9960        \u001b[32m0.0009\u001b[0m       0.9968        0.0139  1.8004\n",
      "     32             0.9960        0.0009       0.9968        0.0139  1.8134\n",
      "     33             0.9960        \u001b[32m0.0007\u001b[0m       0.9968        0.0142  1.8110\n",
      "     34             0.9954        0.0007       0.9963        0.0149  1.8137\n",
      "     35             0.9960        0.0008       0.9968        0.0142  1.8065\n",
      "     36             0.9960        \u001b[32m0.0006\u001b[0m       0.9968        \u001b[31m0.0132\u001b[0m  1.8067\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 14/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.989) f1_score: (test=0.987) total time= 1.1min\n",
      "[CV 2/4; 14/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5021\u001b[0m        \u001b[32m0.4170\u001b[0m       \u001b[35m0.6464\u001b[0m        \u001b[31m0.7639\u001b[0m  1.8084\n",
      "      2             \u001b[36m0.7913\u001b[0m        \u001b[32m0.2444\u001b[0m       \u001b[35m0.8223\u001b[0m        \u001b[31m0.3871\u001b[0m  1.7893\n",
      "      3             \u001b[36m0.8378\u001b[0m        \u001b[32m0.1671\u001b[0m       \u001b[35m0.8617\u001b[0m        0.5586  1.7823\n",
      "      4             \u001b[36m0.9425\u001b[0m        0.1755       \u001b[35m0.9546\u001b[0m        \u001b[31m0.1569\u001b[0m  1.7861\n",
      "      5             0.9272        \u001b[32m0.1154\u001b[0m       0.9395        \u001b[31m0.1192\u001b[0m  1.7871\n",
      "      6             0.9314        \u001b[32m0.0815\u001b[0m       0.9427        \u001b[31m0.1048\u001b[0m  1.7942\n",
      "      7             \u001b[36m0.9562\u001b[0m        \u001b[32m0.0543\u001b[0m       \u001b[35m0.9647\u001b[0m        0.1412  1.7931\n",
      "      8             \u001b[36m0.9642\u001b[0m        0.0552       \u001b[35m0.9716\u001b[0m        \u001b[31m0.1031\u001b[0m  1.7906\n",
      "      9             0.9579        0.0648       0.9670        0.1404  1.7868\n",
      "     10             0.9208        \u001b[32m0.0435\u001b[0m       0.9414        0.2889  1.7913\n",
      "     11             \u001b[36m0.9814\u001b[0m        0.0480       \u001b[35m0.9853\u001b[0m        \u001b[31m0.0554\u001b[0m  1.7864\n",
      "     12             0.8893        \u001b[32m0.0354\u001b[0m       0.9043        0.2796  1.7911\n",
      "     13             0.9803        0.0445       0.9844        0.0758  1.7865\n",
      "     14             0.9771        \u001b[32m0.0199\u001b[0m       0.9817        0.0560  1.7873\n",
      "     15             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0156\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0535\u001b[0m  1.7883\n",
      "     16             0.9239        0.0307       0.9363        0.1861  1.7864\n",
      "     17             0.8707        0.0593       0.8864        0.2919  1.7868\n",
      "Epoch 00018: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     18             0.9597        0.0760       0.9684        0.1192  1.7841\n",
      "     19             0.9816        0.0260       0.9853        \u001b[31m0.0515\u001b[0m  1.7902\n",
      "     20             0.9838        0.0164       0.9872        \u001b[31m0.0459\u001b[0m  1.7877\n",
      "     21             0.9850        \u001b[32m0.0124\u001b[0m       0.9881        \u001b[31m0.0442\u001b[0m  1.7873\n",
      "     22             0.9855        \u001b[32m0.0100\u001b[0m       0.9885        \u001b[31m0.0432\u001b[0m  1.7869\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 14/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.992) f1_score: (test=0.990) total time=  41.4s\n",
      "[CV 3/4; 14/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5160\u001b[0m        \u001b[32m0.4539\u001b[0m       \u001b[35m0.7174\u001b[0m        \u001b[31m0.7230\u001b[0m  1.7973\n",
      "      2             \u001b[36m0.7920\u001b[0m        \u001b[32m0.2235\u001b[0m       \u001b[35m0.8200\u001b[0m        \u001b[31m0.4014\u001b[0m  1.7924\n",
      "      3             \u001b[36m0.8966\u001b[0m        \u001b[32m0.1666\u001b[0m       \u001b[35m0.9116\u001b[0m        \u001b[31m0.1714\u001b[0m  1.7766\n",
      "      4             \u001b[36m0.9441\u001b[0m        \u001b[32m0.1035\u001b[0m       \u001b[35m0.9560\u001b[0m        \u001b[31m0.1583\u001b[0m  1.7466\n",
      "      5             0.9370        \u001b[32m0.0860\u001b[0m       0.9524        0.2235  1.7080\n",
      "      6             0.8838        0.1138       0.9015        0.2641  1.7320\n",
      "      7             0.9440        0.1112       0.9542        \u001b[31m0.1017\u001b[0m  1.8157\n",
      "      8             \u001b[36m0.9702\u001b[0m        \u001b[32m0.0628\u001b[0m       \u001b[35m0.9762\u001b[0m        \u001b[31m0.0662\u001b[0m  1.8037\n",
      "      9             0.9299        \u001b[32m0.0480\u001b[0m       0.9478        0.2465  1.7549\n",
      "     10             0.9637        \u001b[32m0.0412\u001b[0m       0.9707        0.0905  1.7739\n",
      "     11             \u001b[36m0.9709\u001b[0m        0.0414       \u001b[35m0.9766\u001b[0m        0.0782  1.7641\n",
      "     12             \u001b[36m0.9733\u001b[0m        \u001b[32m0.0313\u001b[0m       \u001b[35m0.9794\u001b[0m        0.1091  1.6976\n",
      "     13             0.9532        0.0593       0.9629        0.1866  1.6689\n",
      "     14             0.9498        0.0643       0.9588        0.1279  1.6548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     15             0.8654        0.0683       0.9061        0.4980  1.6362\n",
      "     16             \u001b[36m0.9803\u001b[0m        \u001b[32m0.0288\u001b[0m       \u001b[35m0.9844\u001b[0m        \u001b[31m0.0583\u001b[0m  1.6551\n",
      "     17             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0163\u001b[0m       \u001b[35m0.9872\u001b[0m        \u001b[31m0.0520\u001b[0m  1.6281\n",
      "     18             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0126\u001b[0m       0.9872        \u001b[31m0.0509\u001b[0m  1.6277\n",
      "     19             \u001b[36m0.9872\u001b[0m        \u001b[32m0.0114\u001b[0m       \u001b[35m0.9899\u001b[0m        \u001b[31m0.0492\u001b[0m  1.6759\n",
      "     20             0.9860        \u001b[32m0.0099\u001b[0m       0.9890        0.0533  1.6749\n",
      "     21             0.9872        \u001b[32m0.0084\u001b[0m       0.9899        \u001b[31m0.0485\u001b[0m  1.6344\n",
      "     22             0.9872        \u001b[32m0.0071\u001b[0m       0.9899        0.0498  1.7132\n",
      "     23             0.9866        \u001b[32m0.0069\u001b[0m       0.9895        0.0495  1.7168\n",
      "     24             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0055\u001b[0m       \u001b[35m0.9904\u001b[0m        0.0494  1.6571\n",
      "     25             0.9866        \u001b[32m0.0053\u001b[0m       0.9895        0.0525  1.6383\n",
      "     26             0.9866        \u001b[32m0.0045\u001b[0m       0.9895        0.0515  1.6996\n",
      "     27             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0044\u001b[0m       0.9904        \u001b[31m0.0480\u001b[0m  1.6843\n",
      "     28             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0041\u001b[0m       \u001b[35m0.9908\u001b[0m        0.0494  1.7158\n",
      "     29             0.9866        \u001b[32m0.0034\u001b[0m       0.9895        0.0512  1.6800\n",
      "     30             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0032\u001b[0m       0.9908        0.0484  1.7107\n",
      "     31             0.9878        \u001b[32m0.0024\u001b[0m       0.9904        0.0483  1.6732\n",
      "     32             0.9884        0.0024       0.9908        0.0514  1.6396\n",
      "     33             \u001b[36m0.9884\u001b[0m        0.0024       0.9908        0.0500  1.6353\n",
      "Epoch 00034: reducing learning rate of group 0 to 8.0000e-06.\n",
      "     34             0.9878        0.0026       0.9904        \u001b[31m0.0469\u001b[0m  1.6734\n",
      "     35             0.9878        \u001b[32m0.0020\u001b[0m       0.9904        \u001b[31m0.0467\u001b[0m  1.6877\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 14/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.989) f1_score: (test=0.987) total time= 1.0min\n",
      "[CV 4/4; 14/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4318\u001b[0m        \u001b[32m0.4151\u001b[0m       \u001b[35m0.7183\u001b[0m        \u001b[31m1.0892\u001b[0m  1.7201\n",
      "      2             \u001b[36m0.8336\u001b[0m        \u001b[32m0.2058\u001b[0m       \u001b[35m0.8530\u001b[0m        \u001b[31m0.2657\u001b[0m  1.7001\n",
      "      3             0.7145        \u001b[32m0.1322\u001b[0m       0.7242        0.8532  1.6656\n",
      "      4             \u001b[36m0.9705\u001b[0m        \u001b[32m0.0864\u001b[0m       \u001b[35m0.9766\u001b[0m        \u001b[31m0.0830\u001b[0m  1.7043\n",
      "      5             0.9347        \u001b[32m0.0578\u001b[0m       0.9473        0.1642  1.6655\n",
      "      6             \u001b[36m0.9770\u001b[0m        \u001b[32m0.0538\u001b[0m       \u001b[35m0.9817\u001b[0m        \u001b[31m0.0485\u001b[0m  1.6312\n",
      "      7             0.8990        0.0727       0.9134        0.2514  1.6658\n",
      "      8             0.9610        \u001b[32m0.0538\u001b[0m       0.9689        0.1165  1.6939\n",
      "      9             0.9745        \u001b[32m0.0525\u001b[0m       0.9798        0.0850  1.7068\n",
      "     10             0.9700        \u001b[32m0.0298\u001b[0m       0.9762        0.1063  1.6918\n",
      "     11             \u001b[36m0.9855\u001b[0m        0.0309       \u001b[35m0.9885\u001b[0m        0.0617  1.6600\n",
      "     12             0.9150        0.0482       0.9281        0.2121  1.6312\n",
      "     13             0.9721        \u001b[32m0.0194\u001b[0m       0.9785        0.1277  1.6515\n",
      "     14             0.9819        \u001b[32m0.0128\u001b[0m       0.9858        0.0860  1.6473\n",
      "     15             0.9837        0.0252       0.9872        0.0553  1.6453\n",
      "     16             0.9727        0.0155       0.9780        0.0684  1.7317\n",
      "Epoch 00017: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     17             0.9793        0.0173       0.9840        0.0944  1.7035\n",
      "     18             \u001b[36m0.9913\u001b[0m        \u001b[32m0.0066\u001b[0m       \u001b[35m0.9931\u001b[0m        \u001b[31m0.0407\u001b[0m  1.6946\n",
      "     19             \u001b[36m0.9924\u001b[0m        \u001b[32m0.0023\u001b[0m       \u001b[35m0.9940\u001b[0m        0.0437  1.7308\n",
      "     20             0.9913        \u001b[32m0.0018\u001b[0m       0.9931        0.0430  1.6519\n",
      "     21             0.9919        \u001b[32m0.0013\u001b[0m       0.9936        0.0416  1.6820\n",
      "     22             0.9919        \u001b[32m0.0012\u001b[0m       0.9936        0.0420  1.7225\n",
      "     23             0.9919        \u001b[32m0.0009\u001b[0m       0.9936        0.0426  1.7291\n",
      "     24             \u001b[36m0.9930\u001b[0m        0.0009       \u001b[35m0.9945\u001b[0m        0.0418  1.7345\n",
      "     25             0.9924        0.0009       0.9940        0.0430  1.8010\n",
      "     26             0.9919        \u001b[32m0.0008\u001b[0m       0.9936        0.0417  1.8137\n",
      "     27             0.9924        0.0010       0.9940        0.0422  1.8020\n",
      "     28             0.9924        \u001b[32m0.0007\u001b[0m       0.9940        0.0432  1.7200\n",
      "     29             0.9930        \u001b[32m0.0007\u001b[0m       0.9945        0.0433  1.7165\n",
      "     30             \u001b[36m0.9936\u001b[0m        \u001b[32m0.0006\u001b[0m       \u001b[35m0.9950\u001b[0m        0.0427  1.7196\n",
      "     31             0.9924        \u001b[32m0.0006\u001b[0m       0.9940        0.0426  1.7207\n",
      "     32             0.9924        \u001b[32m0.0005\u001b[0m       0.9940        0.0446  1.7177\n",
      "     33             0.9936        0.0006       0.9950        0.0432  1.7172\n",
      "     34             0.9936        \u001b[32m0.0004\u001b[0m       0.9950        0.0437  1.7157\n",
      "     35             0.9930        0.0006       0.9945        0.0454  1.7260\n",
      "     36             0.9936        0.0005       0.9950        0.0434  1.7177\n",
      "     37             0.9936        \u001b[32m0.0004\u001b[0m       0.9950        0.0449  1.7331\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 14/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.996) f1_score: (test=0.994) total time= 1.1min\n",
      "[CV 1/4; 15/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4199\u001b[0m        \u001b[32m0.4641\u001b[0m       \u001b[35m0.7238\u001b[0m        \u001b[31m0.7068\u001b[0m  0.4978\n",
      "      2             \u001b[36m0.8837\u001b[0m        \u001b[32m0.1933\u001b[0m       \u001b[35m0.9011\u001b[0m        \u001b[31m0.2151\u001b[0m  0.4922\n",
      "      3             \u001b[36m0.9570\u001b[0m        \u001b[32m0.0900\u001b[0m       \u001b[35m0.9652\u001b[0m        \u001b[31m0.1062\u001b[0m  0.4946\n",
      "      4             \u001b[36m0.9597\u001b[0m        \u001b[32m0.0715\u001b[0m       \u001b[35m0.9675\u001b[0m        \u001b[31m0.0975\u001b[0m  0.4925\n",
      "      5             \u001b[36m0.9795\u001b[0m        \u001b[32m0.0367\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0563\u001b[0m  0.4781\n",
      "      6             0.9761        \u001b[32m0.0200\u001b[0m       0.9808        0.0590  0.4923\n",
      "      7             0.9766        \u001b[32m0.0170\u001b[0m       0.9812        0.0592  0.4990\n",
      "      8             \u001b[36m0.9801\u001b[0m        \u001b[32m0.0069\u001b[0m       \u001b[35m0.9840\u001b[0m        \u001b[31m0.0506\u001b[0m  0.4978\n",
      "      9             \u001b[36m0.9827\u001b[0m        \u001b[32m0.0028\u001b[0m       \u001b[35m0.9863\u001b[0m        0.0636  0.4838\n",
      "     10             0.9779        \u001b[32m0.0017\u001b[0m       0.9821        0.0582  0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     11             0.9817        \u001b[32m0.0008\u001b[0m       0.9853        \u001b[31m0.0480\u001b[0m  0.4688\n",
      "     12             0.9817        \u001b[32m0.0004\u001b[0m       0.9853        0.0514  0.4708\n",
      "     13             \u001b[36m0.9840\u001b[0m        \u001b[32m0.0003\u001b[0m       \u001b[35m0.9872\u001b[0m        0.0485  0.4691\n",
      "     14             \u001b[36m0.9846\u001b[0m        \u001b[32m0.0002\u001b[0m       \u001b[35m0.9876\u001b[0m        0.0502  0.4720\n",
      "     15             0.9846        \u001b[32m0.0002\u001b[0m       0.9876        0.0498  0.4718\n",
      "     16             \u001b[36m0.9874\u001b[0m        \u001b[32m0.0002\u001b[0m       \u001b[35m0.9899\u001b[0m        0.0514  0.4758\n",
      "     17             0.9868        0.0003       0.9895        0.0515  0.4666\n",
      "     18             0.9851        \u001b[32m0.0001\u001b[0m       0.9881        0.0514  0.4704\n",
      "     19             0.9851        \u001b[32m0.0001\u001b[0m       0.9881        0.0508  0.4704\n",
      "     20             0.9863        0.0002       0.9890        0.0549  0.4689\n",
      "     21             0.9846        \u001b[32m0.0001\u001b[0m       0.9876        0.0532  0.4750\n",
      "     22             0.9846        \u001b[32m0.0001\u001b[0m       0.9876        0.0527  0.4689\n",
      "     23             0.9812        0.0002       0.9849        0.0551  0.4815\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 15/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.987) f1_score: (test=0.984) total time=  11.7s\n",
      "[CV 2/4; 15/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4416\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.7229\u001b[0m  0.4941\n",
      "      2             \u001b[36m0.8562\u001b[0m        \u001b[32m0.1810\u001b[0m       \u001b[35m0.8905\u001b[0m        \u001b[31m0.3233\u001b[0m  0.4920\n",
      "      3             \u001b[36m0.9645\u001b[0m        \u001b[32m0.0930\u001b[0m       \u001b[35m0.9716\u001b[0m        \u001b[31m0.0885\u001b[0m  0.4780\n",
      "      4             0.9577        \u001b[32m0.0570\u001b[0m       0.9670        0.1247  0.4845\n",
      "      5             \u001b[36m0.9678\u001b[0m        \u001b[32m0.0392\u001b[0m       \u001b[35m0.9748\u001b[0m        0.1042  0.4768\n",
      "      6             \u001b[36m0.9723\u001b[0m        0.0423       \u001b[35m0.9780\u001b[0m        \u001b[31m0.0828\u001b[0m  0.4944\n",
      "      7             0.9593        \u001b[32m0.0174\u001b[0m       0.9670        0.0886  0.4901\n",
      "      8             \u001b[36m0.9742\u001b[0m        \u001b[32m0.0090\u001b[0m       \u001b[35m0.9794\u001b[0m        \u001b[31m0.0697\u001b[0m  0.4971\n",
      "      9             \u001b[36m0.9826\u001b[0m        \u001b[32m0.0035\u001b[0m       \u001b[35m0.9863\u001b[0m        \u001b[31m0.0643\u001b[0m  0.4935\n",
      "     10             0.9770        0.0038       0.9817        0.0726  0.4957\n",
      "     11             \u001b[36m0.9831\u001b[0m        \u001b[32m0.0012\u001b[0m       \u001b[35m0.9867\u001b[0m        \u001b[31m0.0632\u001b[0m  0.4902\n",
      "     12             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0596\u001b[0m  0.4969\n",
      "     13             0.9849        \u001b[32m0.0004\u001b[0m       0.9881        0.0601  0.4886\n",
      "     14             0.9844        \u001b[32m0.0003\u001b[0m       0.9876        0.0604  0.4716\n",
      "     15             0.9850        \u001b[32m0.0002\u001b[0m       0.9881        0.0607  0.4725\n",
      "     16             0.9850        \u001b[32m0.0002\u001b[0m       0.9881        0.0630  0.4753\n",
      "     17             0.9838        0.0002       0.9872        0.0607  0.4698\n",
      "     18             0.9849        \u001b[32m0.0001\u001b[0m       0.9881        0.0640  0.4728\n",
      "     19             0.9843        \u001b[32m0.0001\u001b[0m       0.9876        0.0615  0.4713\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 15/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.987) f1_score: (test=0.984) total time=   9.8s\n",
      "[CV 3/4; 15/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4216\u001b[0m        \u001b[32m0.4982\u001b[0m       \u001b[35m0.7288\u001b[0m        \u001b[31m0.8913\u001b[0m  0.5051\n",
      "      2             \u001b[36m0.8542\u001b[0m        \u001b[32m0.2274\u001b[0m       \u001b[35m0.8855\u001b[0m        \u001b[31m0.3442\u001b[0m  0.4981\n",
      "      3             \u001b[36m0.9133\u001b[0m        \u001b[32m0.1089\u001b[0m       \u001b[35m0.9272\u001b[0m        \u001b[31m0.1705\u001b[0m  0.4941\n",
      "      4             \u001b[36m0.9458\u001b[0m        \u001b[32m0.0823\u001b[0m       \u001b[35m0.9556\u001b[0m        \u001b[31m0.0931\u001b[0m  0.4950\n",
      "      5             \u001b[36m0.9730\u001b[0m        \u001b[32m0.0372\u001b[0m       \u001b[35m0.9785\u001b[0m        \u001b[31m0.0744\u001b[0m  0.5034\n",
      "      6             0.9609        \u001b[32m0.0173\u001b[0m       0.9684        0.0914  0.4829\n",
      "      7             \u001b[36m0.9796\u001b[0m        0.0239       \u001b[35m0.9840\u001b[0m        0.0843  0.4743\n",
      "      8             \u001b[36m0.9809\u001b[0m        \u001b[32m0.0070\u001b[0m       \u001b[35m0.9849\u001b[0m        0.0747  0.4695\n",
      "      9             \u001b[36m0.9836\u001b[0m        \u001b[32m0.0034\u001b[0m       \u001b[35m0.9872\u001b[0m        0.0856  0.4734\n",
      "     10             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0019\u001b[0m       0.9872        0.0815  0.4701\n",
      "     11             \u001b[36m0.9849\u001b[0m        \u001b[32m0.0008\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0732\u001b[0m  0.4716\n",
      "     12             0.9838        \u001b[32m0.0004\u001b[0m       0.9872        0.0760  0.4676\n",
      "     13             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0003\u001b[0m       \u001b[35m0.9885\u001b[0m        0.0757  0.4686\n",
      "     14             \u001b[36m0.9872\u001b[0m        \u001b[32m0.0002\u001b[0m       \u001b[35m0.9899\u001b[0m        0.0749  0.4695\n",
      "     15             0.9861        \u001b[32m0.0002\u001b[0m       0.9890        0.0756  0.4729\n",
      "     16             0.9866        0.0003       0.9895        0.0748  0.4758\n",
      "     17             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0001\u001b[0m       \u001b[35m0.9904\u001b[0m        0.0800  0.4729\n",
      "     18             0.9855        \u001b[32m0.0001\u001b[0m       0.9885        0.0784  0.4732\n",
      "     19             0.9861        0.0001       0.9890        0.0793  0.4930\n",
      "     20             0.9872        \u001b[32m0.0001\u001b[0m       0.9899        0.0774  0.4867\n",
      "     21             0.9872        0.0001       0.9899        0.0775  0.4869\n",
      "     22             0.9861        \u001b[32m0.0001\u001b[0m       0.9890        0.0801  0.4764\n",
      "     23             0.9866        \u001b[32m0.0001\u001b[0m       0.9895        0.0813  0.4759\n",
      "     24             0.9861        \u001b[32m0.0001\u001b[0m       0.9890        0.0816  0.4791\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 15/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  12.2s\n",
      "[CV 4/4; 15/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4605\u001b[0m        \u001b[32m0.4347\u001b[0m       \u001b[35m0.7224\u001b[0m        \u001b[31m0.7271\u001b[0m  0.4898\n",
      "      2             \u001b[36m0.8681\u001b[0m        \u001b[32m0.1600\u001b[0m       \u001b[35m0.8887\u001b[0m        \u001b[31m0.2233\u001b[0m  0.4970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3             \u001b[36m0.9652\u001b[0m        \u001b[32m0.0784\u001b[0m       \u001b[35m0.9721\u001b[0m        \u001b[31m0.0868\u001b[0m  0.4882\n",
      "      4             \u001b[36m0.9690\u001b[0m        \u001b[32m0.0443\u001b[0m       \u001b[35m0.9753\u001b[0m        0.0898  0.4878\n",
      "      5             0.9496        \u001b[32m0.0367\u001b[0m       0.9615        0.1831  0.4993\n",
      "      6             \u001b[36m0.9766\u001b[0m        \u001b[32m0.0145\u001b[0m       \u001b[35m0.9817\u001b[0m        0.0936  0.4826\n",
      "      7             \u001b[36m0.9808\u001b[0m        \u001b[32m0.0076\u001b[0m       \u001b[35m0.9849\u001b[0m        \u001b[31m0.0693\u001b[0m  0.4734\n",
      "      8             0.9690        \u001b[32m0.0074\u001b[0m       0.9753        0.0808  0.4715\n",
      "      9             0.9808        \u001b[32m0.0048\u001b[0m       0.9849        0.0776  0.4783\n",
      "     10             0.9731        0.0081       0.9789        0.1301  0.5086\n",
      "     11             0.9692        0.0084       0.9753        0.0926  0.4993\n",
      "Epoch 00012: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     12             0.9680        0.0152       0.9743        0.1018  0.5037\n",
      "     13             0.9781        \u001b[32m0.0034\u001b[0m       0.9826        0.0822  0.4912\n",
      "     14             0.9775        \u001b[32m0.0014\u001b[0m       0.9821        0.0818  0.5002\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 15/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.990) f1_score: (test=0.988) total time=   7.5s\n",
      "[CV 1/4; 16/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.7193\u001b[0m        \u001b[32m0.5255\u001b[0m       \u001b[35m0.7668\u001b[0m        \u001b[31m0.5453\u001b[0m  1.3384\n",
      "      2             \u001b[36m0.8317\u001b[0m        \u001b[32m0.2965\u001b[0m       \u001b[35m0.8626\u001b[0m        \u001b[31m0.3621\u001b[0m  1.2999\n",
      "      3             \u001b[36m0.9136\u001b[0m        \u001b[32m0.1992\u001b[0m       \u001b[35m0.9290\u001b[0m        \u001b[31m0.1714\u001b[0m  1.3002\n",
      "      4             \u001b[36m0.9250\u001b[0m        \u001b[32m0.1589\u001b[0m       \u001b[35m0.9377\u001b[0m        \u001b[31m0.1430\u001b[0m  1.3402\n",
      "      5             0.8949        \u001b[32m0.1535\u001b[0m       0.9088        0.2067  1.3356\n",
      "      6             \u001b[36m0.9320\u001b[0m        \u001b[32m0.1359\u001b[0m       \u001b[35m0.9446\u001b[0m        0.1624  1.3610\n",
      "      7             \u001b[36m0.9588\u001b[0m        \u001b[32m0.0993\u001b[0m       \u001b[35m0.9661\u001b[0m        \u001b[31m0.0827\u001b[0m  1.2989\n",
      "      8             0.9578        \u001b[32m0.0986\u001b[0m       0.9656        0.0894  1.2908\n",
      "      9             \u001b[36m0.9669\u001b[0m        \u001b[32m0.0719\u001b[0m       \u001b[35m0.9730\u001b[0m        \u001b[31m0.0690\u001b[0m  1.3130\n",
      "     10             \u001b[36m0.9735\u001b[0m        \u001b[32m0.0586\u001b[0m       \u001b[35m0.9785\u001b[0m        \u001b[31m0.0568\u001b[0m  1.2982\n",
      "     11             0.9734        0.0656       0.9785        0.0585  1.2883\n",
      "     12             \u001b[36m0.9828\u001b[0m        0.0602       \u001b[35m0.9863\u001b[0m        0.0640  1.2897\n",
      "     13             0.9729        \u001b[32m0.0498\u001b[0m       0.9780        \u001b[31m0.0567\u001b[0m  1.2927\n",
      "     14             \u001b[36m0.9863\u001b[0m        \u001b[32m0.0346\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0374\u001b[0m  1.2884\n",
      "     15             0.9818        0.0377       0.9853        0.0416  1.2866\n",
      "     16             0.9862        \u001b[32m0.0281\u001b[0m       0.9890        0.0415  1.2846\n",
      "     17             0.9846        \u001b[32m0.0279\u001b[0m       0.9876        \u001b[31m0.0329\u001b[0m  1.2890\n",
      "     18             0.9816        \u001b[32m0.0254\u001b[0m       0.9853        0.0625  1.2885\n",
      "     19             0.9808        \u001b[32m0.0225\u001b[0m       0.9844        0.0338  1.2857\n",
      "     20             0.9780        \u001b[32m0.0173\u001b[0m       0.9821        0.0545  1.2896\n",
      "     21             0.9600        0.0200       0.9679        0.1265  1.2902\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 16/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.930) f1_score: (test=0.906) total time=  28.9s\n",
      "[CV 2/4; 16/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5349\u001b[0m        \u001b[32m0.4995\u001b[0m       \u001b[35m0.7284\u001b[0m        \u001b[31m0.8568\u001b[0m  1.2883\n",
      "      2             \u001b[36m0.8315\u001b[0m        \u001b[32m0.2639\u001b[0m       \u001b[35m0.8594\u001b[0m        \u001b[31m0.3285\u001b[0m  1.2912\n",
      "      3             \u001b[36m0.9383\u001b[0m        \u001b[32m0.1705\u001b[0m       \u001b[35m0.9492\u001b[0m        \u001b[31m0.1201\u001b[0m  1.2913\n",
      "      4             \u001b[36m0.9435\u001b[0m        \u001b[32m0.1281\u001b[0m       \u001b[35m0.9556\u001b[0m        0.1783  1.2882\n",
      "      5             \u001b[36m0.9628\u001b[0m        0.1348       \u001b[35m0.9707\u001b[0m        0.1312  1.2865\n",
      "      6             0.9601        \u001b[32m0.0838\u001b[0m       0.9684        0.1230  1.2888\n",
      "      7             \u001b[36m0.9692\u001b[0m        \u001b[32m0.0677\u001b[0m       \u001b[35m0.9757\u001b[0m        \u001b[31m0.0977\u001b[0m  1.2908\n",
      "      8             0.9277        0.0706       0.9395        0.1525  1.2866\n",
      "      9             0.8774        \u001b[32m0.0602\u001b[0m       0.9111        0.5580  1.2878\n",
      "     10             \u001b[36m0.9694\u001b[0m        0.0726       \u001b[35m0.9762\u001b[0m        0.1287  1.2875\n",
      "     11             \u001b[36m0.9758\u001b[0m        \u001b[32m0.0519\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0837\u001b[0m  1.3038\n",
      "     12             0.9703        \u001b[32m0.0351\u001b[0m       0.9762        \u001b[31m0.0797\u001b[0m  1.2928\n",
      "     13             0.9680        0.0601       0.9748        0.1197  1.2924\n",
      "     14             \u001b[36m0.9799\u001b[0m        0.0373       \u001b[35m0.9840\u001b[0m        0.0814  1.2882\n",
      "     15             0.9419        \u001b[32m0.0257\u001b[0m       0.9519        0.1465  1.2879\n",
      "     16             0.9785        0.0392       0.9831        0.0991  1.2915\n",
      "     17             0.9578        0.0485       0.9675        0.1744  1.2897\n",
      "Epoch 00018: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     18             0.9696        0.0521       0.9757        0.0952  1.2900\n",
      "     19             \u001b[36m0.9849\u001b[0m        0.0260       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0632\u001b[0m  1.2909\n",
      "     20             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0114\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0551\u001b[0m  1.2908\n",
      "     21             0.9872        \u001b[32m0.0091\u001b[0m       0.9899        \u001b[31m0.0551\u001b[0m  1.2916\n",
      "     22             0.9878        \u001b[32m0.0089\u001b[0m       0.9904        0.0559  1.2922\n",
      "     23             0.9878        \u001b[32m0.0061\u001b[0m       0.9904        \u001b[31m0.0550\u001b[0m  1.2902\n",
      "     24             \u001b[36m0.9884\u001b[0m        0.0069       \u001b[35m0.9908\u001b[0m        0.0580  1.2901\n",
      "     25             \u001b[36m0.9889\u001b[0m        \u001b[32m0.0048\u001b[0m       \u001b[35m0.9913\u001b[0m        0.0567  1.2928\n",
      "     26             \u001b[36m0.9896\u001b[0m        \u001b[32m0.0042\u001b[0m       \u001b[35m0.9918\u001b[0m        \u001b[31m0.0541\u001b[0m  1.2982\n",
      "     27             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0031\u001b[0m       \u001b[35m0.9922\u001b[0m        0.0546  1.2909\n",
      "     28             0.9895        \u001b[32m0.0029\u001b[0m       0.9918        0.0570  1.2908\n",
      "     29             0.9890        0.0031       0.9913        0.0576  1.2935\n",
      "     30             0.9890        \u001b[32m0.0023\u001b[0m       0.9913        0.0574  1.2941\n",
      "     31             0.9901        \u001b[32m0.0021\u001b[0m       0.9922        0.0558  1.2939\n",
      "     32             \u001b[36m0.9907\u001b[0m        \u001b[32m0.0019\u001b[0m       \u001b[35m0.9927\u001b[0m        0.0573  1.2928\n",
      "     33             0.9895        0.0022       0.9918        0.0592  1.2917\n",
      "     34             0.9895        \u001b[32m0.0016\u001b[0m       0.9918        0.0599  1.2952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     35             0.9901        0.0016       0.9922        0.0596  1.2960\n",
      "     36             0.9895        \u001b[32m0.0015\u001b[0m       0.9918        0.0583  1.3025\n",
      "     37             0.9907        \u001b[32m0.0011\u001b[0m       0.9927        0.0586  1.2979\n",
      "     38             0.9901        \u001b[32m0.0009\u001b[0m       0.9922        0.0590  1.3018\n",
      "     39             0.9901        0.0010       0.9922        0.0582  1.2978\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 16/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.996) f1_score: (test=0.994) total time=  52.0s\n",
      "[CV 3/4; 16/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.6705\u001b[0m        \u001b[32m0.5474\u001b[0m       \u001b[35m0.6899\u001b[0m        \u001b[31m0.5746\u001b[0m  1.2956\n",
      "      2             \u001b[36m0.8161\u001b[0m        \u001b[32m0.3266\u001b[0m       \u001b[35m0.8383\u001b[0m        \u001b[31m0.3177\u001b[0m  1.2956\n",
      "      3             \u001b[36m0.9002\u001b[0m        \u001b[32m0.2777\u001b[0m       \u001b[35m0.9175\u001b[0m        \u001b[31m0.2271\u001b[0m  1.2962\n",
      "      4             \u001b[36m0.9078\u001b[0m        \u001b[32m0.2001\u001b[0m       \u001b[35m0.9226\u001b[0m        \u001b[31m0.1785\u001b[0m  1.2961\n",
      "      5             \u001b[36m0.9173\u001b[0m        \u001b[32m0.1773\u001b[0m       \u001b[35m0.9304\u001b[0m        \u001b[31m0.1465\u001b[0m  1.3004\n",
      "      6             \u001b[36m0.9393\u001b[0m        \u001b[32m0.1677\u001b[0m       \u001b[35m0.9519\u001b[0m        0.1789  1.2970\n",
      "      7             0.9378        \u001b[32m0.1431\u001b[0m       0.9510        0.1698  1.2973\n",
      "      8             \u001b[36m0.9482\u001b[0m        0.1557       \u001b[35m0.9588\u001b[0m        0.1516  1.2968\n",
      "      9             \u001b[36m0.9574\u001b[0m        \u001b[32m0.1088\u001b[0m       \u001b[35m0.9656\u001b[0m        \u001b[31m0.1040\u001b[0m  1.2996\n",
      "     10             0.9431        \u001b[32m0.1064\u001b[0m       0.9546        0.1715  1.2905\n",
      "     11             0.9518        \u001b[32m0.0841\u001b[0m       0.9606        0.1062  1.2903\n",
      "     12             \u001b[36m0.9665\u001b[0m        \u001b[32m0.0651\u001b[0m       \u001b[35m0.9730\u001b[0m        \u001b[31m0.0806\u001b[0m  1.2935\n",
      "     13             \u001b[36m0.9691\u001b[0m        \u001b[32m0.0624\u001b[0m       \u001b[35m0.9753\u001b[0m        \u001b[31m0.0683\u001b[0m  1.2942\n",
      "     14             \u001b[36m0.9696\u001b[0m        \u001b[32m0.0426\u001b[0m       \u001b[35m0.9757\u001b[0m        0.0858  1.3003\n",
      "     15             0.9555        0.0528       0.9638        0.1024  1.2971\n",
      "     16             \u001b[36m0.9735\u001b[0m        0.0592       \u001b[35m0.9789\u001b[0m        0.0851  1.2947\n",
      "     17             \u001b[36m0.9832\u001b[0m        \u001b[32m0.0351\u001b[0m       \u001b[35m0.9867\u001b[0m        \u001b[31m0.0661\u001b[0m  1.2933\n",
      "     18             0.9831        0.0436       0.9867        0.0855  1.2949\n",
      "     19             0.9648        0.0415       0.9716        0.1071  1.2943\n",
      "     20             0.9814        \u001b[32m0.0272\u001b[0m       0.9853        0.0808  1.2975\n",
      "     21             0.9770        0.0290       0.9817        0.0811  1.2961\n",
      "     22             0.9665        0.0354       0.9739        0.1416  1.2949\n",
      "     23             0.9704        \u001b[32m0.0242\u001b[0m       0.9762        0.0879  1.2973\n",
      "     24             0.9650        0.0379       0.9721        0.1437  1.2966\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 16/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.982) f1_score: (test=0.978) total time=  32.6s\n",
      "[CV 4/4; 16/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.6067\u001b[0m        \u001b[32m0.5953\u001b[0m       \u001b[35m0.7187\u001b[0m        \u001b[31m0.6994\u001b[0m  1.2940\n",
      "      2             \u001b[36m0.7478\u001b[0m        \u001b[32m0.3515\u001b[0m       \u001b[35m0.8177\u001b[0m        \u001b[31m0.6897\u001b[0m  1.2896\n",
      "      3             \u001b[36m0.9071\u001b[0m        \u001b[32m0.2572\u001b[0m       \u001b[35m0.9262\u001b[0m        \u001b[31m0.2252\u001b[0m  1.2906\n",
      "      4             0.8915        \u001b[32m0.2315\u001b[0m       0.9088        0.2396  1.2934\n",
      "      5             \u001b[36m0.9115\u001b[0m        \u001b[32m0.1554\u001b[0m       \u001b[35m0.9272\u001b[0m        \u001b[31m0.2044\u001b[0m  1.2921\n",
      "      6             \u001b[36m0.9290\u001b[0m        0.1593       \u001b[35m0.9459\u001b[0m        0.2182  1.2930\n",
      "      7             0.9125        \u001b[32m0.1331\u001b[0m       0.9258        \u001b[31m0.1583\u001b[0m  1.2934\n",
      "      8             0.9213        \u001b[32m0.1052\u001b[0m       0.9414        0.2275  1.2966\n",
      "      9             \u001b[36m0.9653\u001b[0m        \u001b[32m0.0644\u001b[0m       \u001b[35m0.9721\u001b[0m        \u001b[31m0.0918\u001b[0m  1.2961\n",
      "     10             0.9585        0.0718       0.9670        0.1448  1.2979\n",
      "     11             0.9502        0.0731       0.9592        0.1212  1.2956\n",
      "     12             \u001b[36m0.9706\u001b[0m        \u001b[32m0.0561\u001b[0m       \u001b[35m0.9766\u001b[0m        0.0996  1.2957\n",
      "     13             0.9517        0.0674       0.9629        0.1944  1.2930\n",
      "     14             0.9699        \u001b[32m0.0451\u001b[0m       0.9766        0.1735  1.2901\n",
      "     15             0.9422        \u001b[32m0.0380\u001b[0m       0.9565        0.2907  1.2912\n",
      "     16             0.9439        \u001b[32m0.0367\u001b[0m       0.9537        0.1432  1.2926\n",
      "     17             \u001b[36m0.9826\u001b[0m        0.0492       \u001b[35m0.9863\u001b[0m        \u001b[31m0.0854\u001b[0m  1.2914\n",
      "     18             0.9735        0.0467       0.9789        0.1155  1.2932\n",
      "     19             0.9620        \u001b[32m0.0293\u001b[0m       0.9693        0.1179  1.2954\n",
      "     20             0.9766        0.0294       0.9817        0.1202  1.2887\n",
      "     21             0.9549        0.0316       0.9656        0.2089  1.2880\n",
      "     22             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0266\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0812\u001b[0m  1.2904\n",
      "     23             0.9475        \u001b[32m0.0239\u001b[0m       0.9574        0.1460  1.2871\n",
      "     24             0.8167        0.1010       0.8763        1.2522  1.2943\n",
      "     25             0.9742        0.0804       0.9794        0.1008  1.2898\n",
      "Epoch 00026: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     26             0.9822        0.0311       0.9858        0.0832  1.2888\n",
      "     27             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0123\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0778\u001b[0m  1.2928\n",
      "     28             0.9850        \u001b[32m0.0079\u001b[0m       0.9881        0.0780  1.2914\n",
      "     29             0.9856        \u001b[32m0.0070\u001b[0m       0.9885        0.0783  1.2913\n",
      "     30             0.9856        \u001b[32m0.0070\u001b[0m       0.9885        0.0782  1.2929\n",
      "     31             0.9856        \u001b[32m0.0062\u001b[0m       0.9885        0.0787  1.2901\n",
      "     32             0.9850        \u001b[32m0.0061\u001b[0m       0.9881        0.0781  1.2915\n",
      "     33             0.9838        \u001b[32m0.0047\u001b[0m       0.9872        0.0791  1.2887\n",
      "     34             0.9849        \u001b[32m0.0045\u001b[0m       0.9881        0.0795  1.2900\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 16/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.993) f1_score: (test=0.991) total time=  45.5s\n",
      "[CV 1/4; 17/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4199\u001b[0m        \u001b[32m0.5383\u001b[0m       \u001b[35m0.7238\u001b[0m        \u001b[31m0.6319\u001b[0m  0.2925\n",
      "      2             \u001b[36m0.7840\u001b[0m        \u001b[32m0.4051\u001b[0m       \u001b[35m0.8154\u001b[0m        \u001b[31m0.4198\u001b[0m  0.2994\n",
      "      3             \u001b[36m0.9006\u001b[0m        \u001b[32m0.2781\u001b[0m       \u001b[35m0.9185\u001b[0m        \u001b[31m0.2139\u001b[0m  0.2951\n",
      "      4             \u001b[36m0.9476\u001b[0m        \u001b[32m0.1818\u001b[0m       \u001b[35m0.9574\u001b[0m        \u001b[31m0.1359\u001b[0m  0.2966\n",
      "      5             \u001b[36m0.9569\u001b[0m        \u001b[32m0.1211\u001b[0m       \u001b[35m0.9656\u001b[0m        \u001b[31m0.1010\u001b[0m  0.2946\n",
      "      6             \u001b[36m0.9584\u001b[0m        \u001b[32m0.0825\u001b[0m       \u001b[35m0.9661\u001b[0m        \u001b[31m0.0907\u001b[0m  0.2929\n",
      "      7             \u001b[36m0.9714\u001b[0m        \u001b[32m0.0553\u001b[0m       \u001b[35m0.9771\u001b[0m        \u001b[31m0.0692\u001b[0m  0.2940\n",
      "      8             \u001b[36m0.9715\u001b[0m        \u001b[32m0.0388\u001b[0m       0.9771        \u001b[31m0.0681\u001b[0m  0.2937\n",
      "      9             0.9671        \u001b[32m0.0347\u001b[0m       0.9734        0.0741  0.2912\n",
      "     10             \u001b[36m0.9766\u001b[0m        \u001b[32m0.0257\u001b[0m       \u001b[35m0.9812\u001b[0m        \u001b[31m0.0560\u001b[0m  0.2902\n",
      "     11             0.9756        \u001b[32m0.0158\u001b[0m       0.9803        0.0587  0.2909\n",
      "     12             0.9757        \u001b[32m0.0142\u001b[0m       0.9808        0.0642  0.2960\n",
      "     13             \u001b[36m0.9782\u001b[0m        \u001b[32m0.0093\u001b[0m       \u001b[35m0.9826\u001b[0m        \u001b[31m0.0508\u001b[0m  0.2929\n",
      "     14             \u001b[36m0.9812\u001b[0m        \u001b[32m0.0064\u001b[0m       \u001b[35m0.9849\u001b[0m        \u001b[31m0.0478\u001b[0m  0.2931\n",
      "     15             0.9783        \u001b[32m0.0054\u001b[0m       0.9826        0.0530  0.2910\n",
      "     16             0.9760        \u001b[32m0.0046\u001b[0m       0.9808        0.0520  0.2960\n",
      "     17             0.9810        \u001b[32m0.0035\u001b[0m       0.9849        0.0516  0.2946\n",
      "     18             0.9772        0.0038       0.9817        0.0539  0.2932\n",
      "     19             0.9764        0.0040       0.9812        0.0658  0.2932\n",
      "     20             0.9782        \u001b[32m0.0018\u001b[0m       0.9826        0.0539  0.2914\n",
      "     21             0.9794        \u001b[32m0.0015\u001b[0m       0.9835        0.0541  0.2927\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 17/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.979) f1_score: (test=0.974) total time=   6.6s\n",
      "[CV 2/4; 17/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.5445\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5966\u001b[0m  0.2946\n",
      "      2             \u001b[36m0.7372\u001b[0m        \u001b[32m0.3966\u001b[0m       \u001b[35m0.8113\u001b[0m        \u001b[31m0.3697\u001b[0m  0.2918\n",
      "      3             \u001b[36m0.9014\u001b[0m        \u001b[32m0.2676\u001b[0m       \u001b[35m0.9221\u001b[0m        \u001b[31m0.2046\u001b[0m  0.2900\n",
      "      4             \u001b[36m0.9412\u001b[0m        \u001b[32m0.1678\u001b[0m       \u001b[35m0.9533\u001b[0m        \u001b[31m0.1365\u001b[0m  0.2947\n",
      "      5             \u001b[36m0.9470\u001b[0m        \u001b[32m0.1178\u001b[0m       \u001b[35m0.9574\u001b[0m        \u001b[31m0.1114\u001b[0m  0.2902\n",
      "      6             \u001b[36m0.9643\u001b[0m        \u001b[32m0.0769\u001b[0m       \u001b[35m0.9716\u001b[0m        \u001b[31m0.0926\u001b[0m  0.2974\n",
      "      7             \u001b[36m0.9652\u001b[0m        \u001b[32m0.0534\u001b[0m       \u001b[35m0.9721\u001b[0m        \u001b[31m0.0866\u001b[0m  0.2963\n",
      "      8             \u001b[36m0.9710\u001b[0m        \u001b[32m0.0401\u001b[0m       \u001b[35m0.9771\u001b[0m        \u001b[31m0.0715\u001b[0m  0.2924\n",
      "      9             0.9678        \u001b[32m0.0334\u001b[0m       0.9743        0.0831  0.2921\n",
      "     10             0.9693        \u001b[32m0.0222\u001b[0m       0.9757        0.0736  0.2954\n",
      "     11             0.9707        \u001b[32m0.0156\u001b[0m       0.9766        0.0728  0.2932\n",
      "     12             \u001b[36m0.9732\u001b[0m        \u001b[32m0.0144\u001b[0m       \u001b[35m0.9789\u001b[0m        \u001b[31m0.0684\u001b[0m  0.2944\n",
      "     13             \u001b[36m0.9778\u001b[0m        \u001b[32m0.0108\u001b[0m       \u001b[35m0.9826\u001b[0m        \u001b[31m0.0673\u001b[0m  0.2928\n",
      "     14             0.9725        \u001b[32m0.0080\u001b[0m       0.9785        \u001b[31m0.0644\u001b[0m  0.2960\n",
      "     15             0.9700        \u001b[32m0.0059\u001b[0m       0.9762        0.0732  0.2943\n",
      "     16             0.9687        0.0072       0.9757        0.0891  0.2931\n",
      "     17             0.9729        \u001b[32m0.0044\u001b[0m       0.9785        0.0716  0.2925\n",
      "     18             0.9767        \u001b[32m0.0026\u001b[0m       0.9817        \u001b[31m0.0628\u001b[0m  0.2934\n",
      "     19             0.9713        \u001b[32m0.0026\u001b[0m       0.9771        0.0770  0.2927\n",
      "     20             0.9717        \u001b[32m0.0014\u001b[0m       0.9776        0.0688  0.2994\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 17/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.985) f1_score: (test=0.982) total time=   6.3s\n",
      "[CV 3/4; 17/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.5434\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5984\u001b[0m  0.2916\n",
      "      2             \u001b[36m0.7169\u001b[0m        \u001b[32m0.4127\u001b[0m       \u001b[35m0.8012\u001b[0m        \u001b[31m0.4063\u001b[0m  0.2922\n",
      "      3             \u001b[36m0.9134\u001b[0m        \u001b[32m0.2588\u001b[0m       \u001b[35m0.9299\u001b[0m        \u001b[31m0.1973\u001b[0m  0.2922\n",
      "      4             \u001b[36m0.9393\u001b[0m        \u001b[32m0.1537\u001b[0m       \u001b[35m0.9505\u001b[0m        \u001b[31m0.1396\u001b[0m  0.2916\n",
      "      5             \u001b[36m0.9499\u001b[0m        \u001b[32m0.0937\u001b[0m       \u001b[35m0.9597\u001b[0m        \u001b[31m0.1058\u001b[0m  0.2961\n",
      "      6             \u001b[36m0.9623\u001b[0m        \u001b[32m0.0643\u001b[0m       \u001b[35m0.9707\u001b[0m        \u001b[31m0.0878\u001b[0m  0.2977\n",
      "      7             0.9389        \u001b[32m0.0574\u001b[0m       0.9542        0.1237  0.2923\n",
      "      8             \u001b[36m0.9686\u001b[0m        \u001b[32m0.0386\u001b[0m       \u001b[35m0.9753\u001b[0m        \u001b[31m0.0729\u001b[0m  0.2926\n",
      "      9             0.9659        \u001b[32m0.0250\u001b[0m       0.9734        \u001b[31m0.0712\u001b[0m  0.2954\n",
      "     10             \u001b[36m0.9713\u001b[0m        \u001b[32m0.0171\u001b[0m       \u001b[35m0.9771\u001b[0m        0.0755  0.2951\n",
      "     11             0.9656        \u001b[32m0.0113\u001b[0m       0.9734        0.0850  0.2962\n",
      "     12             0.9650        \u001b[32m0.0105\u001b[0m       0.9730        0.0905  0.2953\n",
      "     13             0.9712        \u001b[32m0.0070\u001b[0m       0.9771        \u001b[31m0.0691\u001b[0m  0.2997\n",
      "     14             \u001b[36m0.9724\u001b[0m        \u001b[32m0.0047\u001b[0m       \u001b[35m0.9785\u001b[0m        \u001b[31m0.0687\u001b[0m  0.2978\n",
      "     15             \u001b[36m0.9728\u001b[0m        0.0069       0.9785        \u001b[31m0.0686\u001b[0m  0.2940\n",
      "     16             0.9725        \u001b[32m0.0035\u001b[0m       0.9785        0.0702  0.2959\n",
      "     17             0.9717        \u001b[32m0.0028\u001b[0m       0.9776        0.0689  0.2988\n",
      "     18             \u001b[36m0.9765\u001b[0m        \u001b[32m0.0018\u001b[0m       \u001b[35m0.9817\u001b[0m        0.0692  0.2953\n",
      "     19             \u001b[36m0.9766\u001b[0m        \u001b[32m0.0011\u001b[0m       0.9817        \u001b[31m0.0652\u001b[0m  0.2977\n",
      "     20             \u001b[36m0.9784\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9831\u001b[0m        \u001b[31m0.0635\u001b[0m  0.2982\n",
      "     21             0.9756        0.0014       0.9808        0.0687  0.2946\n",
      "     22             0.9756        0.0011       0.9808        0.0651  0.2928\n",
      "     23             0.9778        \u001b[32m0.0009\u001b[0m       0.9826        0.0738  0.2933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     24             0.9772        0.0010       0.9821        0.0701  0.2928\n",
      "     25             0.9746        0.0011       0.9798        0.0714  0.2929\n",
      "Epoch 00026: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     26             0.9774        0.0010       0.9821        0.0696  0.2928\n",
      "     27             0.9768        0.0009       0.9817        0.0686  0.2930\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 17/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.984) f1_score: (test=0.980) total time=   8.4s\n",
      "[CV 4/4; 17/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.5381\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.6219\u001b[0m  0.2924\n",
      "      2             \u001b[36m0.5733\u001b[0m        \u001b[32m0.4171\u001b[0m       \u001b[35m0.7705\u001b[0m        \u001b[31m0.4358\u001b[0m  0.2946\n",
      "      3             \u001b[36m0.8868\u001b[0m        \u001b[32m0.2780\u001b[0m       \u001b[35m0.9052\u001b[0m        \u001b[31m0.2360\u001b[0m  0.2959\n",
      "      4             \u001b[36m0.9338\u001b[0m        \u001b[32m0.1671\u001b[0m       \u001b[35m0.9469\u001b[0m        \u001b[31m0.1457\u001b[0m  0.2973\n",
      "      5             \u001b[36m0.9390\u001b[0m        \u001b[32m0.0996\u001b[0m       \u001b[35m0.9505\u001b[0m        \u001b[31m0.1290\u001b[0m  0.2922\n",
      "      6             \u001b[36m0.9555\u001b[0m        \u001b[32m0.0716\u001b[0m       \u001b[35m0.9643\u001b[0m        \u001b[31m0.1075\u001b[0m  0.3427\n",
      "      7             \u001b[36m0.9619\u001b[0m        \u001b[32m0.0594\u001b[0m       \u001b[35m0.9702\u001b[0m        \u001b[31m0.1015\u001b[0m  0.2964\n",
      "      8             \u001b[36m0.9698\u001b[0m        \u001b[32m0.0383\u001b[0m       \u001b[35m0.9762\u001b[0m        \u001b[31m0.0824\u001b[0m  0.2961\n",
      "      9             0.9664        \u001b[32m0.0267\u001b[0m       0.9734        0.0846  0.2939\n",
      "     10             \u001b[36m0.9704\u001b[0m        \u001b[32m0.0204\u001b[0m       \u001b[35m0.9766\u001b[0m        \u001b[31m0.0816\u001b[0m  0.2947\n",
      "     11             0.9699        \u001b[32m0.0129\u001b[0m       0.9762        0.0858  0.2942\n",
      "     12             \u001b[36m0.9706\u001b[0m        \u001b[32m0.0115\u001b[0m       0.9766        0.0946  0.2920\n",
      "     13             0.9677        0.0213       0.9743        0.0991  0.2937\n",
      "     14             \u001b[36m0.9716\u001b[0m        \u001b[32m0.0109\u001b[0m       \u001b[35m0.9776\u001b[0m        0.0872  0.2950\n",
      "     15             \u001b[36m0.9768\u001b[0m        \u001b[32m0.0084\u001b[0m       \u001b[35m0.9817\u001b[0m        0.0905  0.2951\n",
      "     16             0.9750        \u001b[32m0.0051\u001b[0m       0.9803        0.0863  0.2947\n",
      "     17             0.9756        0.0060       0.9808        0.0877  0.3032\n",
      "     18             0.9749        0.0078       0.9803        0.0848  0.3004\n",
      "Epoch 00019: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     19             0.9711        0.0083       0.9771        0.0887  0.2933\n",
      "     20             0.9763        \u001b[32m0.0044\u001b[0m       0.9812        0.0841  0.2989\n",
      "     21             0.9762        \u001b[32m0.0025\u001b[0m       0.9812        0.0836  0.2953\n",
      "     22             0.9768        \u001b[32m0.0019\u001b[0m       0.9817        0.0828  0.2994\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 17/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[9, 7, 7, 7, 5], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.987) f1_score: (test=0.984) total time=   7.0s\n",
      "[CV 1/4; 18/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4197\u001b[0m        \u001b[32m0.4438\u001b[0m       \u001b[35m0.7233\u001b[0m        \u001b[31m0.5892\u001b[0m  1.4269\n",
      "      2             \u001b[36m0.7607\u001b[0m        \u001b[32m0.2250\u001b[0m       \u001b[35m0.7994\u001b[0m        \u001b[31m0.4061\u001b[0m  1.4184\n",
      "      3             \u001b[36m0.9548\u001b[0m        \u001b[32m0.1353\u001b[0m       \u001b[35m0.9638\u001b[0m        \u001b[31m0.1023\u001b[0m  1.4193\n",
      "      4             \u001b[36m0.9551\u001b[0m        \u001b[32m0.0814\u001b[0m       \u001b[35m0.9647\u001b[0m        \u001b[31m0.0812\u001b[0m  1.4183\n",
      "      5             \u001b[36m0.9697\u001b[0m        \u001b[32m0.0579\u001b[0m       \u001b[35m0.9762\u001b[0m        \u001b[31m0.0730\u001b[0m  1.4181\n",
      "      6             0.9563        \u001b[32m0.0432\u001b[0m       0.9638        0.0945  1.4195\n",
      "      7             0.9433        \u001b[32m0.0274\u001b[0m       0.9565        0.1197  1.4200\n",
      "      8             0.9692        \u001b[32m0.0204\u001b[0m       0.9748        \u001b[31m0.0607\u001b[0m  1.4178\n",
      "      9             \u001b[36m0.9745\u001b[0m        0.0223       \u001b[35m0.9794\u001b[0m        \u001b[31m0.0577\u001b[0m  1.4209\n",
      "     10             \u001b[36m0.9839\u001b[0m        \u001b[32m0.0153\u001b[0m       \u001b[35m0.9872\u001b[0m        \u001b[31m0.0329\u001b[0m  1.4201\n",
      "     11             \u001b[36m0.9851\u001b[0m        \u001b[32m0.0073\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0309\u001b[0m  1.4196\n",
      "     12             0.9759        \u001b[32m0.0054\u001b[0m       0.9803        0.0732  1.4225\n",
      "     13             0.9446        0.0101       0.9574        0.1454  1.4237\n",
      "     14             0.9822        0.0122       0.9858        0.0398  1.4252\n",
      "Epoch 00015: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     15             0.9655        0.0098       0.9716        0.1040  1.4290\n",
      "     16             \u001b[36m0.9880\u001b[0m        0.0054       \u001b[35m0.9904\u001b[0m        0.0341  1.4244\n",
      "     17             \u001b[36m0.9880\u001b[0m        \u001b[32m0.0015\u001b[0m       0.9904        0.0348  1.4277\n",
      "     18             0.9874        \u001b[32m0.0010\u001b[0m       0.9899        0.0337  1.4273\n",
      "     19             \u001b[36m0.9880\u001b[0m        0.0011       0.9904        0.0349  1.4193\n",
      "     20             0.9875        \u001b[32m0.0007\u001b[0m       0.9899        0.0327  1.4209\n",
      "     21             0.9875        \u001b[32m0.0007\u001b[0m       0.9899        0.0325  1.4184\n",
      "     22             0.9880        \u001b[32m0.0006\u001b[0m       0.9904        0.0319  1.4135\n",
      "     23             0.9880        \u001b[32m0.0005\u001b[0m       0.9904        0.0321  1.4147\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 18/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.986) f1_score: (test=0.983) total time=  34.2s\n",
      "[CV 2/4; 18/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5449\u001b[0m        \u001b[32m0.4359\u001b[0m       \u001b[35m0.6899\u001b[0m        \u001b[31m0.5819\u001b[0m  1.4158\n",
      "      2             \u001b[36m0.8000\u001b[0m        \u001b[32m0.2007\u001b[0m       \u001b[35m0.8200\u001b[0m        \u001b[31m0.4277\u001b[0m  1.4153\n",
      "      3             \u001b[36m0.9500\u001b[0m        \u001b[32m0.1127\u001b[0m       \u001b[35m0.9592\u001b[0m        \u001b[31m0.1181\u001b[0m  1.4145\n",
      "      4             \u001b[36m0.9601\u001b[0m        \u001b[32m0.0718\u001b[0m       \u001b[35m0.9679\u001b[0m        \u001b[31m0.0977\u001b[0m  1.4173\n",
      "      5             0.9587        \u001b[32m0.0607\u001b[0m       0.9679        0.1100  1.4229\n",
      "      6             \u001b[36m0.9662\u001b[0m        \u001b[32m0.0500\u001b[0m       \u001b[35m0.9730\u001b[0m        \u001b[31m0.0819\u001b[0m  1.4230\n",
      "      7             \u001b[36m0.9704\u001b[0m        \u001b[32m0.0308\u001b[0m       \u001b[35m0.9771\u001b[0m        0.0907  1.4212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8             \u001b[36m0.9756\u001b[0m        \u001b[32m0.0263\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0776\u001b[0m  1.4232\n",
      "      9             0.9751        \u001b[32m0.0212\u001b[0m       0.9803        \u001b[31m0.0659\u001b[0m  1.4211\n",
      "     10             0.9738        \u001b[32m0.0130\u001b[0m       0.9794        0.0882  1.4238\n",
      "     11             \u001b[36m0.9762\u001b[0m        0.0133       \u001b[35m0.9812\u001b[0m        0.0915  1.4226\n",
      "     12             0.9310        0.0148       0.9427        0.1933  1.4232\n",
      "Epoch 00013: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     13             0.9716        0.0173       0.9776        0.0797  1.4221\n",
      "     14             \u001b[36m0.9785\u001b[0m        \u001b[32m0.0068\u001b[0m       \u001b[35m0.9831\u001b[0m        0.0705  1.4281\n",
      "     15             \u001b[36m0.9802\u001b[0m        \u001b[32m0.0035\u001b[0m       \u001b[35m0.9844\u001b[0m        0.0718  1.4242\n",
      "     16             \u001b[36m0.9814\u001b[0m        \u001b[32m0.0023\u001b[0m       \u001b[35m0.9853\u001b[0m        0.0676  1.4241\n",
      "     17             0.9814        \u001b[32m0.0014\u001b[0m       0.9853        0.0687  1.4228\n",
      "     18             \u001b[36m0.9820\u001b[0m        \u001b[32m0.0012\u001b[0m       \u001b[35m0.9858\u001b[0m        0.0681  1.4222\n",
      "     19             \u001b[36m0.9825\u001b[0m        \u001b[32m0.0010\u001b[0m       \u001b[35m0.9863\u001b[0m        0.0685  1.4227\n",
      "     20             0.9825        0.0011       0.9863        0.0689  1.4264\n",
      "     21             0.9825        \u001b[32m0.0009\u001b[0m       0.9863        0.0691  1.4253\n",
      "     22             0.9825        \u001b[32m0.0008\u001b[0m       0.9863        0.0695  1.4298\n",
      "     23             0.9825        0.0011       0.9863        0.0700  1.4256\n",
      "     24             \u001b[36m0.9825\u001b[0m        0.0009       0.9863        0.0694  1.4233\n",
      "Epoch 00025: reducing learning rate of group 0 to 8.0000e-06.\n",
      "     25             0.9820        0.0008       0.9858        0.0717  1.4222\n",
      "     26             0.9825        \u001b[32m0.0007\u001b[0m       0.9863        0.0713  1.4223\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 18/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.986) f1_score: (test=0.983) total time=  38.6s\n",
      "[CV 3/4; 18/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4186\u001b[0m        \u001b[32m0.4608\u001b[0m       \u001b[35m0.7201\u001b[0m        \u001b[31m0.5886\u001b[0m  1.4199\n",
      "      2             \u001b[36m0.8440\u001b[0m        \u001b[32m0.2270\u001b[0m       \u001b[35m0.8667\u001b[0m        \u001b[31m0.3067\u001b[0m  1.4180\n",
      "      3             \u001b[36m0.9567\u001b[0m        \u001b[32m0.1127\u001b[0m       \u001b[35m0.9661\u001b[0m        \u001b[31m0.1033\u001b[0m  1.4181\n",
      "      4             \u001b[36m0.9744\u001b[0m        \u001b[32m0.0771\u001b[0m       \u001b[35m0.9798\u001b[0m        \u001b[31m0.0687\u001b[0m  1.4174\n",
      "      5             0.7465        \u001b[32m0.0532\u001b[0m       0.8424        0.5588  1.4194\n",
      "      6             0.9283        0.0542       0.9469        0.1648  1.4166\n",
      "      7             \u001b[36m0.9789\u001b[0m        \u001b[32m0.0280\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0631\u001b[0m  1.4112\n",
      "      8             0.9737        \u001b[32m0.0192\u001b[0m       0.9789        0.0692  1.4143\n",
      "      9             0.9339        0.0301       0.9450        0.1434  1.4195\n",
      "     10             0.9776        \u001b[32m0.0183\u001b[0m       0.9821        0.0691  1.4215\n",
      "     11             \u001b[36m0.9803\u001b[0m        \u001b[32m0.0151\u001b[0m       \u001b[35m0.9844\u001b[0m        0.0685  1.4175\n",
      "     12             0.9737        \u001b[32m0.0121\u001b[0m       0.9789        0.0766  1.4177\n",
      "     13             0.9765        0.0164       0.9812        0.0740  1.4178\n",
      "     14             0.9473        0.0205       0.9569        0.1317  1.4164\n",
      "Epoch 00015: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     15             \u001b[36m0.9803\u001b[0m        0.0254       0.9844        \u001b[31m0.0601\u001b[0m  1.4211\n",
      "     16             \u001b[36m0.9854\u001b[0m        \u001b[32m0.0068\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0526\u001b[0m  1.4231\n",
      "     17             \u001b[36m0.9866\u001b[0m        \u001b[32m0.0026\u001b[0m       \u001b[35m0.9895\u001b[0m        \u001b[31m0.0509\u001b[0m  1.4207\n",
      "     18             0.9866        \u001b[32m0.0018\u001b[0m       0.9895        \u001b[31m0.0501\u001b[0m  1.4206\n",
      "     19             0.9860        \u001b[32m0.0016\u001b[0m       0.9890        0.0501  1.4234\n",
      "     20             0.9860        0.0018       0.9890        \u001b[31m0.0481\u001b[0m  1.4291\n",
      "     21             0.9860        \u001b[32m0.0014\u001b[0m       0.9890        0.0492  1.4206\n",
      "     22             0.9860        \u001b[32m0.0012\u001b[0m       0.9890        0.0495  1.4192\n",
      "     23             0.9860        \u001b[32m0.0011\u001b[0m       0.9890        0.0493  1.4202\n",
      "     24             \u001b[36m0.9866\u001b[0m        \u001b[32m0.0009\u001b[0m       0.9895        0.0491  1.4160\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 18/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  35.6s\n",
      "[CV 4/4; 18/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4551\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5524\u001b[0m  1.4209\n",
      "      2             \u001b[36m0.8469\u001b[0m        \u001b[32m0.2167\u001b[0m       \u001b[35m0.8759\u001b[0m        \u001b[31m0.2581\u001b[0m  1.4201\n",
      "      3             0.8349        \u001b[32m0.1225\u001b[0m       \u001b[35m0.8882\u001b[0m        0.2634  1.4211\n",
      "      4             \u001b[36m0.9713\u001b[0m        \u001b[32m0.0731\u001b[0m       \u001b[35m0.9776\u001b[0m        \u001b[31m0.0705\u001b[0m  1.4473\n",
      "      5             0.9647        \u001b[32m0.0487\u001b[0m       0.9725        0.0744  1.4900\n",
      "      6             0.9710        \u001b[32m0.0341\u001b[0m       0.9776        \u001b[31m0.0669\u001b[0m  1.4397\n",
      "      7             \u001b[36m0.9785\u001b[0m        \u001b[32m0.0220\u001b[0m       \u001b[35m0.9831\u001b[0m        \u001b[31m0.0472\u001b[0m  1.3493\n",
      "      8             0.9307        \u001b[32m0.0138\u001b[0m       0.9423        0.1730  1.3532\n",
      "      9             0.9746        0.0152       0.9803        0.0681  1.3526\n",
      "     10             0.9740        0.0187       0.9798        0.0775  1.3526\n",
      "Epoch 00011: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     11             0.9587        0.0215       0.9666        0.1040  1.3537\n",
      "     12             \u001b[36m0.9855\u001b[0m        0.0179       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0401\u001b[0m  1.3520\n",
      "     13             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0042\u001b[0m       \u001b[35m0.9918\u001b[0m        \u001b[31m0.0377\u001b[0m  1.3531\n",
      "     14             0.9878        \u001b[32m0.0024\u001b[0m       0.9904        0.0382  1.3539\n",
      "     15             0.9878        \u001b[32m0.0023\u001b[0m       0.9904        0.0390  1.3542\n",
      "     16             0.9872        \u001b[32m0.0017\u001b[0m       0.9899        0.0390  1.3523\n",
      "     17             0.9872        \u001b[32m0.0015\u001b[0m       0.9899        0.0392  1.3516\n",
      "     18             0.9849        \u001b[32m0.0014\u001b[0m       0.9881        0.0398  1.3511\n",
      "     19             0.9872        0.0015       0.9899        0.0398  1.3508\n",
      "     20             0.9872        \u001b[32m0.0011\u001b[0m       0.9899        0.0396  1.3506\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 18/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=16, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[16, 24, 24, 24, 32], module__residual=True, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.989) f1_score: (test=0.986) total time=  29.1s\n",
      "[CV 1/4; 19/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5454\u001b[0m        \u001b[32m0.3936\u001b[0m       \u001b[35m0.7448\u001b[0m        \u001b[31m0.7776\u001b[0m  0.4443\n",
      "      2             \u001b[36m0.8881\u001b[0m        \u001b[32m0.2074\u001b[0m       \u001b[35m0.9038\u001b[0m        \u001b[31m0.1823\u001b[0m  0.4449\n",
      "      3             \u001b[36m0.9369\u001b[0m        \u001b[32m0.1200\u001b[0m       \u001b[35m0.9473\u001b[0m        \u001b[31m0.1080\u001b[0m  0.4412\n",
      "      4             \u001b[36m0.9479\u001b[0m        \u001b[32m0.0943\u001b[0m       \u001b[35m0.9569\u001b[0m        \u001b[31m0.0872\u001b[0m  0.4409\n",
      "      5             \u001b[36m0.9687\u001b[0m        \u001b[32m0.0707\u001b[0m       \u001b[35m0.9748\u001b[0m        \u001b[31m0.0813\u001b[0m  0.4412\n",
      "      6             0.9568        0.0903       0.9643        \u001b[31m0.0778\u001b[0m  0.4411\n",
      "      7             0.9670        \u001b[32m0.0417\u001b[0m       0.9730        \u001b[31m0.0542\u001b[0m  0.4416\n",
      "      8             \u001b[36m0.9709\u001b[0m        \u001b[32m0.0363\u001b[0m       \u001b[35m0.9771\u001b[0m        0.1000  0.4437\n",
      "      9             \u001b[36m0.9743\u001b[0m        \u001b[32m0.0316\u001b[0m       \u001b[35m0.9794\u001b[0m        0.0709  0.4438\n",
      "     10             0.9603        0.0404       0.9679        0.1257  0.4442\n",
      "     11             0.9703        \u001b[32m0.0256\u001b[0m       0.9757        0.0659  0.4436\n",
      "     12             \u001b[36m0.9880\u001b[0m        \u001b[32m0.0107\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0334\u001b[0m  0.4476\n",
      "     13             0.9310        0.0257       0.9473        0.3152  0.4483\n",
      "     14             0.9195        0.0466       0.9317        0.2587  0.4470\n",
      "Epoch 00015: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     15             0.9758        0.0355       0.9808        0.0708  0.4468\n",
      "     16             \u001b[36m0.9914\u001b[0m        0.0169       \u001b[35m0.9931\u001b[0m        \u001b[31m0.0221\u001b[0m  0.4476\n",
      "     17             0.9914        \u001b[32m0.0066\u001b[0m       0.9931        \u001b[31m0.0198\u001b[0m  0.4426\n",
      "     18             0.9914        \u001b[32m0.0037\u001b[0m       0.9931        \u001b[31m0.0197\u001b[0m  0.4441\n",
      "     19             \u001b[36m0.9926\u001b[0m        \u001b[32m0.0036\u001b[0m       \u001b[35m0.9940\u001b[0m        0.0197  0.4439\n",
      "     20             0.9926        \u001b[32m0.0024\u001b[0m       0.9940        0.0200  0.4441\n",
      "     21             0.9920        \u001b[32m0.0021\u001b[0m       0.9936        0.0198  0.4438\n",
      "     22             0.9926        \u001b[32m0.0021\u001b[0m       0.9940        0.0211  0.4440\n",
      "     23             0.9920        \u001b[32m0.0015\u001b[0m       0.9936        0.0208  0.4439\n",
      "     24             0.9926        0.0016       0.9940        0.0211  0.4465\n",
      "     25             \u001b[36m0.9926\u001b[0m        \u001b[32m0.0015\u001b[0m       0.9940        0.0212  0.4467\n",
      "     26             0.9920        \u001b[32m0.0013\u001b[0m       0.9936        0.0222  0.4449\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 19/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.992) f1_score: (test=0.990) total time=  12.1s\n",
      "[CV 2/4; 19/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4227\u001b[0m        \u001b[32m0.3668\u001b[0m       \u001b[35m0.7274\u001b[0m        \u001b[31m2.2620\u001b[0m  0.4441\n",
      "      2             \u001b[36m0.8604\u001b[0m        \u001b[32m0.1891\u001b[0m       \u001b[35m0.8809\u001b[0m        \u001b[31m0.2690\u001b[0m  0.4446\n",
      "      3             0.8471        \u001b[32m0.1341\u001b[0m       0.8635        0.2744  0.4446\n",
      "      4             \u001b[36m0.9555\u001b[0m        \u001b[32m0.0957\u001b[0m       \u001b[35m0.9643\u001b[0m        \u001b[31m0.0963\u001b[0m  0.4447\n",
      "      5             0.9431        0.0992       0.9542        0.1182  0.4447\n",
      "      6             0.8884        \u001b[32m0.0770\u001b[0m       0.9038        0.2763  0.4455\n",
      "      7             \u001b[36m0.9679\u001b[0m        \u001b[32m0.0456\u001b[0m       \u001b[35m0.9743\u001b[0m        \u001b[31m0.0886\u001b[0m  0.4448\n",
      "      8             \u001b[36m0.9752\u001b[0m        \u001b[32m0.0268\u001b[0m       \u001b[35m0.9803\u001b[0m        \u001b[31m0.0779\u001b[0m  0.4446\n",
      "      9             0.9665        0.0282       0.9730        0.0829  0.4444\n",
      "     10             0.9358        0.0450       0.9469        0.1376  0.4460\n",
      "Epoch 00011: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     11             0.9649        0.0521       0.9725        0.1188  0.4446\n",
      "     12             \u001b[36m0.9759\u001b[0m        \u001b[32m0.0240\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0506\u001b[0m  0.4458\n",
      "     13             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0101\u001b[0m       \u001b[35m0.9872\u001b[0m        \u001b[31m0.0453\u001b[0m  0.4456\n",
      "     14             0.9821        \u001b[32m0.0075\u001b[0m       0.9858        \u001b[31m0.0432\u001b[0m  0.4453\n",
      "     15             \u001b[36m0.9850\u001b[0m        \u001b[32m0.0065\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0422\u001b[0m  0.4457\n",
      "     16             0.9827        \u001b[32m0.0052\u001b[0m       0.9863        0.0426  0.4450\n",
      "     17             \u001b[36m0.9856\u001b[0m        \u001b[32m0.0042\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0402\u001b[0m  0.4455\n",
      "     18             \u001b[36m0.9867\u001b[0m        \u001b[32m0.0039\u001b[0m       \u001b[35m0.9895\u001b[0m        \u001b[31m0.0391\u001b[0m  0.4457\n",
      "     19             0.9867        \u001b[32m0.0034\u001b[0m       0.9895        0.0395  0.4461\n",
      "     20             0.9867        \u001b[32m0.0030\u001b[0m       0.9895        0.0402  0.4443\n",
      "     21             0.9856        \u001b[32m0.0024\u001b[0m       0.9885        0.0394  0.4447\n",
      "     22             \u001b[36m0.9879\u001b[0m        \u001b[32m0.0021\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0390\u001b[0m  0.4445\n",
      "     23             0.9867        0.0022       0.9895        0.0397  0.4453\n",
      "     24             0.9879        \u001b[32m0.0020\u001b[0m       0.9904        0.0398  0.4468\n",
      "     25             \u001b[36m0.9879\u001b[0m        \u001b[32m0.0018\u001b[0m       0.9904        \u001b[31m0.0389\u001b[0m  0.4453\n",
      "     26             \u001b[36m0.9890\u001b[0m        \u001b[32m0.0017\u001b[0m       \u001b[35m0.9913\u001b[0m        \u001b[31m0.0381\u001b[0m  0.4452\n",
      "     27             0.9879        \u001b[32m0.0014\u001b[0m       0.9904        0.0385  0.4453\n",
      "     28             0.9884        \u001b[32m0.0012\u001b[0m       0.9908        \u001b[31m0.0376\u001b[0m  0.4469\n",
      "     29             0.9879        \u001b[32m0.0012\u001b[0m       0.9904        0.0393  0.4449\n",
      "     30             0.9879        \u001b[32m0.0009\u001b[0m       0.9904        0.0388  0.4446\n",
      "     31             0.9873        0.0009       0.9899        0.0392  0.4445\n",
      "     32             0.9884        \u001b[32m0.0009\u001b[0m       0.9908        0.0399  0.4444\n",
      "     33             0.9884        \u001b[32m0.0006\u001b[0m       0.9908        0.0394  0.4442\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 19/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.989) f1_score: (test=0.986) total time=  15.3s\n",
      "[CV 3/4; 19/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4639\u001b[0m        \u001b[32m0.4214\u001b[0m       \u001b[35m0.7160\u001b[0m        \u001b[31m0.9205\u001b[0m  0.4440\n",
      "      2             \u001b[36m0.9031\u001b[0m        \u001b[32m0.2113\u001b[0m       \u001b[35m0.9230\u001b[0m        \u001b[31m0.2323\u001b[0m  0.4464\n",
      "      3             \u001b[36m0.9442\u001b[0m        \u001b[32m0.1371\u001b[0m       \u001b[35m0.9565\u001b[0m        \u001b[31m0.1688\u001b[0m  0.4448\n",
      "      4             0.9419        \u001b[32m0.0811\u001b[0m       0.9524        \u001b[31m0.1046\u001b[0m  0.4457\n",
      "      5             \u001b[36m0.9561\u001b[0m        \u001b[32m0.0586\u001b[0m       \u001b[35m0.9643\u001b[0m        \u001b[31m0.0886\u001b[0m  0.4450\n",
      "      6             \u001b[36m0.9587\u001b[0m        \u001b[32m0.0412\u001b[0m       \u001b[35m0.9670\u001b[0m        0.1067  0.4449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7             0.9294        0.0874       0.9414        0.1469  0.4449\n",
      "      8             \u001b[36m0.9771\u001b[0m        0.0471       \u001b[35m0.9817\u001b[0m        \u001b[31m0.0656\u001b[0m  0.4454\n",
      "      9             \u001b[36m0.9820\u001b[0m        \u001b[32m0.0369\u001b[0m       \u001b[35m0.9858\u001b[0m        0.0769  0.4451\n",
      "     10             0.9403        \u001b[32m0.0343\u001b[0m       0.9505        0.1264  0.4451\n",
      "     11             0.9609        \u001b[32m0.0236\u001b[0m       0.9702        0.1790  0.4449\n",
      "     12             0.9779        \u001b[32m0.0143\u001b[0m       0.9826        0.0709  0.4451\n",
      "     13             0.9715        \u001b[32m0.0136\u001b[0m       0.9771        0.0964  0.4450\n",
      "     14             0.9623        0.0207       0.9698        0.0965  0.4459\n",
      "     15             0.9681        0.0284       0.9743        0.0887  0.4450\n",
      "Epoch 00016: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     16             0.8701        0.0446       0.8859        0.3574  0.4449\n",
      "     17             \u001b[36m0.9866\u001b[0m        0.0213       \u001b[35m0.9895\u001b[0m        \u001b[31m0.0510\u001b[0m  0.4459\n",
      "     18             0.9861        \u001b[32m0.0067\u001b[0m       0.9890        \u001b[31m0.0465\u001b[0m  0.4448\n",
      "     19             \u001b[36m0.9867\u001b[0m        \u001b[32m0.0046\u001b[0m       0.9895        \u001b[31m0.0414\u001b[0m  0.4450\n",
      "     20             \u001b[36m0.9872\u001b[0m        \u001b[32m0.0036\u001b[0m       \u001b[35m0.9899\u001b[0m        0.0429  0.4445\n",
      "     21             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0408\u001b[0m  0.4450\n",
      "     22             0.9872        \u001b[32m0.0025\u001b[0m       0.9899        0.0422  0.4444\n",
      "     23             0.9872        \u001b[32m0.0022\u001b[0m       0.9899        0.0411  0.4445\n",
      "     24             0.9878        \u001b[32m0.0018\u001b[0m       0.9904        0.0418  0.4442\n",
      "     25             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0017\u001b[0m       \u001b[35m0.9908\u001b[0m        0.0432  0.4446\n",
      "     26             0.9884        \u001b[32m0.0015\u001b[0m       0.9908        0.0414  0.4449\n",
      "     27             \u001b[36m0.9889\u001b[0m        \u001b[32m0.0012\u001b[0m       \u001b[35m0.9913\u001b[0m        0.0436  0.4449\n",
      "     28             \u001b[36m0.9889\u001b[0m        0.0013       0.9913        0.0423  0.4454\n",
      "     29             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0011\u001b[0m       \u001b[35m0.9918\u001b[0m        0.0434  0.4445\n",
      "     30             0.9884        \u001b[32m0.0010\u001b[0m       0.9908        0.0413  0.4449\n",
      "     31             0.9889        0.0010       0.9913        0.0421  0.4442\n",
      "     32             0.9889        0.0010       0.9913        0.0455  0.4517\n",
      "     33             0.9889        \u001b[32m0.0008\u001b[0m       0.9913        0.0434  0.4442\n",
      "     34             0.9884        \u001b[32m0.0008\u001b[0m       0.9908        0.0442  0.4437\n",
      "     35             0.9889        \u001b[32m0.0007\u001b[0m       0.9913        0.0435  0.4443\n",
      "     36             0.9884        0.0007       0.9908        0.0444  0.4437\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 19/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.991) f1_score: (test=0.988) total time=  16.6s\n",
      "[CV 4/4; 19/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4229\u001b[0m        \u001b[32m0.4158\u001b[0m       \u001b[35m0.7279\u001b[0m        \u001b[31m1.9118\u001b[0m  0.4433\n",
      "      2             \u001b[36m0.8757\u001b[0m        \u001b[32m0.1999\u001b[0m       \u001b[35m0.9075\u001b[0m        \u001b[31m0.3164\u001b[0m  0.4439\n",
      "      3             \u001b[36m0.9477\u001b[0m        \u001b[32m0.1271\u001b[0m       \u001b[35m0.9574\u001b[0m        \u001b[31m0.0991\u001b[0m  0.4450\n",
      "      4             0.9460        \u001b[32m0.0884\u001b[0m       0.9560        0.1080  0.4435\n",
      "      5             0.9012        \u001b[32m0.0795\u001b[0m       0.9240        0.2744  0.4454\n",
      "      6             \u001b[36m0.9689\u001b[0m        \u001b[32m0.0765\u001b[0m       \u001b[35m0.9753\u001b[0m        \u001b[31m0.0710\u001b[0m  0.4444\n",
      "      7             0.9559        \u001b[32m0.0327\u001b[0m       0.9643        0.0981  0.4445\n",
      "      8             \u001b[36m0.9767\u001b[0m        \u001b[32m0.0285\u001b[0m       \u001b[35m0.9817\u001b[0m        0.0746  0.4446\n",
      "      9             0.9675        0.0430       0.9739        0.0992  0.4445\n",
      "     10             0.9293        0.0320       0.9409        0.1462  0.4446\n",
      "Epoch 00011: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     11             0.9646        0.0327       0.9725        0.1190  0.4457\n",
      "     12             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0171\u001b[0m       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0377\u001b[0m  0.4452\n",
      "     13             0.9878        \u001b[32m0.0050\u001b[0m       0.9904        \u001b[31m0.0372\u001b[0m  0.4460\n",
      "     14             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0037\u001b[0m       \u001b[35m0.9922\u001b[0m        \u001b[31m0.0365\u001b[0m  0.4443\n",
      "     15             0.9901        \u001b[32m0.0030\u001b[0m       0.9922        0.0366  0.4439\n",
      "     16             0.9895        \u001b[32m0.0027\u001b[0m       0.9918        0.0378  0.4438\n",
      "     17             0.9895        \u001b[32m0.0021\u001b[0m       0.9918        0.0368  0.4439\n",
      "     18             0.9890        0.0022       0.9913        0.0392  0.4441\n",
      "     19             0.9884        \u001b[32m0.0017\u001b[0m       0.9908        0.0384  0.4440\n",
      "     20             0.9890        \u001b[32m0.0017\u001b[0m       0.9913        0.0384  0.4445\n",
      "     21             0.9884        \u001b[32m0.0016\u001b[0m       0.9908        0.0407  0.4440\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 19/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.994) f1_score: (test=0.992) total time=   9.9s\n",
      "[CV 1/4; 20/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4450\u001b[0m        \u001b[32m0.3959\u001b[0m       \u001b[35m0.7219\u001b[0m        \u001b[31m0.7182\u001b[0m  1.2050\n",
      "      2             \u001b[36m0.8886\u001b[0m        \u001b[32m0.1804\u001b[0m       \u001b[35m0.9098\u001b[0m        \u001b[31m0.2571\u001b[0m  1.2099\n",
      "      3             \u001b[36m0.9623\u001b[0m        \u001b[32m0.0812\u001b[0m       \u001b[35m0.9698\u001b[0m        \u001b[31m0.1002\u001b[0m  1.2089\n",
      "      4             \u001b[36m0.9692\u001b[0m        \u001b[32m0.0642\u001b[0m       \u001b[35m0.9753\u001b[0m        \u001b[31m0.0828\u001b[0m  1.2083\n",
      "      5             \u001b[36m0.9744\u001b[0m        \u001b[32m0.0535\u001b[0m       \u001b[35m0.9798\u001b[0m        0.0882  1.2173\n",
      "      6             \u001b[36m0.9748\u001b[0m        \u001b[32m0.0317\u001b[0m       0.9794        \u001b[31m0.0392\u001b[0m  1.2167\n",
      "      7             0.9747        \u001b[32m0.0202\u001b[0m       0.9794        0.0399  1.2169\n",
      "      8             \u001b[36m0.9834\u001b[0m        \u001b[32m0.0106\u001b[0m       \u001b[35m0.9867\u001b[0m        0.0489  1.2174\n",
      "      9             \u001b[36m0.9847\u001b[0m        \u001b[32m0.0065\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0240\u001b[0m  1.2171\n",
      "     10             \u001b[36m0.9886\u001b[0m        \u001b[32m0.0058\u001b[0m       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0186\u001b[0m  1.2160\n",
      "     11             0.9880        0.0077       0.9904        0.0317  1.2140\n",
      "     12             0.9733        0.0092       0.9785        0.0814  1.2085\n",
      "Epoch 00013: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     13             0.9649        0.0428       0.9716        0.0950  1.2088\n",
      "     14             0.9813        0.0172       0.9849        0.0330  1.2094\n",
      "     15             \u001b[36m0.9908\u001b[0m        \u001b[32m0.0054\u001b[0m       \u001b[35m0.9927\u001b[0m        0.0249  1.2090\n",
      "     16             0.9908        \u001b[32m0.0037\u001b[0m       0.9927        0.0231  1.2169\n",
      "     17             0.9897        \u001b[32m0.0030\u001b[0m       0.9918        0.0221  1.2172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     18             0.9908        \u001b[32m0.0024\u001b[0m       0.9927        0.0224  1.2086\n",
      "     19             \u001b[36m0.9914\u001b[0m        \u001b[32m0.0018\u001b[0m       \u001b[35m0.9931\u001b[0m        0.0228  1.2183\n",
      "     20             0.9908        \u001b[32m0.0017\u001b[0m       0.9927        0.0231  1.2152\n",
      "     21             \u001b[36m0.9920\u001b[0m        \u001b[32m0.0015\u001b[0m       \u001b[35m0.9936\u001b[0m        0.0229  1.2176\n",
      "     22             \u001b[36m0.9925\u001b[0m        \u001b[32m0.0015\u001b[0m       \u001b[35m0.9940\u001b[0m        0.0227  1.2162\n",
      "     23             0.9925        \u001b[32m0.0011\u001b[0m       0.9940        0.0225  1.2177\n",
      "     24             \u001b[36m0.9931\u001b[0m        0.0012       \u001b[35m0.9945\u001b[0m        0.0226  1.2167\n",
      "     25             0.9920        \u001b[32m0.0010\u001b[0m       0.9936        0.0214  1.2172\n",
      "     26             0.9914        0.0012       0.9931        0.0216  1.2187\n",
      "     27             0.9920        \u001b[32m0.0010\u001b[0m       0.9936        0.0229  1.2186\n",
      "     28             0.9925        \u001b[32m0.0008\u001b[0m       0.9940        0.0219  1.2189\n",
      "     29             0.9931        0.0009       0.9945        0.0219  1.2181\n",
      "     30             0.9931        \u001b[32m0.0008\u001b[0m       0.9945        0.0219  1.2172\n",
      "     31             0.9931        \u001b[32m0.0006\u001b[0m       0.9945        0.0223  1.2172\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 20/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.990) f1_score: (test=0.987) total time=  39.1s\n",
      "[CV 2/4; 20/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.6109\u001b[0m        \u001b[32m0.4011\u001b[0m       \u001b[35m0.7371\u001b[0m        \u001b[31m0.6440\u001b[0m  1.2186\n",
      "      2             \u001b[36m0.8763\u001b[0m        \u001b[32m0.1647\u001b[0m       \u001b[35m0.9070\u001b[0m        \u001b[31m0.2734\u001b[0m  1.2179\n",
      "      3             \u001b[36m0.9375\u001b[0m        \u001b[32m0.0882\u001b[0m       \u001b[35m0.9482\u001b[0m        \u001b[31m0.1181\u001b[0m  1.2185\n",
      "      4             \u001b[36m0.9770\u001b[0m        \u001b[32m0.0587\u001b[0m       \u001b[35m0.9817\u001b[0m        \u001b[31m0.0544\u001b[0m  1.2177\n",
      "      5             0.9730        \u001b[32m0.0390\u001b[0m       0.9785        0.0665  1.2188\n",
      "      6             0.9682        \u001b[32m0.0258\u001b[0m       0.9743        0.0593  1.2179\n",
      "      7             0.9303        \u001b[32m0.0185\u001b[0m       0.9418        0.1183  1.2125\n",
      "      8             \u001b[36m0.9798\u001b[0m        \u001b[32m0.0142\u001b[0m       \u001b[35m0.9840\u001b[0m        0.0587  1.2090\n",
      "      9             0.9791        0.0200       0.9835        0.0705  1.2148\n",
      "     10             \u001b[36m0.9821\u001b[0m        0.0152       \u001b[35m0.9858\u001b[0m        0.0588  1.2177\n",
      "Epoch 00011: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     11             0.9461        0.0193       0.9556        0.1061  1.2147\n",
      "     12             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0068\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0405\u001b[0m  1.2104\n",
      "     13             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0027\u001b[0m       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0313\u001b[0m  1.2101\n",
      "     14             0.9884        \u001b[32m0.0019\u001b[0m       0.9908        0.0319  1.2133\n",
      "     15             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0015\u001b[0m       \u001b[35m0.9918\u001b[0m        0.0313  1.2097\n",
      "     16             \u001b[36m0.9907\u001b[0m        \u001b[32m0.0012\u001b[0m       \u001b[35m0.9927\u001b[0m        \u001b[31m0.0313\u001b[0m  1.2101\n",
      "     17             0.9895        \u001b[32m0.0011\u001b[0m       0.9918        \u001b[31m0.0302\u001b[0m  1.2093\n",
      "     18             0.9901        \u001b[32m0.0010\u001b[0m       0.9922        \u001b[31m0.0300\u001b[0m  1.2089\n",
      "     19             0.9907        0.0010       0.9927        0.0302  1.2092\n",
      "     20             0.9901        \u001b[32m0.0009\u001b[0m       0.9922        0.0306  1.2082\n",
      "     21             0.9901        \u001b[32m0.0007\u001b[0m       0.9922        0.0306  1.2087\n",
      "     22             \u001b[36m0.9907\u001b[0m        0.0008       0.9927        0.0301  1.2119\n",
      "     23             0.9901        0.0007       0.9922        0.0306  1.2099\n",
      "Epoch 00024: reducing learning rate of group 0 to 2.0000e-06.\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 20/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.993) f1_score: (test=0.991) total time=  29.3s\n",
      "[CV 3/4; 20/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4438\u001b[0m        \u001b[32m0.3982\u001b[0m       \u001b[35m0.7293\u001b[0m        \u001b[31m0.7107\u001b[0m  1.2168\n",
      "      2             \u001b[36m0.8409\u001b[0m        \u001b[32m0.1568\u001b[0m       \u001b[35m0.8635\u001b[0m        \u001b[31m0.2625\u001b[0m  1.2108\n",
      "      3             \u001b[36m0.9649\u001b[0m        \u001b[32m0.0748\u001b[0m       \u001b[35m0.9721\u001b[0m        \u001b[31m0.0857\u001b[0m  1.2092\n",
      "      4             \u001b[36m0.9767\u001b[0m        \u001b[32m0.0463\u001b[0m       \u001b[35m0.9817\u001b[0m        \u001b[31m0.0808\u001b[0m  1.2118\n",
      "      5             0.9366        \u001b[32m0.0438\u001b[0m       0.9473        0.1173  1.2114\n",
      "      6             \u001b[36m0.9803\u001b[0m        \u001b[32m0.0398\u001b[0m       \u001b[35m0.9844\u001b[0m        \u001b[31m0.0614\u001b[0m  1.2101\n",
      "      7             \u001b[36m0.9821\u001b[0m        \u001b[32m0.0168\u001b[0m       \u001b[35m0.9858\u001b[0m        \u001b[31m0.0530\u001b[0m  1.2103\n",
      "      8             0.9066        \u001b[32m0.0138\u001b[0m       0.9203        0.2093  1.2112\n",
      "      9             0.9559        0.0337       0.9643        0.1047  1.2139\n",
      "     10             0.9746        0.0250       0.9803        0.1226  1.2154\n",
      "Epoch 00011: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     11             0.9557        0.0233       0.9638        0.0841  1.2138\n",
      "     12             \u001b[36m0.9849\u001b[0m        \u001b[32m0.0073\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0395\u001b[0m  1.2153\n",
      "     13             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0028\u001b[0m       \u001b[35m0.9908\u001b[0m        0.0410  1.2140\n",
      "     14             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0020\u001b[0m       \u001b[35m0.9918\u001b[0m        0.0404  1.2131\n",
      "     15             0.9884        \u001b[32m0.0016\u001b[0m       0.9908        0.0405  1.2144\n",
      "     16             0.9895        0.0018       0.9918        0.0415  1.2154\n",
      "     17             0.9884        \u001b[32m0.0012\u001b[0m       0.9908        \u001b[31m0.0394\u001b[0m  1.2137\n",
      "     18             0.9895        0.0013       0.9918        0.0401  1.2264\n",
      "     19             0.9895        \u001b[32m0.0010\u001b[0m       0.9918        0.0409  1.2356\n",
      "     20             0.9889        0.0011       0.9913        0.0409  1.3223\n",
      "     21             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9922\u001b[0m        0.0414  1.2742\n",
      "     22             0.9895        \u001b[32m0.0008\u001b[0m       0.9918        0.0407  1.2241\n",
      "     23             0.9895        \u001b[32m0.0008\u001b[0m       0.9918        0.0405  1.2612\n",
      "     24             0.9895        \u001b[32m0.0007\u001b[0m       0.9918        0.0398  1.2915\n",
      "     25             0.9895        \u001b[32m0.0006\u001b[0m       0.9918        0.0410  1.3280\n",
      "     26             0.9895        0.0007       0.9918        0.0403  1.2253\n",
      "     27             0.9895        \u001b[32m0.0006\u001b[0m       0.9918        0.0419  1.2231\n",
      "     28             0.9895        0.0006       0.9918        0.0398  1.2168\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 20/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.992) f1_score: (test=0.991) total time=  36.0s\n",
      "[CV 4/4; 20/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4050\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m1.2080\u001b[0m  1.3466\n",
      "      2             \u001b[36m0.9271\u001b[0m        \u001b[32m0.1473\u001b[0m       \u001b[35m0.9409\u001b[0m        \u001b[31m0.1707\u001b[0m  1.3241\n",
      "      3             \u001b[36m0.9540\u001b[0m        \u001b[32m0.0907\u001b[0m       \u001b[35m0.9624\u001b[0m        \u001b[31m0.0809\u001b[0m  1.2931\n",
      "      4             \u001b[36m0.9597\u001b[0m        \u001b[32m0.0437\u001b[0m       \u001b[35m0.9675\u001b[0m        0.0913  1.2939\n",
      "      5             \u001b[36m0.9670\u001b[0m        \u001b[32m0.0415\u001b[0m       \u001b[35m0.9739\u001b[0m        0.0831  1.2908\n",
      "      6             \u001b[36m0.9798\u001b[0m        \u001b[32m0.0252\u001b[0m       \u001b[35m0.9840\u001b[0m        \u001b[31m0.0498\u001b[0m  1.2867\n",
      "      7             0.9207        \u001b[32m0.0234\u001b[0m       0.9331        0.1483  1.2890\n",
      "      8             0.8974        0.0541       0.9120        0.2229  1.2887\n",
      "      9             \u001b[36m0.9844\u001b[0m        \u001b[32m0.0221\u001b[0m       \u001b[35m0.9876\u001b[0m        \u001b[31m0.0409\u001b[0m  1.2856\n",
      "     10             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0092\u001b[0m       \u001b[35m0.9890\u001b[0m        0.0434  1.2891\n",
      "     11             0.9514        0.0095       0.9601        0.0930  1.2892\n",
      "     12             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0069\u001b[0m       \u001b[35m0.9918\u001b[0m        0.0432  1.2877\n",
      "     13             \u001b[36m0.9919\u001b[0m        \u001b[32m0.0024\u001b[0m       \u001b[35m0.9936\u001b[0m        \u001b[31m0.0320\u001b[0m  1.2893\n",
      "     14             \u001b[36m0.9936\u001b[0m        \u001b[32m0.0011\u001b[0m       \u001b[35m0.9950\u001b[0m        0.0330  1.2843\n",
      "     15             \u001b[36m0.9942\u001b[0m        \u001b[32m0.0006\u001b[0m       \u001b[35m0.9954\u001b[0m        0.0345  1.2900\n",
      "     16             0.9936        \u001b[32m0.0003\u001b[0m       0.9950        0.0334  1.2864\n",
      "     17             0.9936        \u001b[32m0.0002\u001b[0m       0.9950        0.0356  1.2893\n",
      "     18             0.9924        \u001b[32m0.0002\u001b[0m       0.9940        0.0366  1.2885\n",
      "     19             0.9930        \u001b[32m0.0001\u001b[0m       0.9945        0.0353  1.2889\n",
      "     20             0.9925        \u001b[32m0.0001\u001b[0m       0.9940        0.0359  1.2877\n",
      "     21             0.9924        \u001b[32m0.0001\u001b[0m       0.9940        0.0373  1.2891\n",
      "     22             0.9924        0.0001       0.9940        0.0370  1.2894\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 20/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.997) f1_score: (test=0.996) total time=  30.0s\n",
      "[CV 1/4; 21/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4199\u001b[0m        \u001b[32m0.5242\u001b[0m       \u001b[35m0.7238\u001b[0m        \u001b[31m0.6097\u001b[0m  0.3074\n",
      "      2             \u001b[36m0.7718\u001b[0m        \u001b[32m0.3837\u001b[0m       \u001b[35m0.8213\u001b[0m        \u001b[31m0.3825\u001b[0m  0.3040\n",
      "      3             \u001b[36m0.9024\u001b[0m        \u001b[32m0.2634\u001b[0m       \u001b[35m0.9212\u001b[0m        \u001b[31m0.2094\u001b[0m  0.3062\n",
      "      4             \u001b[36m0.9391\u001b[0m        \u001b[32m0.1642\u001b[0m       \u001b[35m0.9514\u001b[0m        \u001b[31m0.1344\u001b[0m  0.3061\n",
      "      5             \u001b[36m0.9547\u001b[0m        \u001b[32m0.1035\u001b[0m       \u001b[35m0.9638\u001b[0m        \u001b[31m0.0983\u001b[0m  0.3178\n",
      "      6             \u001b[36m0.9585\u001b[0m        \u001b[32m0.0723\u001b[0m       \u001b[35m0.9670\u001b[0m        \u001b[31m0.0850\u001b[0m  0.3069\n",
      "      7             \u001b[36m0.9623\u001b[0m        \u001b[32m0.0500\u001b[0m       \u001b[35m0.9698\u001b[0m        \u001b[31m0.0756\u001b[0m  0.3086\n",
      "      8             0.9540        0.0523       0.9629        0.0877  0.3071\n",
      "      9             \u001b[36m0.9649\u001b[0m        \u001b[32m0.0330\u001b[0m       \u001b[35m0.9716\u001b[0m        \u001b[31m0.0665\u001b[0m  0.3054\n",
      "     10             \u001b[36m0.9697\u001b[0m        \u001b[32m0.0187\u001b[0m       \u001b[35m0.9762\u001b[0m        \u001b[31m0.0620\u001b[0m  0.3048\n",
      "     11             \u001b[36m0.9714\u001b[0m        \u001b[32m0.0120\u001b[0m       \u001b[35m0.9771\u001b[0m        \u001b[31m0.0584\u001b[0m  0.3034\n",
      "     12             \u001b[36m0.9726\u001b[0m        \u001b[32m0.0073\u001b[0m       \u001b[35m0.9780\u001b[0m        0.0587  0.3045\n",
      "     13             \u001b[36m0.9737\u001b[0m        \u001b[32m0.0055\u001b[0m       \u001b[35m0.9789\u001b[0m        \u001b[31m0.0547\u001b[0m  0.3073\n",
      "     14             0.9731        \u001b[32m0.0037\u001b[0m       0.9785        0.0597  0.3049\n",
      "     15             \u001b[36m0.9759\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0544\u001b[0m  0.3039\n",
      "     16             0.9758        \u001b[32m0.0019\u001b[0m       0.9808        0.0552  0.3043\n",
      "     17             0.9746        \u001b[32m0.0017\u001b[0m       0.9798        0.0568  0.3101\n",
      "     18             0.9739        0.0019       0.9789        0.0624  0.3040\n",
      "     19             0.9749        \u001b[32m0.0014\u001b[0m       0.9798        0.0621  0.3010\n",
      "     20             \u001b[36m0.9776\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9821\u001b[0m        0.0571  0.3027\n",
      "     21             \u001b[36m0.9777\u001b[0m        \u001b[32m0.0007\u001b[0m       0.9821        0.0563  0.3013\n",
      "     22             0.9771        0.0007       0.9817        0.0574  0.3033\n",
      "     23             0.9755        \u001b[32m0.0005\u001b[0m       0.9803        0.0612  0.3020\n",
      "     24             \u001b[36m0.9788\u001b[0m        \u001b[32m0.0005\u001b[0m       \u001b[35m0.9831\u001b[0m        0.0584  0.3045\n",
      "     25             0.9749        \u001b[32m0.0004\u001b[0m       0.9798        0.0614  0.3033\n",
      "     26             0.9754        0.0005       0.9803        0.0610  0.3034\n",
      "     27             0.9766        0.0005       0.9812        0.0611  0.3022\n",
      "Epoch 00028: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     28             0.9777        0.0005       0.9821        0.0645  0.3056\n",
      "     29             0.9771        \u001b[32m0.0004\u001b[0m       0.9817        0.0638  0.3025\n",
      "     30             0.9777        0.0004       0.9821        0.0624  0.3018\n",
      "     31             0.9783        \u001b[32m0.0003\u001b[0m       0.9826        0.0619  0.3025\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 21/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.977) f1_score: (test=0.972) total time=   9.9s\n",
      "[CV 2/4; 21/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.5350\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.6121\u001b[0m  0.3047\n",
      "      2             \u001b[36m0.8001\u001b[0m        \u001b[32m0.4056\u001b[0m       \u001b[35m0.8323\u001b[0m        \u001b[31m0.3998\u001b[0m  0.3095\n",
      "      3             \u001b[36m0.8892\u001b[0m        \u001b[32m0.2391\u001b[0m       \u001b[35m0.9070\u001b[0m        \u001b[31m0.2233\u001b[0m  0.3036\n",
      "      4             \u001b[36m0.9468\u001b[0m        \u001b[32m0.1235\u001b[0m       \u001b[35m0.9574\u001b[0m        \u001b[31m0.1185\u001b[0m  0.3015\n",
      "      5             \u001b[36m0.9630\u001b[0m        \u001b[32m0.0758\u001b[0m       \u001b[35m0.9707\u001b[0m        \u001b[31m0.0951\u001b[0m  0.3026\n",
      "      6             0.9620        \u001b[32m0.0439\u001b[0m       0.9698        \u001b[31m0.0835\u001b[0m  0.3067\n",
      "      7             0.9629        \u001b[32m0.0275\u001b[0m       0.9702        0.0876  0.3083\n",
      "      8             0.9628        \u001b[32m0.0179\u001b[0m       \u001b[35m0.9711\u001b[0m        0.0839  0.3066\n",
      "      9             \u001b[36m0.9679\u001b[0m        \u001b[32m0.0130\u001b[0m       \u001b[35m0.9743\u001b[0m        \u001b[31m0.0830\u001b[0m  0.3068\n",
      "     10             \u001b[36m0.9682\u001b[0m        0.0132       \u001b[35m0.9748\u001b[0m        \u001b[31m0.0771\u001b[0m  0.3055\n",
      "     11             0.9667        0.0131       0.9734        0.0829  0.3056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12             \u001b[36m0.9724\u001b[0m        \u001b[32m0.0101\u001b[0m       \u001b[35m0.9780\u001b[0m        \u001b[31m0.0759\u001b[0m  0.3075\n",
      "     13             \u001b[36m0.9740\u001b[0m        \u001b[32m0.0041\u001b[0m       \u001b[35m0.9794\u001b[0m        \u001b[31m0.0748\u001b[0m  0.3042\n",
      "     14             \u001b[36m0.9746\u001b[0m        \u001b[32m0.0026\u001b[0m       \u001b[35m0.9798\u001b[0m        \u001b[31m0.0740\u001b[0m  0.3050\n",
      "     15             \u001b[36m0.9755\u001b[0m        \u001b[32m0.0023\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0687\u001b[0m  0.3082\n",
      "     16             0.9750        \u001b[32m0.0014\u001b[0m       0.9803        0.0746  0.3096\n",
      "     17             \u001b[36m0.9774\u001b[0m        \u001b[32m0.0008\u001b[0m       \u001b[35m0.9821\u001b[0m        0.0709  0.3112\n",
      "     18             \u001b[36m0.9785\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9831\u001b[0m        0.0715  0.3075\n",
      "     19             0.9763        0.0007       0.9812        0.0734  0.3100\n",
      "     20             0.9774        \u001b[32m0.0005\u001b[0m       0.9821        0.0733  0.3070\n",
      "     21             0.9763        \u001b[32m0.0004\u001b[0m       0.9812        0.0757  0.3066\n",
      "     22             0.9785        \u001b[32m0.0004\u001b[0m       0.9831        0.0732  0.3054\n",
      "     23             \u001b[36m0.9791\u001b[0m        \u001b[32m0.0003\u001b[0m       \u001b[35m0.9835\u001b[0m        0.0722  0.3045\n",
      "     24             0.9786        \u001b[32m0.0003\u001b[0m       0.9831        0.0736  0.3074\n",
      "     25             0.9785        0.0003       0.9831        0.0756  0.3077\n",
      "     26             0.9780        \u001b[32m0.0002\u001b[0m       0.9826        0.0721  0.3062\n",
      "     27             0.9768        0.0002       0.9817        0.0754  0.3056\n",
      "     28             \u001b[36m0.9792\u001b[0m        \u001b[32m0.0002\u001b[0m       0.9835        0.0742  0.3046\n",
      "     29             0.9780        0.0002       0.9826        0.0759  0.2996\n",
      "     30             0.9792        0.0004       0.9835        0.0743  0.3057\n",
      "Epoch 00031: reducing learning rate of group 0 to 2.0000e-05.\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 21/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=   9.6s\n",
      "[CV 3/4; 21/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.5082\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.6049\u001b[0m  0.3071\n",
      "      2             \u001b[36m0.7898\u001b[0m        \u001b[32m0.3238\u001b[0m       \u001b[35m0.8342\u001b[0m        \u001b[31m0.3331\u001b[0m  0.3070\n",
      "      3             \u001b[36m0.9192\u001b[0m        \u001b[32m0.2021\u001b[0m       \u001b[35m0.9354\u001b[0m        \u001b[31m0.1725\u001b[0m  0.3039\n",
      "      4             \u001b[36m0.9241\u001b[0m        \u001b[32m0.1213\u001b[0m       \u001b[35m0.9368\u001b[0m        \u001b[31m0.1548\u001b[0m  0.3168\n",
      "      5             \u001b[36m0.9329\u001b[0m        \u001b[32m0.0929\u001b[0m       \u001b[35m0.9459\u001b[0m        \u001b[31m0.1359\u001b[0m  0.3083\n",
      "      6             \u001b[36m0.9679\u001b[0m        \u001b[32m0.0644\u001b[0m       \u001b[35m0.9743\u001b[0m        \u001b[31m0.0769\u001b[0m  0.3147\n",
      "      7             \u001b[36m0.9682\u001b[0m        \u001b[32m0.0341\u001b[0m       \u001b[35m0.9748\u001b[0m        \u001b[31m0.0660\u001b[0m  0.3097\n",
      "      8             \u001b[36m0.9785\u001b[0m        \u001b[32m0.0218\u001b[0m       \u001b[35m0.9831\u001b[0m        \u001b[31m0.0556\u001b[0m  0.3101\n",
      "      9             0.9715        \u001b[32m0.0181\u001b[0m       0.9776        0.0643  0.3110\n",
      "     10             0.9783        \u001b[32m0.0100\u001b[0m       0.9831        0.0631  0.3076\n",
      "     11             0.9749        \u001b[32m0.0064\u001b[0m       0.9803        0.0612  0.3170\n",
      "     12             \u001b[36m0.9786\u001b[0m        \u001b[32m0.0041\u001b[0m       0.9831        0.0619  0.3190\n",
      "     13             \u001b[36m0.9808\u001b[0m        \u001b[32m0.0027\u001b[0m       \u001b[35m0.9849\u001b[0m        0.0564  0.3088\n",
      "     14             0.9774        0.0030       0.9821        0.0626  0.3095\n",
      "     15             0.9737        0.0047       0.9794        0.0644  0.3110\n",
      "Epoch 00016: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     16             0.9703        0.0074       0.9762        0.0873  0.3101\n",
      "     17             0.9791        0.0043       0.9835        0.0594  0.3179\n",
      "     18             \u001b[36m0.9820\u001b[0m        \u001b[32m0.0021\u001b[0m       \u001b[35m0.9858\u001b[0m        0.0563  0.3089\n",
      "     19             0.9803        \u001b[32m0.0017\u001b[0m       0.9844        0.0564  0.3082\n",
      "     20             0.9814        \u001b[32m0.0015\u001b[0m       0.9853        0.0560  0.3138\n",
      "     21             0.9808        \u001b[32m0.0012\u001b[0m       0.9849        0.0574  0.3122\n",
      "     22             0.9808        \u001b[32m0.0010\u001b[0m       0.9849        0.0577  0.3102\n",
      "     23             0.9814        0.0012       0.9853        0.0561  0.3081\n",
      "     24             \u001b[36m0.9826\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9863\u001b[0m        0.0556  0.3092\n",
      "     25             \u001b[36m0.9838\u001b[0m        0.0010       \u001b[35m0.9872\u001b[0m        0.0558  0.3119\n",
      "     26             \u001b[36m0.9838\u001b[0m        0.0011       0.9872        \u001b[31m0.0554\u001b[0m  0.3134\n",
      "     27             0.9837        \u001b[32m0.0009\u001b[0m       0.9872        \u001b[31m0.0553\u001b[0m  0.3136\n",
      "     28             0.9826        \u001b[32m0.0008\u001b[0m       0.9863        0.0560  0.3097\n",
      "     29             0.9820        0.0016       0.9858        0.0574  0.3129\n",
      "     30             0.9792        0.0009       0.9835        0.0598  0.3123\n",
      "Epoch 00031: reducing learning rate of group 0 to 2.0000e-06.\n",
      "     31             0.9808        0.0008       0.9849        0.0578  0.3081\n",
      "     32             0.9815        0.0010       0.9853        0.0569  0.3112\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 21/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.981) f1_score: (test=0.976) total time=  10.4s\n",
      "[CV 4/4; 21/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.5215\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.5831\u001b[0m  0.3154\n",
      "      2             \u001b[36m0.7963\u001b[0m        \u001b[32m0.3432\u001b[0m       \u001b[35m0.8520\u001b[0m        \u001b[31m0.3127\u001b[0m  0.3104\n",
      "      3             \u001b[36m0.9266\u001b[0m        \u001b[32m0.1873\u001b[0m       \u001b[35m0.9437\u001b[0m        \u001b[31m0.1468\u001b[0m  0.3079\n",
      "      4             \u001b[36m0.9421\u001b[0m        \u001b[32m0.1086\u001b[0m       \u001b[35m0.9556\u001b[0m        \u001b[31m0.1193\u001b[0m  0.3102\n",
      "      5             \u001b[36m0.9628\u001b[0m        \u001b[32m0.0606\u001b[0m       \u001b[35m0.9707\u001b[0m        \u001b[31m0.0891\u001b[0m  0.3096\n",
      "      6             \u001b[36m0.9641\u001b[0m        \u001b[32m0.0403\u001b[0m       \u001b[35m0.9711\u001b[0m        \u001b[31m0.0886\u001b[0m  0.3097\n",
      "      7             \u001b[36m0.9680\u001b[0m        \u001b[32m0.0243\u001b[0m       \u001b[35m0.9743\u001b[0m        \u001b[31m0.0811\u001b[0m  0.3111\n",
      "      8             \u001b[36m0.9711\u001b[0m        \u001b[32m0.0151\u001b[0m       \u001b[35m0.9771\u001b[0m        \u001b[31m0.0709\u001b[0m  0.3058\n",
      "      9             \u001b[36m0.9719\u001b[0m        \u001b[32m0.0111\u001b[0m       \u001b[35m0.9776\u001b[0m        0.0768  0.3050\n",
      "     10             \u001b[36m0.9722\u001b[0m        \u001b[32m0.0068\u001b[0m       \u001b[35m0.9780\u001b[0m        0.0749  0.3043\n",
      "     11             0.9709        \u001b[32m0.0049\u001b[0m       0.9771        0.0756  0.3109\n",
      "     12             \u001b[36m0.9724\u001b[0m        \u001b[32m0.0030\u001b[0m       0.9780        0.0829  0.3081\n",
      "     13             0.9707        \u001b[32m0.0028\u001b[0m       0.9766        0.0959  0.3159\n",
      "     14             \u001b[36m0.9747\u001b[0m        0.0029       \u001b[35m0.9798\u001b[0m        0.0782  0.3091\n",
      "     15             0.9649        \u001b[32m0.0027\u001b[0m       0.9725        0.1027  0.3063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     16             0.9724        \u001b[32m0.0023\u001b[0m       0.9780        0.0955  0.3148\n",
      "     17             \u001b[36m0.9761\u001b[0m        \u001b[32m0.0014\u001b[0m       \u001b[35m0.9812\u001b[0m        \u001b[31m0.0692\u001b[0m  0.3044\n",
      "     18             0.9756        \u001b[32m0.0007\u001b[0m       0.9808        0.0770  0.3060\n",
      "     19             0.9752        \u001b[32m0.0005\u001b[0m       0.9803        0.0882  0.3080\n",
      "     20             \u001b[36m0.9769\u001b[0m        \u001b[32m0.0004\u001b[0m       \u001b[35m0.9817\u001b[0m        0.0832  0.3087\n",
      "     21             0.9758        0.0005       0.9808        0.0875  0.3131\n",
      "     22             0.9762        \u001b[32m0.0003\u001b[0m       0.9812        0.0832  0.3117\n",
      "     23             0.9769        \u001b[32m0.0003\u001b[0m       0.9817        0.0871  0.3078\n",
      "     24             0.9757        0.0003       0.9808        0.0873  0.3008\n",
      "     25             \u001b[36m0.9774\u001b[0m        0.0003       \u001b[35m0.9821\u001b[0m        0.0860  0.3103\n",
      "Epoch 00026: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     26             0.9757        0.0003       0.9808        0.0936  0.3075\n",
      "     27             \u001b[36m0.9774\u001b[0m        0.0003       0.9821        0.0876  0.3084\n",
      "     28             0.9774        \u001b[32m0.0002\u001b[0m       0.9821        0.0883  0.3089\n",
      "     29             0.9774        \u001b[32m0.0002\u001b[0m       0.9821        0.0881  0.3091\n",
      "     30             0.9768        0.0002       0.9817        0.0865  0.3017\n",
      "     31             0.9757        0.0003       0.9808        0.0889  0.3001\n",
      "     32             0.9763        \u001b[32m0.0002\u001b[0m       0.9812        0.0886  0.3014\n",
      "     33             \u001b[36m0.9786\u001b[0m        \u001b[32m0.0002\u001b[0m       \u001b[35m0.9831\u001b[0m        0.0860  0.3038\n",
      "     34             0.9786        \u001b[32m0.0002\u001b[0m       0.9831        0.0856  0.3058\n",
      "     35             0.9786        0.0002       0.9831        0.0851  0.3027\n",
      "     36             0.9786        0.0003       0.9831        0.0851  0.3057\n",
      "Epoch 00037: reducing learning rate of group 0 to 2.0000e-06.\n",
      "     37             0.9785        0.0002       0.9831        0.0838  0.3081\n",
      "     38             0.9785        0.0002       0.9831        0.0848  0.3025\n",
      "     39             0.9780        0.0003       0.9826        0.0858  0.3028\n",
      "     40             0.9780        \u001b[32m0.0002\u001b[0m       0.9826        0.0857  0.3039\n",
      "     41             \u001b[36m0.9791\u001b[0m        0.0002       \u001b[35m0.9835\u001b[0m        0.0846  0.3159\n",
      "     42             0.9786        0.0002       0.9831        0.0849  0.3092\n",
      "Epoch 00043: reducing learning rate of group 0 to 1.0000e-06.\n",
      "     43             \u001b[36m0.9791\u001b[0m        0.0002       0.9835        0.0851  0.3071\n",
      "     44             0.9786        0.0002       0.9831        0.0857  0.3076\n",
      "     45             0.9786        0.0002       0.9831        0.0858  0.3065\n",
      "     46             0.9786        0.0002       0.9831        0.0852  0.3090\n",
      "     47             0.9780        0.0002       0.9826        0.0855  0.3066\n",
      "     48             0.9780        0.0002       0.9826        0.0853  0.3086\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 21/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=16, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[16, 24, 24, 24, 32], module__residual=False, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.985) f1_score: (test=0.982) total time=  15.3s\n",
      "[CV 1/4; 22/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4199\u001b[0m        \u001b[32m0.3731\u001b[0m       \u001b[35m0.7238\u001b[0m        \u001b[31m1.3156\u001b[0m  0.7565\n",
      "      2             \u001b[36m0.8464\u001b[0m        \u001b[32m0.1771\u001b[0m       \u001b[35m0.8626\u001b[0m        \u001b[31m0.3354\u001b[0m  0.7593\n",
      "      3             \u001b[36m0.9075\u001b[0m        \u001b[32m0.0975\u001b[0m       \u001b[35m0.9313\u001b[0m        \u001b[31m0.1921\u001b[0m  0.7592\n",
      "      4             0.8600        0.0998       0.9006        0.4366  0.7596\n",
      "      5             \u001b[36m0.9247\u001b[0m        \u001b[32m0.0621\u001b[0m       \u001b[35m0.9427\u001b[0m        \u001b[31m0.1405\u001b[0m  0.7606\n",
      "      6             \u001b[36m0.9743\u001b[0m        \u001b[32m0.0444\u001b[0m       \u001b[35m0.9798\u001b[0m        \u001b[31m0.0861\u001b[0m  0.7574\n",
      "      7             0.9557        \u001b[32m0.0389\u001b[0m       0.9656        0.1014  0.7560\n",
      "      8             0.9418        0.0458       0.9519        0.1153  0.7546\n",
      "      9             \u001b[36m0.9891\u001b[0m        \u001b[32m0.0243\u001b[0m       \u001b[35m0.9913\u001b[0m        \u001b[31m0.0249\u001b[0m  0.7544\n",
      "     10             \u001b[36m0.9920\u001b[0m        \u001b[32m0.0158\u001b[0m       \u001b[35m0.9936\u001b[0m        \u001b[31m0.0165\u001b[0m  0.7551\n",
      "     11             0.9375        0.0168       0.9473        0.1750  0.7683\n",
      "     12             0.9141        0.0459       0.9262        0.3285  0.7606\n",
      "Epoch 00013: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     13             0.9536        0.0224       0.9643        0.1126  0.7595\n",
      "     14             0.9914        \u001b[32m0.0111\u001b[0m       0.9931        0.0236  0.7620\n",
      "     15             \u001b[36m0.9925\u001b[0m        \u001b[32m0.0047\u001b[0m       \u001b[35m0.9940\u001b[0m        0.0218  0.7588\n",
      "     16             \u001b[36m0.9937\u001b[0m        \u001b[32m0.0033\u001b[0m       \u001b[35m0.9950\u001b[0m        0.0200  0.7609\n",
      "     17             0.9937        \u001b[32m0.0029\u001b[0m       0.9950        0.0199  0.7567\n",
      "     18             \u001b[36m0.9948\u001b[0m        \u001b[32m0.0022\u001b[0m       \u001b[35m0.9959\u001b[0m        0.0186  0.7602\n",
      "     19             0.9948        \u001b[32m0.0018\u001b[0m       0.9959        0.0187  0.7577\n",
      "     20             0.9948        \u001b[32m0.0017\u001b[0m       0.9959        0.0187  0.7569\n",
      "     21             0.9948        \u001b[32m0.0016\u001b[0m       0.9959        0.0190  0.7601\n",
      "     22             0.9943        \u001b[32m0.0012\u001b[0m       0.9954        0.0194  0.7568\n",
      "     23             0.9943        \u001b[32m0.0012\u001b[0m       0.9954        0.0189  0.7563\n",
      "     24             0.9937        \u001b[32m0.0011\u001b[0m       0.9950        0.0188  0.7555\n",
      "     25             0.9937        \u001b[32m0.0011\u001b[0m       0.9950        0.0191  0.7555\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 22/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.993) f1_score: (test=0.991) total time=  19.9s\n",
      "[CV 2/4; 22/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.3742\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.7956\u001b[0m  0.7555\n",
      "      2             \u001b[36m0.8220\u001b[0m        \u001b[32m0.1864\u001b[0m       \u001b[35m0.8681\u001b[0m        \u001b[31m0.3081\u001b[0m  0.7566\n",
      "      3             \u001b[36m0.9560\u001b[0m        \u001b[32m0.1173\u001b[0m       \u001b[35m0.9643\u001b[0m        \u001b[31m0.1009\u001b[0m  0.7557\n",
      "      4             \u001b[36m0.9675\u001b[0m        \u001b[32m0.1005\u001b[0m       \u001b[35m0.9743\u001b[0m        \u001b[31m0.0745\u001b[0m  0.7566\n",
      "      5             0.9665        \u001b[32m0.0552\u001b[0m       0.9734        \u001b[31m0.0727\u001b[0m  0.7546\n",
      "      6             0.9524        \u001b[32m0.0395\u001b[0m       0.9638        0.1663  0.7556\n",
      "      7             0.9210        \u001b[32m0.0277\u001b[0m       0.9336        0.2293  0.7549\n",
      "      8             0.9346        0.0351       0.9455        0.1695  0.7543\n",
      "      9             0.9259        0.0281       0.9377        0.2081  0.7613\n",
      "     10             0.9558        \u001b[32m0.0241\u001b[0m       0.9661        0.1012  0.7559\n",
      "     11             0.9659        0.0400       0.9725        0.0864  0.7549\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 22/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.971) f1_score: (test=0.964) total time=   9.2s\n",
      "[CV 3/4; 22/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4877\u001b[0m        \u001b[32m0.4047\u001b[0m       \u001b[35m0.7393\u001b[0m        \u001b[31m0.5305\u001b[0m  0.7606\n",
      "      2             \u001b[36m0.8005\u001b[0m        \u001b[32m0.1938\u001b[0m       \u001b[35m0.8562\u001b[0m        \u001b[31m0.3141\u001b[0m  0.7551\n",
      "      3             \u001b[36m0.9186\u001b[0m        \u001b[32m0.1475\u001b[0m       \u001b[35m0.9345\u001b[0m        \u001b[31m0.1585\u001b[0m  0.7548\n",
      "      4             \u001b[36m0.9606\u001b[0m        \u001b[32m0.1043\u001b[0m       \u001b[35m0.9698\u001b[0m        \u001b[31m0.0915\u001b[0m  0.7553\n",
      "      5             \u001b[36m0.9647\u001b[0m        \u001b[32m0.0865\u001b[0m       \u001b[35m0.9721\u001b[0m        0.0942  0.7543\n",
      "      6             0.8894        \u001b[32m0.0562\u001b[0m       0.9185        0.2220  0.7571\n",
      "      7             0.9234        \u001b[32m0.0494\u001b[0m       0.9432        0.1894  0.7525\n",
      "      8             0.9023        \u001b[32m0.0432\u001b[0m       0.9295        0.2311  0.7543\n",
      "      9             0.9562        0.0537       0.9647        0.1229  0.7545\n",
      "     10             \u001b[36m0.9722\u001b[0m        \u001b[32m0.0313\u001b[0m       \u001b[35m0.9780\u001b[0m        \u001b[31m0.0682\u001b[0m  0.7565\n",
      "     11             \u001b[36m0.9815\u001b[0m        \u001b[32m0.0173\u001b[0m       \u001b[35m0.9853\u001b[0m        \u001b[31m0.0468\u001b[0m  0.7571\n",
      "     12             \u001b[36m0.9849\u001b[0m        \u001b[32m0.0119\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0412\u001b[0m  0.7560\n",
      "     13             0.9568        0.0297       0.9661        0.1055  0.7603\n",
      "     14             0.9529        0.0472       0.9643        0.1205  0.7557\n",
      "Epoch 00015: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     15             0.9813        0.0247       0.9853        0.0442  0.7565\n",
      "     16             \u001b[36m0.9883\u001b[0m        \u001b[32m0.0109\u001b[0m       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0384\u001b[0m  0.7570\n",
      "     17             0.9866        \u001b[32m0.0050\u001b[0m       0.9895        0.0385  0.7573\n",
      "     18             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0035\u001b[0m       \u001b[35m0.9918\u001b[0m        \u001b[31m0.0359\u001b[0m  0.7570\n",
      "     19             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0027\u001b[0m       \u001b[35m0.9922\u001b[0m        \u001b[31m0.0353\u001b[0m  0.7570\n",
      "     20             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0022\u001b[0m       0.9922        \u001b[31m0.0343\u001b[0m  0.7520\n",
      "     21             0.9901        \u001b[32m0.0020\u001b[0m       0.9922        0.0347  0.7602\n",
      "     22             0.9895        \u001b[32m0.0015\u001b[0m       0.9918        0.0351  0.7662\n",
      "     23             0.9901        \u001b[32m0.0014\u001b[0m       0.9922        0.0353  0.7680\n",
      "     24             0.9895        \u001b[32m0.0013\u001b[0m       0.9918        0.0362  0.7686\n",
      "     25             0.9895        \u001b[32m0.0011\u001b[0m       0.9918        0.0352  0.7673\n",
      "     26             0.9901        0.0012       0.9922        0.0351  0.7709\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 22/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.995) f1_score: (test=0.993) total time=  20.7s\n",
      "[CV 4/4; 22/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4546\u001b[0m        \u001b[32m0.3852\u001b[0m       \u001b[35m0.7306\u001b[0m        \u001b[31m0.5034\u001b[0m  0.7680\n",
      "      2             \u001b[36m0.8323\u001b[0m        \u001b[32m0.1886\u001b[0m       \u001b[35m0.8777\u001b[0m        \u001b[31m0.2962\u001b[0m  0.7662\n",
      "      3             \u001b[36m0.9110\u001b[0m        \u001b[32m0.1056\u001b[0m       \u001b[35m0.9313\u001b[0m        \u001b[31m0.1698\u001b[0m  0.7598\n",
      "      4             \u001b[36m0.9218\u001b[0m        \u001b[32m0.0938\u001b[0m       \u001b[35m0.9363\u001b[0m        \u001b[31m0.1577\u001b[0m  0.7635\n",
      "      5             \u001b[36m0.9694\u001b[0m        0.1018       \u001b[35m0.9757\u001b[0m        \u001b[31m0.0758\u001b[0m  0.7631\n",
      "      6             \u001b[36m0.9788\u001b[0m        \u001b[32m0.0404\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0654\u001b[0m  0.7614\n",
      "      7             0.9722        0.0412       0.9780        0.0725  0.7614\n",
      "      8             0.9684        \u001b[32m0.0318\u001b[0m       0.9753        0.0771  0.7642\n",
      "      9             0.9474        0.0345       0.9574        0.1185  0.7634\n",
      "     10             0.9659        \u001b[32m0.0305\u001b[0m       0.9725        0.0807  0.7617\n",
      "     11             0.9460        0.0353       0.9556        0.1346  0.7637\n",
      "     12             0.9622        \u001b[32m0.0303\u001b[0m       0.9711        0.1205  0.7639\n",
      "     13             \u001b[36m0.9793\u001b[0m        0.0424       0.9835        \u001b[31m0.0485\u001b[0m  0.7611\n",
      "     14             0.9764        \u001b[32m0.0167\u001b[0m       0.9817        0.0701  0.7596\n",
      "     15             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0062\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0413\u001b[0m  0.7637\n",
      "     16             0.9806        0.0065       0.9849        0.0756  0.7631\n",
      "     17             0.9297        0.0299       0.9414        0.2180  0.7654\n",
      "Epoch 00018: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     18             0.9660        0.0346       0.9739        0.0994  0.7632\n",
      "     19             \u001b[36m0.9889\u001b[0m        0.0075       \u001b[35m0.9913\u001b[0m        \u001b[31m0.0325\u001b[0m  0.7641\n",
      "     20             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0045\u001b[0m       \u001b[35m0.9918\u001b[0m        \u001b[31m0.0298\u001b[0m  0.7624\n",
      "     21             \u001b[36m0.9901\u001b[0m        \u001b[32m0.0035\u001b[0m       \u001b[35m0.9922\u001b[0m        \u001b[31m0.0287\u001b[0m  0.7606\n",
      "     22             \u001b[36m0.9913\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9931\u001b[0m        \u001b[31m0.0281\u001b[0m  0.7602\n",
      "     23             0.9913        \u001b[32m0.0022\u001b[0m       0.9931        \u001b[31m0.0281\u001b[0m  0.7609\n",
      "     24             0.9913        \u001b[32m0.0020\u001b[0m       0.9931        \u001b[31m0.0279\u001b[0m  0.7556\n",
      "     25             \u001b[36m0.9919\u001b[0m        \u001b[32m0.0017\u001b[0m       \u001b[35m0.9936\u001b[0m        0.0279  0.7567\n",
      "     26             0.9907        \u001b[32m0.0015\u001b[0m       0.9927        0.0282  0.7572\n",
      "     27             0.9913        \u001b[32m0.0013\u001b[0m       0.9931        \u001b[31m0.0276\u001b[0m  0.7572\n",
      "     28             0.9913        \u001b[32m0.0012\u001b[0m       0.9931        \u001b[31m0.0276\u001b[0m  0.7531\n",
      "     29             0.9913        \u001b[32m0.0010\u001b[0m       0.9931        0.0282  0.7545\n",
      "     30             0.9913        0.0011       0.9931        0.0279  0.7531\n",
      "     31             0.9913        \u001b[32m0.0009\u001b[0m       0.9931        0.0280  0.7562\n",
      "     32             0.9919        \u001b[32m0.0008\u001b[0m       0.9936        0.0280  0.7568\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 22/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=256, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.997) f1_score: (test=0.996) total time=  25.3s\n",
      "[CV 1/4; 23/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.6479\u001b[0m        \u001b[32m0.4798\u001b[0m       \u001b[35m0.7439\u001b[0m        \u001b[31m0.6001\u001b[0m  0.5931\n",
      "      2             \u001b[36m0.8278\u001b[0m        \u001b[32m0.2452\u001b[0m       \u001b[35m0.8461\u001b[0m        \u001b[31m0.2772\u001b[0m  0.5916\n",
      "      3             \u001b[36m0.8955\u001b[0m        \u001b[32m0.1225\u001b[0m       \u001b[35m0.9088\u001b[0m        \u001b[31m0.1571\u001b[0m  0.5906\n",
      "      4             \u001b[36m0.9649\u001b[0m        \u001b[32m0.0796\u001b[0m       \u001b[35m0.9716\u001b[0m        \u001b[31m0.0749\u001b[0m  0.5917\n",
      "      5             \u001b[36m0.9794\u001b[0m        \u001b[32m0.0471\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0562\u001b[0m  0.5902\n",
      "      6             0.9719        \u001b[32m0.0281\u001b[0m       0.9771        \u001b[31m0.0507\u001b[0m  0.5942\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      7             0.9665        \u001b[32m0.0232\u001b[0m       0.9725        0.0535  0.5965\n",
      "      8             \u001b[36m0.9829\u001b[0m        \u001b[32m0.0186\u001b[0m       \u001b[35m0.9863\u001b[0m        \u001b[31m0.0357\u001b[0m  0.5899\n",
      "      9             0.9757        \u001b[32m0.0124\u001b[0m       0.9803        0.0372  0.5924\n",
      "     10             \u001b[36m0.9852\u001b[0m        \u001b[32m0.0093\u001b[0m       \u001b[35m0.9881\u001b[0m        0.0417  0.5899\n",
      "     11             0.9784        \u001b[32m0.0045\u001b[0m       0.9831        0.0952  0.5898\n",
      "     12             0.9800        0.0049       0.9840        0.0553  0.5915\n",
      "     13             0.9792        0.0055       0.9831        0.0450  0.5894\n",
      "Epoch 00014: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     14             0.9786        0.0066       0.9826        0.0400  0.5908\n",
      "     15             \u001b[36m0.9869\u001b[0m        \u001b[32m0.0038\u001b[0m       \u001b[35m0.9895\u001b[0m        \u001b[31m0.0278\u001b[0m  0.5896\n",
      "     16             \u001b[36m0.9886\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0258\u001b[0m  0.5921\n",
      "     17             \u001b[36m0.9891\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9913\u001b[0m        \u001b[31m0.0234\u001b[0m  0.5916\n",
      "     18             \u001b[36m0.9903\u001b[0m        \u001b[32m0.0006\u001b[0m       \u001b[35m0.9922\u001b[0m        \u001b[31m0.0229\u001b[0m  0.5911\n",
      "     19             0.9897        \u001b[32m0.0005\u001b[0m       0.9918        \u001b[31m0.0228\u001b[0m  0.5899\n",
      "     20             \u001b[36m0.9909\u001b[0m        \u001b[32m0.0005\u001b[0m       \u001b[35m0.9927\u001b[0m        \u001b[31m0.0223\u001b[0m  0.5911\n",
      "     21             0.9897        0.0007       0.9918        0.0237  0.6008\n",
      "     22             0.9897        0.0007       0.9918        \u001b[31m0.0222\u001b[0m  0.5945\n",
      "     23             \u001b[36m0.9909\u001b[0m        \u001b[32m0.0004\u001b[0m       0.9927        \u001b[31m0.0210\u001b[0m  0.5962\n",
      "     24             0.9903        0.0005       0.9922        \u001b[31m0.0209\u001b[0m  0.5918\n",
      "     25             0.9897        0.0004       0.9918        0.0215  0.5923\n",
      "     26             0.9903        \u001b[32m0.0004\u001b[0m       0.9922        0.0210  0.5913\n",
      "     27             0.9903        \u001b[32m0.0003\u001b[0m       0.9922        0.0212  0.5933\n",
      "     28             \u001b[36m0.9914\u001b[0m        0.0004       \u001b[35m0.9931\u001b[0m        0.0214  0.5989\n",
      "     29             0.9914        \u001b[32m0.0003\u001b[0m       0.9931        \u001b[31m0.0207\u001b[0m  0.5911\n",
      "     30             0.9914        \u001b[32m0.0003\u001b[0m       0.9931        0.0210  0.5915\n",
      "     31             0.9903        0.0003       0.9922        0.0209  0.5932\n",
      "     32             0.9914        0.0003       0.9931        0.0208  0.5908\n",
      "Epoch 00033: reducing learning rate of group 0 to 2.0000e-06.\n",
      "     33             0.9909        0.0003       0.9927        \u001b[31m0.0204\u001b[0m  0.5909\n",
      "     34             \u001b[36m0.9914\u001b[0m        \u001b[32m0.0003\u001b[0m       0.9931        0.0209  0.5912\n",
      "     35             \u001b[36m0.9926\u001b[0m        0.0003       \u001b[35m0.9940\u001b[0m        0.0206  0.5896\n",
      "     36             0.9914        0.0003       0.9931        0.0207  0.5893\n",
      "     37             0.9909        \u001b[32m0.0003\u001b[0m       0.9927        0.0205  0.5923\n",
      "     38             0.9914        \u001b[32m0.0002\u001b[0m       0.9931        0.0210  0.5932\n",
      "     39             0.9914        0.0003       0.9931        0.0207  0.5935\n",
      "     40             0.9914        0.0003       0.9931        0.0208  0.5931\n",
      "Epoch 00041: reducing learning rate of group 0 to 1.0000e-06.\n",
      "     41             0.9920        0.0003       0.9936        0.0212  0.5911\n",
      "     42             0.9920        0.0003       0.9936        0.0210  0.5925\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 23/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.987) f1_score: (test=0.984) total time=  25.7s\n",
      "[CV 2/4; 23/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5422\u001b[0m        \u001b[32m0.5056\u001b[0m       \u001b[35m0.6606\u001b[0m        \u001b[31m0.6682\u001b[0m  0.5891\n",
      "      2             \u001b[36m0.8607\u001b[0m        \u001b[32m0.2734\u001b[0m       \u001b[35m0.8791\u001b[0m        \u001b[31m0.2371\u001b[0m  0.5906\n",
      "      3             \u001b[36m0.8870\u001b[0m        \u001b[32m0.1472\u001b[0m       \u001b[35m0.9024\u001b[0m        \u001b[31m0.1811\u001b[0m  0.5953\n",
      "      4             \u001b[36m0.9502\u001b[0m        \u001b[32m0.0994\u001b[0m       \u001b[35m0.9606\u001b[0m        \u001b[31m0.1233\u001b[0m  0.5915\n",
      "      5             \u001b[36m0.9553\u001b[0m        \u001b[32m0.0653\u001b[0m       \u001b[35m0.9638\u001b[0m        \u001b[31m0.0860\u001b[0m  0.5888\n",
      "      6             0.9220        \u001b[32m0.0441\u001b[0m       0.9345        0.1429  0.5933\n",
      "      7             \u001b[36m0.9609\u001b[0m        \u001b[32m0.0406\u001b[0m       \u001b[35m0.9684\u001b[0m        \u001b[31m0.0777\u001b[0m  0.5909\n",
      "      8             \u001b[36m0.9781\u001b[0m        \u001b[32m0.0255\u001b[0m       \u001b[35m0.9826\u001b[0m        \u001b[31m0.0686\u001b[0m  0.5922\n",
      "      9             \u001b[36m0.9792\u001b[0m        \u001b[32m0.0127\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0666\u001b[0m  0.5914\n",
      "     10             0.9566        \u001b[32m0.0112\u001b[0m       0.9647        0.1111  0.5910\n",
      "     11             0.9714        0.0115       0.9771        0.0751  0.5944\n",
      "     12             0.9498        0.0203       0.9592        0.1329  0.5916\n",
      "Epoch 00013: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     13             0.9578        0.0207       0.9656        0.0998  0.5895\n",
      "     14             0.9792        \u001b[32m0.0068\u001b[0m       0.9835        \u001b[31m0.0628\u001b[0m  0.5901\n",
      "     15             \u001b[36m0.9792\u001b[0m        \u001b[32m0.0036\u001b[0m       0.9835        \u001b[31m0.0616\u001b[0m  0.5909\n",
      "     16             \u001b[36m0.9798\u001b[0m        \u001b[32m0.0024\u001b[0m       \u001b[35m0.9840\u001b[0m        0.0636  0.5890\n",
      "     17             \u001b[36m0.9804\u001b[0m        \u001b[32m0.0021\u001b[0m       \u001b[35m0.9844\u001b[0m        0.0647  0.5897\n",
      "     18             0.9804        \u001b[32m0.0019\u001b[0m       0.9844        0.0647  0.5923\n",
      "     19             \u001b[36m0.9809\u001b[0m        \u001b[32m0.0016\u001b[0m       \u001b[35m0.9849\u001b[0m        0.0641  0.5877\n",
      "     20             \u001b[36m0.9810\u001b[0m        0.0018       0.9849        0.0647  0.5910\n",
      "     21             0.9809        \u001b[32m0.0015\u001b[0m       0.9849        0.0650  0.5939\n",
      "     22             0.9809        \u001b[32m0.0015\u001b[0m       0.9849        0.0649  0.6140\n",
      "     23             \u001b[36m0.9815\u001b[0m        \u001b[32m0.0012\u001b[0m       \u001b[35m0.9853\u001b[0m        0.0645  0.6218\n",
      "     24             0.9815        0.0012       0.9853        0.0661  0.6235\n",
      "     25             0.9815        \u001b[32m0.0012\u001b[0m       0.9853        0.0659  0.6182\n",
      "     26             \u001b[36m0.9827\u001b[0m        \u001b[32m0.0011\u001b[0m       \u001b[35m0.9863\u001b[0m        0.0642  0.6242\n",
      "     27             0.9827        \u001b[32m0.0010\u001b[0m       0.9863        0.0668  0.6244\n",
      "     28             0.9815        0.0011       0.9853        0.0678  0.6205\n",
      "     29             0.9815        \u001b[32m0.0009\u001b[0m       0.9853        0.0665  0.6185\n",
      "     30             0.9821        0.0009       0.9858        0.0675  0.6112\n",
      "     31             0.9815        \u001b[32m0.0009\u001b[0m       0.9853        0.0686  0.6303\n",
      "     32             0.9821        \u001b[32m0.0007\u001b[0m       0.9858        0.0682  0.6162\n",
      "     33             0.9821        0.0007       0.9858        0.0673  0.5920\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 23/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.990) f1_score: (test=0.988) total time=  20.6s\n",
      "[CV 3/4; 23/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4219\u001b[0m        \u001b[32m0.4979\u001b[0m       \u001b[35m0.7297\u001b[0m        \u001b[31m0.9894\u001b[0m  0.6294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      2             \u001b[36m0.8412\u001b[0m        \u001b[32m0.2356\u001b[0m       \u001b[35m0.8713\u001b[0m        \u001b[31m0.3379\u001b[0m  0.6325\n",
      "      3             \u001b[36m0.8799\u001b[0m        \u001b[32m0.1291\u001b[0m       \u001b[35m0.8956\u001b[0m        \u001b[31m0.1954\u001b[0m  0.6280\n",
      "      4             \u001b[36m0.9552\u001b[0m        \u001b[32m0.1016\u001b[0m       \u001b[35m0.9638\u001b[0m        \u001b[31m0.0958\u001b[0m  0.6364\n",
      "      5             \u001b[36m0.9726\u001b[0m        \u001b[32m0.0530\u001b[0m       \u001b[35m0.9785\u001b[0m        \u001b[31m0.0885\u001b[0m  0.6309\n",
      "      6             \u001b[36m0.9756\u001b[0m        \u001b[32m0.0481\u001b[0m       \u001b[35m0.9808\u001b[0m        \u001b[31m0.0857\u001b[0m  0.6249\n",
      "      7             0.9730        \u001b[32m0.0416\u001b[0m       0.9789        0.1094  0.6202\n",
      "      8             \u001b[36m0.9791\u001b[0m        \u001b[32m0.0227\u001b[0m       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0763\u001b[0m  0.6229\n",
      "      9             0.9779        \u001b[32m0.0179\u001b[0m       0.9826        0.0866  0.6209\n",
      "     10             \u001b[36m0.9813\u001b[0m        \u001b[32m0.0065\u001b[0m       \u001b[35m0.9853\u001b[0m        0.0883  0.6202\n",
      "     11             0.9770        \u001b[32m0.0037\u001b[0m       0.9817        \u001b[31m0.0753\u001b[0m  0.6219\n",
      "     12             \u001b[36m0.9824\u001b[0m        \u001b[32m0.0032\u001b[0m       \u001b[35m0.9863\u001b[0m        0.0940  0.6173\n",
      "     13             0.9818        \u001b[32m0.0011\u001b[0m       0.9858        0.0907  0.6070\n",
      "     14             0.9818        0.0017       0.9858        0.0967  0.6162\n",
      "     15             \u001b[36m0.9861\u001b[0m        \u001b[32m0.0009\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0743\u001b[0m  0.5992\n",
      "     16             0.9637        0.0015       0.9707        0.1099  0.5977\n",
      "     17             0.9753        0.0025       0.9803        0.0762  0.5974\n",
      "     18             0.9830        \u001b[32m0.0009\u001b[0m       0.9867        0.0921  0.5966\n",
      "     19             0.9824        \u001b[32m0.0006\u001b[0m       0.9863        0.0902  0.5980\n",
      "     20             0.9854        0.0006       0.9885        0.0811  0.5932\n",
      "     21             0.9854        \u001b[32m0.0003\u001b[0m       0.9885        0.0841  0.5967\n",
      "     22             0.9562        0.0119       0.9647        0.1422  0.6159\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 23/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.948) f1_score: (test=0.933) total time=  14.3s\n",
      "[CV 4/4; 23/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4224\u001b[0m        \u001b[32m0.4921\u001b[0m       \u001b[35m0.7265\u001b[0m        \u001b[31m0.7413\u001b[0m  0.5944\n",
      "      2             \u001b[36m0.8396\u001b[0m        \u001b[32m0.2473\u001b[0m       \u001b[35m0.8814\u001b[0m        \u001b[31m0.3942\u001b[0m  0.5966\n",
      "      3             \u001b[36m0.9614\u001b[0m        \u001b[32m0.1153\u001b[0m       \u001b[35m0.9693\u001b[0m        \u001b[31m0.1022\u001b[0m  0.5954\n",
      "      4             \u001b[36m0.9729\u001b[0m        \u001b[32m0.0740\u001b[0m       \u001b[35m0.9789\u001b[0m        0.1235  0.6008\n",
      "      5             0.9607        \u001b[32m0.0407\u001b[0m       0.9698        0.1532  0.5962\n",
      "      6             \u001b[36m0.9739\u001b[0m        0.0419       \u001b[35m0.9794\u001b[0m        \u001b[31m0.0807\u001b[0m  0.6024\n",
      "      7             \u001b[36m0.9741\u001b[0m        \u001b[32m0.0314\u001b[0m       0.9794        \u001b[31m0.0807\u001b[0m  0.5969\n",
      "      8             \u001b[36m0.9771\u001b[0m        \u001b[32m0.0167\u001b[0m       \u001b[35m0.9817\u001b[0m        \u001b[31m0.0659\u001b[0m  0.5971\n",
      "      9             0.9648        \u001b[32m0.0105\u001b[0m       0.9716        0.0789  0.5967\n",
      "     10             \u001b[36m0.9848\u001b[0m        \u001b[32m0.0058\u001b[0m       \u001b[35m0.9881\u001b[0m        0.0768  0.5963\n",
      "     11             0.9837        \u001b[32m0.0048\u001b[0m       0.9872        0.0786  0.5957\n",
      "     12             0.9616        \u001b[32m0.0030\u001b[0m       0.9707        0.2256  0.5975\n",
      "     13             0.9444        0.0134       0.9542        0.1502  0.5964\n",
      "     14             0.8636        0.0686       0.8804        0.4480  0.5973\n",
      "Epoch 00015: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     15             0.9747        0.1028       0.9798        0.0785  0.5969\n",
      "     16             0.9792        0.0222       0.9835        0.0745  0.5936\n",
      "     17             0.9769        0.0156       0.9817        0.0741  0.5921\n",
      "Epoch 00018: reducing learning rate of group 0 to 2.0000e-06.\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 23/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=64, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.987) f1_score: (test=0.984) total time=  10.9s\n",
      "[CV 1/4; 24/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.5201\u001b[0m        \u001b[32m0.4362\u001b[0m       \u001b[35m0.7064\u001b[0m        \u001b[31m0.8455\u001b[0m  0.5955\n",
      "      2             \u001b[36m0.8390\u001b[0m        \u001b[32m0.2338\u001b[0m       \u001b[35m0.8557\u001b[0m        \u001b[31m0.2555\u001b[0m  0.5995\n",
      "      3             \u001b[36m0.9324\u001b[0m        \u001b[32m0.1433\u001b[0m       \u001b[35m0.9478\u001b[0m        \u001b[31m0.1875\u001b[0m  0.6037\n",
      "      4             \u001b[36m0.9543\u001b[0m        \u001b[32m0.0948\u001b[0m       \u001b[35m0.9638\u001b[0m        \u001b[31m0.1352\u001b[0m  0.5997\n",
      "      5             \u001b[36m0.9561\u001b[0m        \u001b[32m0.0652\u001b[0m       0.9638        \u001b[31m0.0785\u001b[0m  0.5993\n",
      "      6             0.9553        \u001b[32m0.0594\u001b[0m       0.9629        0.0802  0.5983\n",
      "      7             0.8928        0.1258       0.9088        0.2159  0.5947\n",
      "      8             \u001b[36m0.9783\u001b[0m        \u001b[32m0.0496\u001b[0m       \u001b[35m0.9826\u001b[0m        \u001b[31m0.0539\u001b[0m  0.5970\n",
      "      9             0.9738        \u001b[32m0.0223\u001b[0m       0.9794        0.1567  0.5954\n",
      "     10             0.5724        0.0655       0.7668        3.1561  0.5960\n",
      "     11             \u001b[36m0.9802\u001b[0m        0.0478       \u001b[35m0.9840\u001b[0m        \u001b[31m0.0378\u001b[0m  0.5955\n",
      "     12             \u001b[36m0.9885\u001b[0m        \u001b[32m0.0162\u001b[0m       \u001b[35m0.9908\u001b[0m        0.0446  0.5989\n",
      "     13             0.9840        \u001b[32m0.0090\u001b[0m       0.9872        0.0476  0.5996\n",
      "     14             0.9846        0.0170       0.9876        \u001b[31m0.0342\u001b[0m  0.5968\n",
      "     15             0.9765        0.0187       0.9812        0.0864  0.5973\n",
      "Epoch 00016: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     16             0.9690        0.0129       0.9748        0.0616  0.5980\n",
      "     17             \u001b[36m0.9914\u001b[0m        \u001b[32m0.0055\u001b[0m       \u001b[35m0.9931\u001b[0m        0.0451  0.5970\n",
      "     18             \u001b[36m0.9931\u001b[0m        \u001b[32m0.0017\u001b[0m       \u001b[35m0.9945\u001b[0m        0.0347  0.5955\n",
      "     19             \u001b[36m0.9937\u001b[0m        \u001b[32m0.0010\u001b[0m       \u001b[35m0.9950\u001b[0m        0.0342  0.5950\n",
      "     20             \u001b[36m0.9943\u001b[0m        0.0010       \u001b[35m0.9954\u001b[0m        \u001b[31m0.0313\u001b[0m  0.5921\n",
      "     21             0.9943        \u001b[32m0.0007\u001b[0m       0.9954        0.0327  0.5940\n",
      "     22             0.9937        \u001b[32m0.0007\u001b[0m       0.9950        0.0335  0.5942\n",
      "     23             0.9937        \u001b[32m0.0007\u001b[0m       0.9950        0.0327  0.5947\n",
      "     24             0.9943        \u001b[32m0.0007\u001b[0m       0.9954        0.0346  0.5948\n",
      "     25             0.9937        \u001b[32m0.0005\u001b[0m       0.9950        0.0329  0.5943\n",
      "     26             0.9931        0.0006       0.9945        0.0336  0.5966\n",
      "     27             0.9937        \u001b[32m0.0004\u001b[0m       0.9950        0.0374  0.5976\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 24/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.991) f1_score: (test=0.988) total time=  16.9s\n",
      "[CV 2/4; 24/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4190\u001b[0m        \u001b[32m0.3719\u001b[0m       \u001b[35m0.7164\u001b[0m        \u001b[31m2.9213\u001b[0m  0.5982\n",
      "      2             \u001b[36m0.8222\u001b[0m        \u001b[32m0.2040\u001b[0m       \u001b[35m0.8681\u001b[0m        \u001b[31m0.4734\u001b[0m  0.5964\n",
      "      3             \u001b[36m0.9517\u001b[0m        \u001b[32m0.1165\u001b[0m       \u001b[35m0.9615\u001b[0m        \u001b[31m0.1468\u001b[0m  0.5980\n",
      "      4             \u001b[36m0.9809\u001b[0m        \u001b[32m0.0847\u001b[0m       \u001b[35m0.9849\u001b[0m        \u001b[31m0.0694\u001b[0m  0.5975\n",
      "      5             0.9565        \u001b[32m0.0653\u001b[0m       0.9647        0.0855  0.6005\n",
      "      6             0.9606        \u001b[32m0.0501\u001b[0m       0.9689        0.1306  0.5982\n",
      "      7             0.9648        \u001b[32m0.0315\u001b[0m       0.9716        \u001b[31m0.0661\u001b[0m  0.5999\n",
      "      8             0.9465        \u001b[32m0.0304\u001b[0m       0.9565        0.1159  0.6003\n",
      "      9             0.9330        0.0445       0.9501        0.2604  0.5958\n",
      "     10             0.9670        0.0400       0.9734        0.0713  0.5967\n",
      "Epoch 00011: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     11             0.9501        0.0451       0.9592        0.0838  0.5954\n",
      "     12             \u001b[36m0.9827\u001b[0m        \u001b[32m0.0177\u001b[0m       \u001b[35m0.9863\u001b[0m        \u001b[31m0.0463\u001b[0m  0.5974\n",
      "     13             \u001b[36m0.9878\u001b[0m        \u001b[32m0.0073\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0329\u001b[0m  0.5935\n",
      "     14             0.9872        \u001b[32m0.0053\u001b[0m       0.9899        \u001b[31m0.0324\u001b[0m  0.5919\n",
      "     15             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0044\u001b[0m       \u001b[35m0.9908\u001b[0m        0.0325  0.5970\n",
      "     16             0.9878        \u001b[32m0.0039\u001b[0m       0.9904        \u001b[31m0.0312\u001b[0m  0.5952\n",
      "     17             0.9878        \u001b[32m0.0031\u001b[0m       0.9904        0.0321  0.5946\n",
      "     18             0.9878        \u001b[32m0.0025\u001b[0m       0.9904        0.0318  0.5945\n",
      "     19             0.9878        0.0025       0.9904        0.0318  0.5946\n",
      "     20             0.9872        \u001b[32m0.0019\u001b[0m       0.9899        0.0338  0.5925\n",
      "     21             0.9872        \u001b[32m0.0018\u001b[0m       0.9899        0.0337  0.5947\n",
      "     22             0.9872        \u001b[32m0.0015\u001b[0m       0.9899        0.0314  0.5931\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 24/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.992) f1_score: (test=0.990) total time=  13.9s\n",
      "[CV 3/4; 24/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4372\u001b[0m        \u001b[32m0.4097\u001b[0m       \u001b[35m0.7320\u001b[0m        \u001b[31m1.4092\u001b[0m  0.5979\n",
      "      2             \u001b[36m0.8536\u001b[0m        \u001b[32m0.1793\u001b[0m       \u001b[35m0.8804\u001b[0m        \u001b[31m0.3085\u001b[0m  0.5979\n",
      "      3             \u001b[36m0.9396\u001b[0m        \u001b[32m0.1199\u001b[0m       \u001b[35m0.9505\u001b[0m        \u001b[31m0.1103\u001b[0m  0.5980\n",
      "      4             \u001b[36m0.9569\u001b[0m        \u001b[32m0.1035\u001b[0m       \u001b[35m0.9661\u001b[0m        0.1272  0.5963\n",
      "      5             0.9453        \u001b[32m0.0591\u001b[0m       0.9579        0.1701  0.5965\n",
      "      6             \u001b[36m0.9769\u001b[0m        \u001b[32m0.0393\u001b[0m       \u001b[35m0.9817\u001b[0m        \u001b[31m0.0689\u001b[0m  0.5957\n",
      "      7             0.9360        0.0583       0.9519        0.2385  0.5955\n",
      "      8             \u001b[36m0.9813\u001b[0m        \u001b[32m0.0340\u001b[0m       \u001b[35m0.9853\u001b[0m        0.0894  0.5949\n",
      "      9             \u001b[36m0.9819\u001b[0m        \u001b[32m0.0289\u001b[0m       \u001b[35m0.9858\u001b[0m        0.0736  0.5995\n",
      "     10             0.8948        0.0551       0.9093        0.2417  0.5963\n",
      "     11             0.9802        0.0397       0.9844        0.0888  0.5960\n",
      "     12             \u001b[36m0.9832\u001b[0m        \u001b[32m0.0152\u001b[0m       \u001b[35m0.9867\u001b[0m        \u001b[31m0.0504\u001b[0m  0.5989\n",
      "     13             \u001b[36m0.9856\u001b[0m        \u001b[32m0.0082\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0431\u001b[0m  0.6000\n",
      "     14             0.9682        \u001b[32m0.0071\u001b[0m       0.9743        0.0965  0.5975\n",
      "     15             0.9785        \u001b[32m0.0061\u001b[0m       0.9831        0.0854  0.5974\n",
      "     16             0.9619        0.0277       0.9702        0.2226  0.5972\n",
      "     17             0.9729        0.0389       0.9789        0.0993  0.5986\n",
      "Epoch 00018: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     18             0.9579        0.0189       0.9661        0.1000  0.6005\n",
      "     19             \u001b[36m0.9873\u001b[0m        \u001b[32m0.0048\u001b[0m       \u001b[35m0.9899\u001b[0m        0.0451  0.5998\n",
      "     20             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0024\u001b[0m       \u001b[35m0.9908\u001b[0m        0.0454  0.5983\n",
      "     21             \u001b[36m0.9890\u001b[0m        \u001b[32m0.0016\u001b[0m       \u001b[35m0.9913\u001b[0m        0.0445  0.5984\n",
      "     22             0.9890        \u001b[32m0.0011\u001b[0m       0.9913        0.0446  0.5995\n",
      "     23             \u001b[36m0.9896\u001b[0m        \u001b[32m0.0010\u001b[0m       \u001b[35m0.9918\u001b[0m        0.0462  0.5992\n",
      "     24             0.9895        \u001b[32m0.0008\u001b[0m       0.9918        0.0446  0.5990\n",
      "     25             \u001b[36m0.9901\u001b[0m        0.0008       \u001b[35m0.9922\u001b[0m        0.0463  0.5941\n",
      "     26             0.9895        \u001b[32m0.0006\u001b[0m       0.9918        0.0477  0.5921\n",
      "     27             0.9901        \u001b[32m0.0006\u001b[0m       0.9922        0.0468  0.5949\n",
      "     28             0.9890        \u001b[32m0.0006\u001b[0m       0.9913        0.0480  0.5944\n",
      "     29             0.9901        \u001b[32m0.0006\u001b[0m       0.9922        0.0467  0.5948\n",
      "     30             0.9901        \u001b[32m0.0005\u001b[0m       0.9922        0.0478  0.5942\n",
      "     31             0.9895        0.0005       0.9918        0.0470  0.5922\n",
      "     32             0.9901        \u001b[32m0.0004\u001b[0m       0.9922        0.0481  0.5945\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 24/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.991) f1_score: (test=0.988) total time=  19.9s\n",
      "[CV 4/4; 24/25] START criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.7579\u001b[0m        \u001b[32m0.4497\u001b[0m       \u001b[35m0.7934\u001b[0m        \u001b[31m0.5057\u001b[0m  0.5942\n",
      "      2             \u001b[36m0.8745\u001b[0m        \u001b[32m0.2114\u001b[0m       \u001b[35m0.8942\u001b[0m        \u001b[31m0.2991\u001b[0m  0.5924\n",
      "      3             \u001b[36m0.9231\u001b[0m        \u001b[32m0.1292\u001b[0m       \u001b[35m0.9377\u001b[0m        \u001b[31m0.1973\u001b[0m  0.5978\n",
      "      4             \u001b[36m0.9405\u001b[0m        \u001b[32m0.0993\u001b[0m       \u001b[35m0.9551\u001b[0m        \u001b[31m0.1707\u001b[0m  0.6038\n",
      "      5             \u001b[36m0.9635\u001b[0m        \u001b[32m0.0536\u001b[0m       \u001b[35m0.9707\u001b[0m        \u001b[31m0.0916\u001b[0m  0.5992\n",
      "      6             0.9577        \u001b[32m0.0505\u001b[0m       0.9656        \u001b[31m0.0877\u001b[0m  0.6000\n",
      "      7             0.9202        \u001b[32m0.0408\u001b[0m       0.9331        0.1683  0.5994\n",
      "      8             \u001b[36m0.9791\u001b[0m        0.0411       \u001b[35m0.9835\u001b[0m        \u001b[31m0.0822\u001b[0m  0.6008\n",
      "      9             0.9696        \u001b[32m0.0281\u001b[0m       0.9757        0.0827  0.5999\n",
      "     10             \u001b[36m0.9815\u001b[0m        \u001b[32m0.0144\u001b[0m       \u001b[35m0.9853\u001b[0m        \u001b[31m0.0694\u001b[0m  0.5996\n",
      "     11             0.9776        0.0370       0.9821        0.0873  0.6006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     12             0.9685        0.0292       0.9748        0.0864  0.5993\n",
      "Epoch 00013: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     13             0.9769        0.0261       0.9817        0.0817  0.5987\n",
      "     14             \u001b[36m0.9838\u001b[0m        \u001b[32m0.0136\u001b[0m       \u001b[35m0.9872\u001b[0m        \u001b[31m0.0529\u001b[0m  0.5948\n",
      "     15             \u001b[36m0.9855\u001b[0m        \u001b[32m0.0042\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0491\u001b[0m  0.5940\n",
      "     16             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0024\u001b[0m       \u001b[35m0.9908\u001b[0m        0.0492  0.5959\n",
      "     17             0.9884        \u001b[32m0.0018\u001b[0m       0.9908        0.0508  0.5960\n",
      "     18             \u001b[36m0.9889\u001b[0m        0.0018       \u001b[35m0.9913\u001b[0m        0.0498  0.5999\n",
      "     19             \u001b[36m0.9890\u001b[0m        \u001b[32m0.0014\u001b[0m       0.9913        0.0514  0.5939\n",
      "     20             0.9884        \u001b[32m0.0011\u001b[0m       0.9908        0.0504  0.5952\n",
      "     21             0.9889        \u001b[32m0.0010\u001b[0m       0.9913        0.0516  0.5968\n",
      "     22             0.9884        \u001b[32m0.0008\u001b[0m       0.9908        0.0507  0.5958\n",
      "     23             0.9889        \u001b[32m0.0008\u001b[0m       0.9913        0.0517  0.5971\n",
      "     24             0.9884        \u001b[32m0.0007\u001b[0m       0.9908        0.0525  0.5976\n",
      "     25             0.9884        0.0009       0.9908        0.0499  0.5966\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 24/25] END criterion__weight=tensor([1.7981, 0.6926]), iterator_train__batch_size=256, lr=0.0008, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[13, 9, 9, 9, 7], module__n_filters=[32, 48, 48, 48, 64], module__residual=True, module__strides=[2, 2, 1, 1, 1]; accuracy: (test=0.994) f1_score: (test=0.993) total time=  15.7s\n",
      "[CV 1/4; 25/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4182\u001b[0m        \u001b[32m0.4235\u001b[0m       \u001b[35m0.7187\u001b[0m        \u001b[31m0.5622\u001b[0m  1.7337\n",
      "      2             \u001b[36m0.8698\u001b[0m        \u001b[32m0.1691\u001b[0m       \u001b[35m0.9061\u001b[0m        \u001b[31m0.2248\u001b[0m  1.7292\n",
      "      3             \u001b[36m0.9626\u001b[0m        \u001b[32m0.0831\u001b[0m       \u001b[35m0.9702\u001b[0m        \u001b[31m0.0823\u001b[0m  1.7310\n",
      "      4             \u001b[36m0.9790\u001b[0m        \u001b[32m0.0561\u001b[0m       \u001b[35m0.9831\u001b[0m        \u001b[31m0.0438\u001b[0m  1.7295\n",
      "      5             \u001b[36m0.9863\u001b[0m        \u001b[32m0.0430\u001b[0m       \u001b[35m0.9890\u001b[0m        \u001b[31m0.0323\u001b[0m  1.7324\n",
      "      6             0.9775        \u001b[32m0.0196\u001b[0m       0.9817        0.0494  1.7332\n",
      "      7             0.9833        \u001b[32m0.0161\u001b[0m       0.9867        0.0363  1.7307\n",
      "      8             0.9814        \u001b[32m0.0100\u001b[0m       0.9849        0.0474  1.7276\n",
      "      9             \u001b[36m0.9914\u001b[0m        \u001b[32m0.0084\u001b[0m       \u001b[35m0.9931\u001b[0m        \u001b[31m0.0250\u001b[0m  1.7244\n",
      "     10             0.9869        \u001b[32m0.0051\u001b[0m       0.9895        0.0262  1.7308\n",
      "     11             \u001b[36m0.9943\u001b[0m        \u001b[32m0.0031\u001b[0m       \u001b[35m0.9954\u001b[0m        \u001b[31m0.0177\u001b[0m  1.7288\n",
      "     12             0.9737        0.0031       0.9794        0.0648  1.7261\n",
      "     13             0.9926        \u001b[32m0.0022\u001b[0m       0.9940        \u001b[31m0.0145\u001b[0m  1.7341\n",
      "     14             0.9761        \u001b[32m0.0020\u001b[0m       0.9812        0.0511  1.7323\n",
      "     15             0.9879        \u001b[32m0.0019\u001b[0m       0.9904        0.0289  1.7340\n",
      "     16             0.9193        0.0032       0.9308        0.2863  1.7300\n",
      "     17             0.9613        0.0344       0.9698        0.0831  1.7344\n",
      "Epoch 00018: reducing learning rate of group 0 to 2.0000e-05.\n",
      "     18             0.9835        0.0215       0.9867        0.0456  1.7329\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 1/4; 25/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.988) f1_score: (test=0.985) total time=  33.1s\n",
      "[CV 2/4; 25/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4231\u001b[0m        \u001b[32m0.4364\u001b[0m       \u001b[35m0.7284\u001b[0m        \u001b[31m0.5899\u001b[0m  1.7312\n",
      "      2             \u001b[36m0.8735\u001b[0m        \u001b[32m0.1819\u001b[0m       \u001b[35m0.8937\u001b[0m        \u001b[31m0.2390\u001b[0m  1.7301\n",
      "      3             \u001b[36m0.9697\u001b[0m        \u001b[32m0.0918\u001b[0m       \u001b[35m0.9757\u001b[0m        \u001b[31m0.0813\u001b[0m  1.7287\n",
      "      4             0.9676        \u001b[32m0.0419\u001b[0m       0.9748        \u001b[31m0.0633\u001b[0m  1.7302\n",
      "      5             \u001b[36m0.9779\u001b[0m        \u001b[32m0.0413\u001b[0m       \u001b[35m0.9826\u001b[0m        \u001b[31m0.0487\u001b[0m  1.7362\n",
      "      6             0.9697        \u001b[32m0.0214\u001b[0m       0.9766        0.0606  1.7246\n",
      "      7             \u001b[36m0.9877\u001b[0m        \u001b[32m0.0098\u001b[0m       \u001b[35m0.9904\u001b[0m        \u001b[31m0.0364\u001b[0m  1.7249\n",
      "      8             0.9830        \u001b[32m0.0056\u001b[0m       0.9867        0.0435  1.7274\n",
      "      9             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0021\u001b[0m       \u001b[35m0.9918\u001b[0m        \u001b[31m0.0239\u001b[0m  1.7281\n",
      "     10             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0013\u001b[0m       0.9918        0.0250  1.7263\n",
      "     11             \u001b[36m0.9924\u001b[0m        \u001b[32m0.0008\u001b[0m       \u001b[35m0.9940\u001b[0m        0.0244  1.7301\n",
      "     12             0.9913        \u001b[32m0.0005\u001b[0m       0.9931        \u001b[31m0.0219\u001b[0m  1.7350\n",
      "     13             0.9918        \u001b[32m0.0004\u001b[0m       0.9936        \u001b[31m0.0214\u001b[0m  1.7306\n",
      "     14             0.9918        0.0004       0.9936        0.0228  1.7309\n",
      "     15             0.9924        \u001b[32m0.0004\u001b[0m       0.9940        0.0222  1.7286\n",
      "     16             0.9913        \u001b[32m0.0003\u001b[0m       0.9931        0.0232  1.7359\n",
      "     17             0.9907        0.0003       0.9927        0.0242  1.7325\n",
      "     18             0.9907        \u001b[32m0.0003\u001b[0m       0.9927        0.0247  1.7431\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 2/4; 25/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.993) f1_score: (test=0.991) total time=  33.1s\n",
      "[CV 3/4; 25/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4223\u001b[0m        \u001b[32m0.3955\u001b[0m       \u001b[35m0.7261\u001b[0m        \u001b[31m0.5483\u001b[0m  1.7368\n",
      "      2             \u001b[36m0.8004\u001b[0m        \u001b[32m0.1740\u001b[0m       \u001b[35m0.8667\u001b[0m        \u001b[31m0.2919\u001b[0m  1.7315\n",
      "      3             \u001b[36m0.9693\u001b[0m        \u001b[32m0.0748\u001b[0m       \u001b[35m0.9762\u001b[0m        \u001b[31m0.0815\u001b[0m  1.7294\n",
      "      4             0.9674        \u001b[32m0.0484\u001b[0m       0.9748        \u001b[31m0.0742\u001b[0m  1.7263\n",
      "      5             \u001b[36m0.9773\u001b[0m        \u001b[32m0.0340\u001b[0m       \u001b[35m0.9821\u001b[0m        \u001b[31m0.0532\u001b[0m  1.7259\n",
      "      6             0.9486        \u001b[32m0.0190\u001b[0m       0.9579        0.1104  1.7285\n",
      "      7             0.9641        0.0494       0.9721        0.0789  1.7369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      8             0.9745        0.0263       0.9803        0.0713  1.7179\n",
      "Epoch 00009: reducing learning rate of group 0 to 2.0000e-05.\n",
      "      9             \u001b[36m0.9798\u001b[0m        0.0198       \u001b[35m0.9840\u001b[0m        0.0549  1.7170\n",
      "     10             \u001b[36m0.9849\u001b[0m        \u001b[32m0.0070\u001b[0m       \u001b[35m0.9881\u001b[0m        \u001b[31m0.0337\u001b[0m  1.7190\n",
      "     11             \u001b[36m0.9854\u001b[0m        \u001b[32m0.0035\u001b[0m       \u001b[35m0.9885\u001b[0m        \u001b[31m0.0336\u001b[0m  1.7189\n",
      "     12             \u001b[36m0.9866\u001b[0m        \u001b[32m0.0029\u001b[0m       \u001b[35m0.9895\u001b[0m        \u001b[31m0.0333\u001b[0m  1.7209\n",
      "     13             0.9860        \u001b[32m0.0026\u001b[0m       0.9890        0.0340  1.7218\n",
      "     14             \u001b[36m0.9895\u001b[0m        \u001b[32m0.0026\u001b[0m       \u001b[35m0.9918\u001b[0m        \u001b[31m0.0330\u001b[0m  1.7253\n",
      "     15             0.9883        \u001b[32m0.0019\u001b[0m       0.9908        0.0332  1.7324\n",
      "     16             0.9889        0.0021       0.9913        0.0332  1.7271\n",
      "     17             0.9883        \u001b[32m0.0016\u001b[0m       0.9908        0.0332  1.7211\n",
      "     18             0.9878        \u001b[32m0.0016\u001b[0m       0.9904        0.0335  1.7195\n",
      "     19             0.9878        \u001b[32m0.0015\u001b[0m       0.9904        0.0334  1.7212\n",
      "     20             0.9883        \u001b[32m0.0015\u001b[0m       0.9908        0.0336  1.7198\n",
      "     21             0.9895        \u001b[32m0.0013\u001b[0m       0.9918        0.0330  1.7219\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 3/4; 25/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.991) f1_score: (test=0.989) total time=  38.2s\n",
      "[CV 4/4; 25/25] START criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.4224\u001b[0m        \u001b[32m0.4212\u001b[0m       \u001b[35m0.7265\u001b[0m        \u001b[31m0.5500\u001b[0m  1.7168\n",
      "      2             \u001b[36m0.8465\u001b[0m        \u001b[32m0.1875\u001b[0m       \u001b[35m0.8740\u001b[0m        \u001b[31m0.2494\u001b[0m  1.7239\n",
      "      3             \u001b[36m0.9708\u001b[0m        \u001b[32m0.0935\u001b[0m       \u001b[35m0.9766\u001b[0m        \u001b[31m0.0741\u001b[0m  1.7292\n",
      "      4             \u001b[36m0.9748\u001b[0m        \u001b[32m0.0442\u001b[0m       \u001b[35m0.9798\u001b[0m        \u001b[31m0.0674\u001b[0m  1.7284\n",
      "      5             0.9532        \u001b[32m0.0382\u001b[0m       0.9620        0.0987  1.7268\n",
      "      6             \u001b[36m0.9766\u001b[0m        \u001b[32m0.0265\u001b[0m       \u001b[35m0.9817\u001b[0m        \u001b[31m0.0530\u001b[0m  1.7279\n",
      "      7             \u001b[36m0.9836\u001b[0m        \u001b[32m0.0132\u001b[0m       \u001b[35m0.9872\u001b[0m        \u001b[31m0.0440\u001b[0m  1.7267\n",
      "      8             \u001b[36m0.9884\u001b[0m        \u001b[32m0.0088\u001b[0m       \u001b[35m0.9908\u001b[0m        \u001b[31m0.0328\u001b[0m  1.7266\n",
      "      9             \u001b[36m0.9896\u001b[0m        \u001b[32m0.0037\u001b[0m       \u001b[35m0.9918\u001b[0m        \u001b[31m0.0293\u001b[0m  1.7304\n",
      "     10             \u001b[36m0.9907\u001b[0m        \u001b[32m0.0019\u001b[0m       \u001b[35m0.9927\u001b[0m        0.0305  1.7303\n",
      "     11             0.9895        \u001b[32m0.0009\u001b[0m       0.9918        0.0328  1.7339\n",
      "     12             \u001b[36m0.9919\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9936\u001b[0m        \u001b[31m0.0282\u001b[0m  1.7359\n",
      "     13             \u001b[36m0.9924\u001b[0m        \u001b[32m0.0006\u001b[0m       \u001b[35m0.9940\u001b[0m        \u001b[31m0.0258\u001b[0m  1.7283\n",
      "     14             0.9913        \u001b[32m0.0004\u001b[0m       0.9931        0.0297  1.7275\n",
      "     15             0.9924        \u001b[32m0.0003\u001b[0m       0.9940        0.0282  1.7492\n",
      "     16             0.9919        \u001b[32m0.0002\u001b[0m       0.9936        0.0286  1.7292\n",
      "     17             0.9919        \u001b[32m0.0002\u001b[0m       0.9936        0.0292  1.7978\n",
      "     18             0.9924        \u001b[32m0.0002\u001b[0m       0.9940        0.0290  1.7806\n",
      "     19             \u001b[36m0.9930\u001b[0m        \u001b[32m0.0001\u001b[0m       \u001b[35m0.9945\u001b[0m        0.0286  1.8040\n",
      "     20             0.9924        \u001b[32m0.0001\u001b[0m       0.9940        0.0291  1.8036\n",
      "     21             0.9919        \u001b[32m0.0001\u001b[0m       0.9936        0.0300  1.7921\n",
      "     22             0.9924        0.0001       0.9940        0.0295  1.7876\n",
      "     23             0.9924        \u001b[32m0.0001\u001b[0m       0.9940        0.0296  1.7938\n",
      "     24             0.9930        0.0001       0.9945        0.0295  1.7918\n",
      "     25             0.9919        \u001b[32m0.0001\u001b[0m       0.9936        0.0295  1.7907\n",
      "     26             0.9924        0.0001       0.9940        0.0301  1.7341\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "[CV 4/4; 25/25] END criterion__weight=tensor([1., 1.]), iterator_train__batch_size=256, lr=0.0002, module__adaptive_average_len=8, module__fully_connected_features=128, module__kernel_sizes=[7, 5, 5, 5, 3], module__n_filters=[64, 96, 96, 96, 128], module__residual=False, module__strides=[2, 1, 1, 1, 1]; accuracy: (test=0.994) f1_score: (test=0.992) total time=  47.5s\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ------\n",
      "      1             \u001b[36m0.7398\u001b[0m        \u001b[32m0.3373\u001b[0m       \u001b[35m0.7698\u001b[0m        \u001b[31m0.5243\u001b[0m  0.8988\n",
      "      2             \u001b[36m0.8315\u001b[0m        \u001b[32m0.1505\u001b[0m       \u001b[35m0.8478\u001b[0m        \u001b[31m0.4163\u001b[0m  0.9125\n",
      "      3             \u001b[36m0.9541\u001b[0m        \u001b[32m0.0963\u001b[0m       \u001b[35m0.9626\u001b[0m        \u001b[31m0.1076\u001b[0m  0.9194\n",
      "      4             0.9434        0.0964       0.9529        0.1311  0.9157\n",
      "      5             \u001b[36m0.9783\u001b[0m        \u001b[32m0.0391\u001b[0m       \u001b[35m0.9828\u001b[0m        \u001b[31m0.0709\u001b[0m  0.9096\n",
      "      6             0.9555        0.0407       0.9639        0.1050  0.9167\n",
      "      7             0.9734        \u001b[32m0.0343\u001b[0m       0.9787        0.0713  0.9260\n",
      "      8             0.9344        \u001b[32m0.0249\u001b[0m       0.9450        0.1702  0.9155\n",
      "      9             0.9717        \u001b[32m0.0213\u001b[0m       0.9780        0.0952  0.9186\n",
      "     10             \u001b[36m0.9819\u001b[0m        \u001b[32m0.0131\u001b[0m       \u001b[35m0.9856\u001b[0m        \u001b[31m0.0546\u001b[0m  0.9282\n",
      "     11             0.9696        0.0274       0.9756        0.1272  0.8891\n",
      "     12             0.9464        0.0593       0.9557        0.1358  0.8960\n",
      "Epoch 00013: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     13             0.9803        0.0371       0.9842        \u001b[31m0.0513\u001b[0m  0.8933\n",
      "     14             \u001b[36m0.9892\u001b[0m        \u001b[32m0.0091\u001b[0m       \u001b[35m0.9914\u001b[0m        \u001b[31m0.0357\u001b[0m  0.8854\n",
      "     15             0.9888        \u001b[32m0.0054\u001b[0m       0.9911        0.0357  0.8841\n",
      "     16             0.9883        \u001b[32m0.0035\u001b[0m       0.9907        \u001b[31m0.0351\u001b[0m  0.8833\n",
      "     17             0.9883        \u001b[32m0.0030\u001b[0m       0.9907        0.0360  0.8826\n",
      "     18             \u001b[36m0.9900\u001b[0m        \u001b[32m0.0024\u001b[0m       \u001b[35m0.9921\u001b[0m        0.0357  0.8839\n",
      "     19             0.9892        \u001b[32m0.0022\u001b[0m       0.9914        0.0368  0.8847\n",
      "     20             0.9883        0.0024       0.9907        0.0376  0.8859\n",
      "     21             0.9892        \u001b[32m0.0018\u001b[0m       0.9914        0.0374  0.8854\n",
      "     22             0.9892        0.0022       0.9914        0.0382  0.8859\n",
      "     23             0.9896        \u001b[32m0.0012\u001b[0m       0.9918        0.0370  0.8841\n",
      "     24             0.9900        0.0013       0.9921        0.0361  0.8843\n",
      "     25             0.9900        \u001b[32m0.0010\u001b[0m       0.9921        0.0352  0.8828\n",
      "Stopping since skorch_f1_score has not improved in the last 8 epochs.\n",
      "\n",
      "\n",
      "Best score and param setup: 0.9927274779004369, {'module__strides': [2, 1, 1, 1, 1], 'module__residual': False, 'module__n_filters': [32, 48, 48, 48, 64], 'module__kernel_sizes': [9, 7, 7, 7, 5], 'module__fully_connected_features': 128, 'module__adaptive_average_len': 8, 'lr': 0.0008, 'iterator_train__batch_size': 256, 'criterion__weight': tensor([1., 1.])}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if DO_HYPERPARAMETER_SEARCH:\n",
    "    \n",
    "    # Add the class weights as a grid parameter -> bool value to indicate if weights are balanced or not\n",
    "    net = get_neural_net_classifier(module=CNN, n_classes=N_CLASSES, \n",
    "                                    callbacks=[macro_f1_cb, lr_scheduler_cb, early_stopping_cb],\n",
    "                                    train_split=4)\n",
    "\n",
    "    \n",
    "    shallow_grid_params = {\n",
    "        'module__n_filters': [[16, 32], [32, 64], [64, 128]],\n",
    "        'module__kernel_sizes': [[7, 3], [9, 5], [13, 7]],\n",
    "        'module__strides': [[2, 2], [2, 1]],\n",
    "        'module__fully_connected_features': [64, 128, 256],\n",
    "        'module__adaptive_average_len': [8, 16],\n",
    "        'module__residual': [True, False],\n",
    "        \n",
    "        'criterion__weight': [get_class_weights(y, unbalanced=True), get_class_weights(y)],\n",
    "        \n",
    "        'lr': [0.0008, 0.0002],\n",
    "        'iterator_train__batch_size': [256],\n",
    "    }\n",
    "    \n",
    "    deep_grid_params = {\n",
    "        'module__n_filters': [[16, 24, 24, 24, 32], [32, 48, 48, 48, 64], [64, 96, 96, 96, 128]],\n",
    "        'module__kernel_sizes': [[7, 5, 5, 5, 3], [9, 7, 7, 7, 5], [13, 9, 9, 9, 7]],\n",
    "        'module__strides': [[2, 2, 1, 1, 1], [2, 1, 1, 1, 1]],\n",
    "        'module__fully_connected_features': [64, 128, 256],\n",
    "        'module__adaptive_average_len': [8, 16],\n",
    "        'module__residual': [True, False],\n",
    "        \n",
    "        'criterion__weight': [get_class_weights(y, unbalanced=True), get_class_weights(y)],\n",
    "        \n",
    "        'lr': [0.0008, 0.0002],\n",
    "        'iterator_train__batch_size': [256],\n",
    "    }\n",
    "    \n",
    "    if EXPERIMENT_TYPE == \"shallow_hyperparam_search\":\n",
    "        grid_params = shallow_grid_params\n",
    "    elif EXPERIMENT_TYPE == \"deep_hyperparam_search\":\n",
    "        grid_params = deep_grid_params\n",
    "    \n",
    "    save_file(MODEL_SAVE_DIR + '/grid.json', serialize_tensors(grid_params))\n",
    "\n",
    "    # outer split k = 4\n",
    "    gs = RandomizedSearchCV(net, grid_params, n_iter=25, cv=4, scoring={\"accuracy\": \"accuracy\", \"f1_score\": sklearn_f1_score()}, refit=\"f1_score\", verbose=10)\n",
    "\n",
    "    gs.fit(x, y)\n",
    "    print(f\"\\n\\nBest score and param setup: {gs.best_score_}, {gs.best_params_}\\n\\n\")\n",
    "\n",
    "    hyper_search_history = pd.DataFrame(gs.cv_results_)\n",
    "    hyper_search_history.to_csv(MODEL_SAVE_DIR + '/hyperparam_search_history.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e0494e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_module__strides</th>\n",
       "      <th>param_module__residual</th>\n",
       "      <th>param_module__n_filters</th>\n",
       "      <th>param_module__kernel_sizes</th>\n",
       "      <th>param_module__adaptive_average_len</th>\n",
       "      <th>param_module__fully_connected_features</th>\n",
       "      <th>param_criterion__weight</th>\n",
       "      <th>param_lr</th>\n",
       "      <th>param_iterator_train__batch_size</th>\n",
       "      <th>mean_test_accuracy</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 1, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[9, 7, 7, 7, 5]</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>[tensor(1.), tensor(1.)]</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>256</td>\n",
       "      <td>0.994159</td>\n",
       "      <td>0.992727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 1, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[13, 9, 9, 9, 7]</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>[tensor(1.), tensor(1.)]</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>256</td>\n",
       "      <td>0.993729</td>\n",
       "      <td>0.992178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[2, 1, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[64, 96, 96, 96, 128]</td>\n",
       "      <td>[13, 9, 9, 9, 7]</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>[tensor(1.7981), tensor(0.6926)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.992956</td>\n",
       "      <td>0.991229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[13, 9, 9, 9, 7]</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>[tensor(1.7981), tensor(0.6926)]</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>256</td>\n",
       "      <td>0.991925</td>\n",
       "      <td>0.989935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[2, 1, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[64, 96, 96, 96, 128]</td>\n",
       "      <td>[7, 5, 5, 5, 3]</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>[tensor(1.7981), tensor(0.6926)]</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>256</td>\n",
       "      <td>0.991496</td>\n",
       "      <td>0.989395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[2, 1, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[64, 96, 96, 96, 128]</td>\n",
       "      <td>[7, 5, 5, 5, 3]</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>[tensor(1.), tensor(1.)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.991410</td>\n",
       "      <td>0.989293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[13, 9, 9, 9, 7]</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>[tensor(1.7981), tensor(0.6926)]</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>256</td>\n",
       "      <td>0.991238</td>\n",
       "      <td>0.989098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[13, 9, 9, 9, 7]</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>[tensor(1.7981), tensor(0.6926)]</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>256</td>\n",
       "      <td>0.990894</td>\n",
       "      <td>0.988661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[64, 96, 96, 96, 128]</td>\n",
       "      <td>[7, 5, 5, 5, 3]</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>[tensor(1.), tensor(1.)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.990551</td>\n",
       "      <td>0.988210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[64, 96, 96, 96, 128]</td>\n",
       "      <td>[9, 7, 7, 7, 5]</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>[tensor(1.7981), tensor(0.6926)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.990035</td>\n",
       "      <td>0.987586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[2, 1, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[7, 5, 5, 5, 3]</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>[tensor(1.), tensor(1.)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.989863</td>\n",
       "      <td>0.987359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>[64, 96, 96, 96, 128]</td>\n",
       "      <td>[13, 9, 9, 9, 7]</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>[tensor(1.7981), tensor(0.6926)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.989434</td>\n",
       "      <td>0.986846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[2, 1, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[13, 9, 9, 9, 7]</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>[tensor(1.), tensor(1.)]</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>256</td>\n",
       "      <td>0.988746</td>\n",
       "      <td>0.986126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[13, 9, 9, 9, 7]</td>\n",
       "      <td>8</td>\n",
       "      <td>256</td>\n",
       "      <td>[tensor(1.), tensor(1.)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.988747</td>\n",
       "      <td>0.985954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[9, 7, 7, 7, 5]</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>[tensor(1.), tensor(1.)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.988575</td>\n",
       "      <td>0.985741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[13, 9, 9, 9, 7]</td>\n",
       "      <td>16</td>\n",
       "      <td>256</td>\n",
       "      <td>[tensor(1.7981), tensor(0.6926)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.988145</td>\n",
       "      <td>0.985223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[7, 5, 5, 5, 3]</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>[tensor(1.7981), tensor(0.6926)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.987458</td>\n",
       "      <td>0.984398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[2, 1, 1, 1, 1]</td>\n",
       "      <td>True</td>\n",
       "      <td>[16, 24, 24, 24, 32]</td>\n",
       "      <td>[7, 5, 5, 5, 3]</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>[tensor(1.), tensor(1.)]</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>256</td>\n",
       "      <td>0.987372</td>\n",
       "      <td>0.984276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[32, 48, 48, 48, 64]</td>\n",
       "      <td>[9, 7, 7, 7, 5]</td>\n",
       "      <td>16</td>\n",
       "      <td>128</td>\n",
       "      <td>[tensor(1.7981), tensor(0.6926)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.987201</td>\n",
       "      <td>0.984069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[2, 2, 1, 1, 1]</td>\n",
       "      <td>False</td>\n",
       "      <td>[16, 24, 24, 24, 32]</td>\n",
       "      <td>[9, 7, 7, 7, 5]</td>\n",
       "      <td>8</td>\n",
       "      <td>64</td>\n",
       "      <td>[tensor(1.), tensor(1.)]</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>256</td>\n",
       "      <td>0.983765</td>\n",
       "      <td>0.979781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_module__strides param_module__residual param_module__n_filters  \\\n",
       "0        [2, 1, 1, 1, 1]                  False    [32, 48, 48, 48, 64]   \n",
       "4        [2, 1, 1, 1, 1]                  False    [32, 48, 48, 48, 64]   \n",
       "19       [2, 1, 1, 1, 1]                  False   [64, 96, 96, 96, 128]   \n",
       "23       [2, 2, 1, 1, 1]                   True    [32, 48, 48, 48, 64]   \n",
       "13       [2, 1, 1, 1, 1]                  False   [64, 96, 96, 96, 128]   \n",
       "24       [2, 1, 1, 1, 1]                  False   [64, 96, 96, 96, 128]   \n",
       "18       [2, 2, 1, 1, 1]                  False    [32, 48, 48, 48, 64]   \n",
       "10       [2, 2, 1, 1, 1]                   True    [32, 48, 48, 48, 64]   \n",
       "3        [2, 2, 1, 1, 1]                  False   [64, 96, 96, 96, 128]   \n",
       "11       [2, 2, 1, 1, 1]                  False   [64, 96, 96, 96, 128]   \n",
       "5        [2, 1, 1, 1, 1]                  False    [32, 48, 48, 48, 64]   \n",
       "8        [2, 2, 1, 1, 1]                   True   [64, 96, 96, 96, 128]   \n",
       "21       [2, 1, 1, 1, 1]                  False    [32, 48, 48, 48, 64]   \n",
       "1        [2, 2, 1, 1, 1]                   True    [32, 48, 48, 48, 64]   \n",
       "6        [2, 2, 1, 1, 1]                  False    [32, 48, 48, 48, 64]   \n",
       "14       [2, 2, 1, 1, 1]                  False    [32, 48, 48, 48, 64]   \n",
       "9        [2, 2, 1, 1, 1]                   True    [32, 48, 48, 48, 64]   \n",
       "17       [2, 1, 1, 1, 1]                   True    [16, 24, 24, 24, 32]   \n",
       "12       [2, 2, 1, 1, 1]                  False    [32, 48, 48, 48, 64]   \n",
       "16       [2, 2, 1, 1, 1]                  False    [16, 24, 24, 24, 32]   \n",
       "\n",
       "   param_module__kernel_sizes param_module__adaptive_average_len  \\\n",
       "0             [9, 7, 7, 7, 5]                                  8   \n",
       "4            [13, 9, 9, 9, 7]                                  8   \n",
       "19           [13, 9, 9, 9, 7]                                  8   \n",
       "23           [13, 9, 9, 9, 7]                                  8   \n",
       "13            [7, 5, 5, 5, 3]                                  8   \n",
       "24            [7, 5, 5, 5, 3]                                  8   \n",
       "18           [13, 9, 9, 9, 7]                                  8   \n",
       "10           [13, 9, 9, 9, 7]                                 16   \n",
       "3             [7, 5, 5, 5, 3]                                  8   \n",
       "11            [9, 7, 7, 7, 5]                                  8   \n",
       "5             [7, 5, 5, 5, 3]                                 16   \n",
       "8            [13, 9, 9, 9, 7]                                  8   \n",
       "21           [13, 9, 9, 9, 7]                                  8   \n",
       "1            [13, 9, 9, 9, 7]                                  8   \n",
       "6             [9, 7, 7, 7, 5]                                  8   \n",
       "14           [13, 9, 9, 9, 7]                                 16   \n",
       "9             [7, 5, 5, 5, 3]                                  8   \n",
       "17            [7, 5, 5, 5, 3]                                 16   \n",
       "12            [9, 7, 7, 7, 5]                                 16   \n",
       "16            [9, 7, 7, 7, 5]                                  8   \n",
       "\n",
       "   param_module__fully_connected_features           param_criterion__weight  \\\n",
       "0                                     128          [tensor(1.), tensor(1.)]   \n",
       "4                                      64          [tensor(1.), tensor(1.)]   \n",
       "19                                     64  [tensor(1.7981), tensor(0.6926)]   \n",
       "23                                    128  [tensor(1.7981), tensor(0.6926)]   \n",
       "13                                     64  [tensor(1.7981), tensor(0.6926)]   \n",
       "24                                    128          [tensor(1.), tensor(1.)]   \n",
       "18                                     64  [tensor(1.7981), tensor(0.6926)]   \n",
       "10                                     64  [tensor(1.7981), tensor(0.6926)]   \n",
       "3                                     128          [tensor(1.), tensor(1.)]   \n",
       "11                                    256  [tensor(1.7981), tensor(0.6926)]   \n",
       "5                                     128          [tensor(1.), tensor(1.)]   \n",
       "8                                      64  [tensor(1.7981), tensor(0.6926)]   \n",
       "21                                    256          [tensor(1.), tensor(1.)]   \n",
       "1                                     256          [tensor(1.), tensor(1.)]   \n",
       "6                                     128          [tensor(1.), tensor(1.)]   \n",
       "14                                    256  [tensor(1.7981), tensor(0.6926)]   \n",
       "9                                     128  [tensor(1.7981), tensor(0.6926)]   \n",
       "17                                    128          [tensor(1.), tensor(1.)]   \n",
       "12                                    128  [tensor(1.7981), tensor(0.6926)]   \n",
       "16                                     64          [tensor(1.), tensor(1.)]   \n",
       "\n",
       "   param_lr param_iterator_train__batch_size  mean_test_accuracy  \\\n",
       "0    0.0008                              256            0.994159   \n",
       "4    0.0008                              256            0.993729   \n",
       "19   0.0002                              256            0.992956   \n",
       "23   0.0008                              256            0.991925   \n",
       "13   0.0008                              256            0.991496   \n",
       "24   0.0002                              256            0.991410   \n",
       "18   0.0008                              256            0.991238   \n",
       "10   0.0008                              256            0.990894   \n",
       "3    0.0002                              256            0.990551   \n",
       "11   0.0002                              256            0.990035   \n",
       "5    0.0002                              256            0.989863   \n",
       "8    0.0002                              256            0.989434   \n",
       "21   0.0008                              256            0.988746   \n",
       "1    0.0002                              256            0.988747   \n",
       "6    0.0002                              256            0.988575   \n",
       "14   0.0002                              256            0.988145   \n",
       "9    0.0002                              256            0.987458   \n",
       "17   0.0008                              256            0.987372   \n",
       "12   0.0002                              256            0.987201   \n",
       "16   0.0002                              256            0.983765   \n",
       "\n",
       "    mean_test_f1_score  \n",
       "0             0.992727  \n",
       "4             0.992178  \n",
       "19            0.991229  \n",
       "23            0.989935  \n",
       "13            0.989395  \n",
       "24            0.989293  \n",
       "18            0.989098  \n",
       "10            0.988661  \n",
       "3             0.988210  \n",
       "11            0.987586  \n",
       "5             0.987359  \n",
       "8             0.986846  \n",
       "21            0.986126  \n",
       "1             0.985954  \n",
       "6             0.985741  \n",
       "14            0.985223  \n",
       "9             0.984398  \n",
       "17            0.984276  \n",
       "12            0.984069  \n",
       "16            0.979781  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display in a next cell because previous output could be veeerrry long\n",
    "if DO_HYPERPARAMETER_SEARCH:\n",
    "    display(hyper_search_history.sort_values(\"mean_test_f1_score\", ascending=False)[[\"param_module__strides\", \"param_module__residual\", \"param_module__n_filters\", \"param_module__kernel_sizes\", \"param_module__adaptive_average_len\", \"param_module__fully_connected_features\", \"param_criterion__weight\", \"param_lr\", \"param_iterator_train__batch_size\", \"mean_test_accuracy\", \"mean_test_f1_score\"]][:20])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f133332c",
   "metadata": {},
   "source": [
    "# Train & Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36c012c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training params {'module__strides': [2, 1, 1, 1, 1], 'module__residual': False, 'module__n_filters': [32, 48, 48, 48, 64], 'module__kernel_sizes': [9, 7, 7, 7, 5], 'module__fully_connected_features': 128, 'module__adaptive_average_len': 8, 'lr': 0.0008, 'iterator_train__batch_size': 256, 'criterion__weight': tensor([1., 1.])}\n",
      "  epoch    skorch_f1_score    train_loss    valid_acc    valid_loss    cp     dur\n",
      "-------  -----------------  ------------  -----------  ------------  ----  ------\n",
      "      1             \u001b[36m0.6932\u001b[0m        \u001b[32m0.3487\u001b[0m       \u001b[35m0.7651\u001b[0m        \u001b[31m0.4815\u001b[0m     +  0.9248\n",
      "      2             \u001b[36m0.9548\u001b[0m        \u001b[32m0.1409\u001b[0m       \u001b[35m0.9652\u001b[0m        \u001b[31m0.1083\u001b[0m     +  0.9204\n",
      "      3             0.9244        \u001b[32m0.0818\u001b[0m       0.9438        0.1537        0.9212\n",
      "      4             \u001b[36m0.9744\u001b[0m        \u001b[32m0.0522\u001b[0m       \u001b[35m0.9798\u001b[0m        \u001b[31m0.0554\u001b[0m     +  0.9175\n",
      "      5             0.9492        0.0530       0.9618        0.1341        0.9218\n",
      "      6             0.8737        \u001b[32m0.0277\u001b[0m       0.9107        0.3392        0.9238\n",
      "      7             0.9615        \u001b[32m0.0228\u001b[0m       0.9708        0.0866        0.9207\n",
      "      8             0.9097        0.0483       0.9236        0.2241        0.9205\n",
      "      9             \u001b[36m0.9879\u001b[0m        0.0268       \u001b[35m0.9906\u001b[0m        \u001b[31m0.0341\u001b[0m     +  0.9196\n",
      "     10             0.9837        \u001b[32m0.0162\u001b[0m       0.9871        0.0416        0.9173\n",
      "     11             0.9763        0.0241       0.9811        0.0662        0.9199\n",
      "     12             0.9711        0.0200       0.9768        0.0627        0.9219\n",
      "     13             0.9554        \u001b[32m0.0139\u001b[0m       0.9661        0.1050        0.9240\n",
      "     14             0.9858        0.0164       0.9888        0.0373        0.9192\n",
      "     15             0.9847        \u001b[32m0.0109\u001b[0m       0.9880        0.0455        0.9218\n",
      "     16             0.9858        \u001b[32m0.0090\u001b[0m       0.9888        0.0497        0.9227\n",
      "     17             0.9859        0.0112       0.9888        0.0445        0.9170\n",
      "     18             0.9745        0.0141       0.9798        0.0758        0.9193\n",
      "Epoch 00019: reducing learning rate of group 0 to 8.0000e-05.\n",
      "     19             0.9460        0.0175       0.9596        0.1477        0.9178\n",
      "     20             \u001b[36m0.9923\u001b[0m        \u001b[32m0.0050\u001b[0m       \u001b[35m0.9940\u001b[0m        \u001b[31m0.0260\u001b[0m     +  0.9185\n",
      "     21             \u001b[36m0.9940\u001b[0m        \u001b[32m0.0014\u001b[0m       \u001b[35m0.9953\u001b[0m        \u001b[31m0.0255\u001b[0m     +  0.9257\n",
      "     22             0.9940        \u001b[32m0.0007\u001b[0m       0.9953        0.0256        0.9194\n",
      "     23             \u001b[36m0.9945\u001b[0m        \u001b[32m0.0007\u001b[0m       \u001b[35m0.9957\u001b[0m        \u001b[31m0.0249\u001b[0m     +  0.9184\n",
      "     24             0.9945        \u001b[32m0.0007\u001b[0m       0.9957        \u001b[31m0.0241\u001b[0m        0.9197\n",
      "     25             \u001b[36m0.9951\u001b[0m        \u001b[32m0.0005\u001b[0m       \u001b[35m0.9961\u001b[0m        0.0245     +  0.9202\n",
      "     26             0.9945        \u001b[32m0.0005\u001b[0m       0.9957        0.0243        0.9186\n",
      "     27             \u001b[36m0.9962\u001b[0m        \u001b[32m0.0004\u001b[0m       \u001b[35m0.9970\u001b[0m        0.0243     +  0.9149\n",
      "     28             0.9962        \u001b[32m0.0004\u001b[0m       0.9970        \u001b[31m0.0241\u001b[0m        0.9180\n",
      "     29             0.9956        \u001b[32m0.0003\u001b[0m       0.9966        0.0243        0.9154\n",
      "     30             0.9956        0.0003       0.9966        0.0246        0.9189\n",
      "     31             0.9956        \u001b[32m0.0003\u001b[0m       0.9966        0.0244        0.9201\n",
      "     32             0.9956        0.0003       0.9966        0.0253        0.9181\n",
      "     33             0.9962        \u001b[32m0.0003\u001b[0m       0.9970        0.0251        0.9175\n",
      "     34             0.9951        \u001b[32m0.0003\u001b[0m       0.9961        0.0262        0.9191\n",
      "     35             0.9956        \u001b[32m0.0002\u001b[0m       0.9966        0.0254        0.9160\n",
      "     36             0.9951        0.0002       0.9961        0.0257        0.9182\n",
      "     37             0.9956        \u001b[32m0.0002\u001b[0m       0.9966        0.0253        0.9254\n",
      "     38             0.9956        0.0002       0.9966        0.0253        0.9205\n",
      "     39             0.9962        \u001b[32m0.0002\u001b[0m       0.9970        0.0251        0.9153\n",
      "     40             0.9956        \u001b[32m0.0001\u001b[0m       0.9966        0.0257        0.9196\n",
      "     41             0.9962        0.0002       0.9970        0.0254        0.9268\n",
      "Stopping since skorch_f1_score has not improved in the last 15 epochs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=CNN(\n",
       "    (conv_blocks): Sequential(\n",
       "      (0): ConvBlock(\n",
       "        (conv1): Conv1d(1, 32, kernel_size=(9,), stride=(2,))\n",
       "        (bn1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=same)\n",
       "        (bn2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (1): ConvBlock(\n",
       "        (conv1): Conv1d(32, 48, kernel_size=(7,), stride=(1,), padding=same)\n",
       "        (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=same)\n",
       "        (bn2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): ConvBlock(\n",
       "        (conv1): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=same)\n",
       "        (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=same)\n",
       "        (bn2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): ConvBlock(\n",
       "        (conv1): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=same)\n",
       "        (bn1): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(48, 48, kernel_size=(7,), stride=(1,), padding=same)\n",
       "        (bn2): BatchNorm1d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): ConvBlock(\n",
       "        (conv1): Conv1d(48, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "        (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=same)\n",
       "        (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pool): AdaptiveAvgPool1d(output_size=8)\n",
       "    (linear1): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (linear2): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=1)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if DO_HYPERPARAMETER_SEARCH:\n",
    "    best_params = gs.best_params_\n",
    "    save_file(MODEL_SAVE_DIR + '/best_params.json', serialize_tensors(best_params))\n",
    "else:\n",
    "    try:\n",
    "        best_params = deserialize_tensors(read_file(MODEL_SAVE_DIR + '/best_params.json'))\n",
    "    except FileNotFoundError:\n",
    "        print(\"No saved params, setting some defaults\")\n",
    "        best_params = {\n",
    "            'module__n_filters': [32, 64],\n",
    "            'module__strides': [2, 1],\n",
    "            'module__kernel_sizes': [13, 7],\n",
    "            'module__fully_connected_features': 128,\n",
    "            'module__residual': False,\n",
    "            'module__adaptive_average_len': 16,\n",
    "            \n",
    "\n",
    "            'criterion__weight': get_class_weights(y),\n",
    "\n",
    "            \"lr\": 0.001,\n",
    "            \"iterator_train__batch_size\": 256,\n",
    "        }\n",
    "        \n",
    "print(f\"Training params {best_params}\")\n",
    "    \n",
    "# use longer patience\n",
    "early_stopping_cb = EarlyStopping(patience=15, monitor=\"skorch_f1_score\", lower_is_better=False)\n",
    "\n",
    "# used to saved best model on the validation set\n",
    "cp_cb = Checkpoint(dirname=MODEL_SAVE_DIR, monitor=\"skorch_f1_score_best\")\n",
    "\n",
    "net = get_neural_net_classifier(module=CNN, n_classes=N_CLASSES,\n",
    "                                callbacks=[macro_f1_cb, lr_scheduler_cb, cp_cb, early_stopping_cb],\n",
    "                                params=best_params)\n",
    "\n",
    "net.fit(x, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dfed46",
   "metadata": {},
   "source": [
    "# Load back model and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3428447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'module__strides': [2, 1, 1, 1, 1],\n",
       " 'module__residual': False,\n",
       " 'module__n_filters': [32, 48, 48, 48, 64],\n",
       " 'module__kernel_sizes': [9, 7, 7, 7, 5],\n",
       " 'module__fully_connected_features': 128,\n",
       " 'module__adaptive_average_len': 8,\n",
       " 'lr': 0.0008,\n",
       " 'iterator_train__batch_size': 256,\n",
       " 'criterion__weight': tensor([1., 1.])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = Checkpoint(dirname=MODEL_SAVE_DIR)\n",
    "\n",
    "best_params = deserialize_tensors(read_file(MODEL_SAVE_DIR + '/best_params.json'))\n",
    "\n",
    "best_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9126dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_net = get_neural_net_classifier(module=CNN, n_classes=N_CLASSES, params=best_params)\n",
    "loaded_net.initialize()\n",
    "loaded_net.load_params(checkpoint=cp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e20bf676",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy Score: 0.9969082789419443\n",
      "Test Macro F1 Score: 0.9961380741314647\n",
      "\n",
      "\n",
      "ROC AUC score 0.9994651629679897\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PR auc score 0.9997826287331985\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_proba_loaded = loaded_net.predict_proba(xtest)\n",
    "compute_metrics(ytest, y_proba_loaded, name=EXPERIMENT_TYPE + \"CNN\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55319a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (base)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
